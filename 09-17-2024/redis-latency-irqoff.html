<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="sogou_site_verification" content="MQ6oTycfG3"/>
<meta name="google-site-verification" content="hqIFVwBa7rWx4VpI_8SjaGCBNRD664DCU_Sulcvdit8" />
<meta name="360-site-verification" content="329fb6aa8e262eb052b215fce0617f04" />
<meta name="bytedance-verification-code" content="UEpFiB9TrD8NdRaxRndn" />
<meta name="shenma-site-verification" content="0651eae61e001b3f7a26821e537c7ad0_1600871722">

<title>Redis 延迟毛刺问题定位-软中断篇</title>
<meta property="og:site_name" content="有疑说">
<meta property="article:publisher" content="https://www.cyningsun.com" />
<meta property="article:author" content="https://www.cyningsun.com" />
<meta property="article:published_time" content="2024-09-17 00:00:00 +0800"/>
<meta property="og:url" content="/09-17-2024/redis-latency-irqoff.html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta itemprop="description" name="description" content="背景该问题发生于去年的十二月份，业务发现部分线上集群再次出现延迟毛刺。只是现象与上次不同： 延迟出现的时间点不固定，逐渐发生变化 延迟较为规律的每小时出现一次 持续时间大概有差不多十分钟，不是一瞬间 问题定位相比八月份出现类似问题的状态，整个系统的监控系统和定位能力更加完备，包含主调和被调耗时以及耗时百分位。 缩小范围通过 Redis Proxy 主调 Re">

<meta name="keywords" content="软中断,ebpf,perf trace,延迟、时延毛刺">


<link rel="stylesheet" href="/css/bootstrap.css">


<link rel="stylesheet" href="/css/hc.css">

<link rel="shortcut icon" href="/img/favicon.ico">
<style>
    html{ background:#eee; }
    pre{white-space:pre-wrap;}

    em{ text-transform:lowercase; color:#1abc9c; }
    :-moz-any(h1, h2, h3, h4, h5, h5) em{ text-transform: capitalize; }
    em:hover{ color:inherit; }

    #article{ padding:10% 10% 1% 10%; position:relative;   background:#fff;}
    #tagline{ color:#999; font-size:1em; margin:-2em 0 2em; padding-bottom:2em; border-bottom:3px double #eee; }
    #table{ margin-bottom:2em; color:#888; }

    a,code {
      word-break:break-all;
    }

    @media only screen and (max-width: 640px) {
      table{ word-break:break-all;word-wrap:break-word;font-size:12px; }
      .typo table th, .typo table td, .typo-table th, .typo-table td .typo table caption {
        padding: 0.5em;
      }
      #fork{ display:none; }
    }

    ol.toc::before {
      content: '目录';
      font-size: 1.3em;
      border-left: 5px solid #999;
      padding: 2px 5px 2px 15px;
    }
    ol.toc {
        background: #fff;
        overflow: hidden;
        border: 1px solid #efefef;
        color: #999;
        margin-left: 0;
        margin-bottom: 10px;
    }

    ol.toc li {
      padding: 2px 5px 2px 20px;
    }

    ol.toc ol {
      list-style: circle;
      padding: 0px 0px 0px 0px;
      margin-bottom: 0px;
    }

    ol.related::before {
      content: '相关文章';
      font-size: 1.3em;
      border-left: 5px solid #999;
      padding: 2px 5px 2px 15px;
    }
    ol.related {
        background: #fff; 
        overflow: hidden;
        color: #999;
        margin-top: 40px;
        margin-left: 0;
        margin-bottom: 10px;
    }

    ol.related li {
      padding: 2px 5px 2px 20px;
    }
    .official-account-wrapper {
      width: 200px;
      margin-left: 0px;
      padding: 70px 5px 10px 20px;
    }
    .official-account-wrapper img {
      width: 150px;
      height: 150px;
      border-width:2px;
      border-color:#999;
    }
</style>

<link rel="stylesheet" href="/css/iconfont.css">


<link rel="stylesheet" href="/css/syntax.css">

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?fedff94a2e83a6e2a4d203129a3272e8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>    
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-156665333-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'UA-156665333-1');
</script>
  <meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/feed.xml" title="有疑说" type="application/atom+xml">
</head>
  <body>
    <div id = "wrapper">
    <div class="nav-toggle"><i class="fa fa-bars fa-2x"></i> Herring Cove </div>
<div class="navbar navbar-default" role="navigation">
    <div class="container">
        <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </button>
        <p class="navbar-brand">有疑说 </p>
        </div>
        <div class="navbar-collapse collapse">
        <ul class="nav navbar-nav">
          <li><a href="/subjects">主题</a></li>
          <li><a href="/archives">归档</a></li>
          <li><a href="/links">链接</a></li>
          <li><a href="/about">关于</a></li>
        </ul>
        </div><!--/.nav-collapse -->
    </div>
</div>

<!-- Sidebar -->
<div id="sidebar-wrapper">
  <ul class="sidebar-nav">
    <li class="sidebar-brand"><a href="/"><div class="brand">有疑说 </div></a><div>博学、慎思、明辨、笃行</div></li>
    <hr />
          <li><a href="/subjects">主题</a></li>
          <li><a href="/archives">归档</a></li>
          <li><a href="/links">链接</a></li>
          <li><a href="/about">关于</a></li>
    <hr />
    <div id="social-wrapper">
      <li> <a href="http://weibo.com/CyningSun"  target="_blank"><i class="iconfont icon-weibo"></i> @Weibo</a></li>
      <li> <a href="mailto:cyningsun@gmail.com" ><i class="iconfont icon-gmail"></i> Gmail</a> </li>
      <li> <a href="https://www.douban.com/people/cyningscut" target="_blank"><i class="iconfont icon-douban"></i> Douban</a></li>
      <li> <a href="https://github.com/cyningsun" target="_blank"><i class="iconfont icon-github"></i> Github</a> </li>
      <li><a href="/feed.xml" target="_blank"><i class="iconfont icon-rss"></i> RSS</a></li>
    </div>
    <div class="official-account-wrapper" align="center">
      <img src="/img/official-account-qrcode.jpg" alt="official-account-qrcode"/>
      <div>关注公众号</div>
      </div>
  </ul>
</div>
      <div class="container">
        <div id="article"  class="typo">
    <h1>Redis 延迟毛刺问题定位-软中断篇</h1><br/>
    
    <div class="timestamp-info" style="font-family: 'PingFang SC', Verdana, 'Helvetica Neue', 'Microsoft Yahei', 'Hiragino Sans GB', 'Microsoft Sans Serif', 'WenQuanYi Micro Hei', sans-serif; font-weight: 100; font-size: 14px; color: #666; margin-bottom: 10px; padding: 5px; text-align: center;">
        First Published: 2024-09-17
         | 
        Last Revised: 2025-10-30
    </div>
    
    <h2 id="tagline" class="serif"></h2>
    <div class="post">
        
    <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-text">背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D"><span class="toc-text">问题定位</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%A9%E5%B0%8F%E8%8C%83%E5%9B%B4"><span class="toc-text">缩小范围</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E7%94%A8%E9%93%BE%E8%B7%AF%E5%88%86%E6%9E%90"><span class="toc-text">调用链路分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%A4%8D%E7%9B%98"><span class="toc-text">问题复盘</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#MTR-%E5%8E%9F%E7%90%86"><span class="toc-text">MTR 原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RSS-%E7%A1%AC%E4%BB%B6%E5%A4%9A%E9%98%9F%E5%88%97"><span class="toc-text">RSS 硬件多队列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RPS-%E8%BD%AF%E4%BB%B6%E5%A4%9A%E9%98%9F%E5%88%97"><span class="toc-text">RPS 软件多队列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E6%9C%BA%E4%B8%A2%E5%8C%85%E7%8E%AF%E8%8A%82"><span class="toc-text">主机丢包环节</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol>
 
        <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>该问题发生于去年的十二月份，业务发现部分线上集群再次出现延迟毛刺。只是现象与上次不同：</p>
<ol>
<li>延迟出现的时间点不固定，逐渐发生变化</li>
<li>延迟较为规律的每小时出现一次</li>
<li>持续时间大概有差不多十分钟，不是一瞬间</li>
</ol>
<p><img src="/images/redis-latency-irqoff/Redis%20%E5%BB%B6%E8%BF%9F%E6%AF%9B%E5%88%BA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-%E8%BD%AF%E4%B8%AD%E6%96%AD%E7%AF%87-20240409133418.jpg"></p>
<h3 id="问题定位"><a href="#问题定位" class="headerlink" title="问题定位"></a>问题定位</h3><p>相比八月份出现类似问题的状态，整个系统的监控系统和定位能力更加完备，包含主调和被调耗时以及耗时百分位。</p>
<h4 id="缩小范围"><a href="#缩小范围" class="headerlink" title="缩小范围"></a>缩小范围</h4><p>通过 Redis Proxy 主调 Redis 的监控看板，可以观察到明显的耗时毛刺。</p>
<p><img src="/images/redis-latency-irqoff/Redis%20%E5%BB%B6%E8%BF%9F%E6%AF%9B%E5%88%BA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-%E8%BD%AF%E4%B8%AD%E6%96%AD%E7%AF%87-20240409132002.jpg"></p>
<p> 然后，使用 ebpf 抓取 Redis 执行耗时也并未发现慢速命令，说明并非是业务使用命令导致的。</p>
<p> 基于以上手段以及整体架构很容易将问题范围缩小到：Redis Proxy 调用 Redis 链路。 </p>
<p><img src="/images/redis-latency-irqoff/Redis%20%E5%BB%B6%E8%BF%9F%E6%AF%9B%E5%88%BA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-%E8%BD%AF%E4%B8%AD%E6%96%AD%E7%AF%87-20240409133828.png"></p>
<p>接下来，我们将注意力转向了网络层面。</p>
<h4 id="调用链路分析"><a href="#调用链路分析" class="headerlink" title="调用链路分析"></a>调用链路分析</h4><p>首先，在问题出现的时间点，使用 MTR 检查网络丢包和延迟，一切正常。</p>
<p>再次，检查问题集群的上层交换机，一切正常。</p>
<p>最后，检查某个主机的监控时，终于发现了与延迟匹配的指标。</p>
<p><img src="/images/redis-latency-irqoff/Redis%20%E5%BB%B6%E8%BF%9F%E6%AF%9B%E5%88%BA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-%E8%BD%AF%E4%B8%AD%E6%96%AD%E7%AF%87-20240409135042.jpg"></p>
<p>经网络团队检查，看到机器上 rx missed_errors 比较高</p>
<pre><code class="hljs sh">$&gt; ethtool -S eno2 |grep rx |grep error
IX_errors: 0
Ix_over_errors: 0
Ix_crc_errors: o
IX_ frame_errors: 0
IX_fifo_errors: 0
rx missed_errors: 2071867
IX_length_errors: 0
Ix_long_length_errors: 0
rx_short_length_errors: 0</code></pre>

<p>找了一台机器调高 ring buffer 大小为 4096。</p>
<pre><code class="hljs sh">$&gt; ethtool -G &lt;nic&gt; rx 4096  <span class="hljs-comment"># 增加 RX 队列的大小到 4096</span></code></pre>

<pre><code class="hljs sh">$&gt; ethtool -g eno2 <span class="hljs-comment"># 查询网卡队列长度</span>
Ring parameters <span class="hljs-keyword">for</span> eno2:
Pre-<span class="hljs-built_in">set</span> maximums:
RX:		4096
RX Mini:	0
RX Jumbo:	0
TX:		4096
Current hardware settings:
RX:		4096
RX Mini:	0
RX Jumbo:	0
TX:		512</code></pre>

<p>持续观察一天，问题不再复现。</p>
<p>网络团队的同事判断是业务层有周期性阻塞性的任务，导致软中断线程收包阻塞，rx drop 是因为软中断线程收包慢导致的。 使用字节跳动团队的 <a target="_blank" rel="noopener" href="https://github.com/bytedance/trace-irqoff">trace-irqoff</a>，可以观测到以下输出</p>
<pre><code class="hljs sh">$&gt; <span class="hljs-built_in">cat</span> /proc/trace_irqoff/trace_latency
softirq: cpu: 2
	COMMAND: ethtool PID: 95974 LATENCY: 29+ms trace_irqoff_record+0x2a6/0x330 [trace_irqoff] trace_irqoff.
	_hrtimer_handler+0xcb/0xd4 [trace_irqoff]
	__hrtimer_run_queues+0xca/0x1d0
	hrtimer_interrupt+0x109/0x230 __sysvec_apic_timer_
	_interrupt+0x61/0xd0
	sysvec_apic_timer_interrupt+0x77/0x90
	asm_sysvec_apic_timer_interrupt+0x12/0x20
	ixgbe_read_reg+0x33/0xf0 [ixgbe]
	ixgbe_lower_i2c_clk+0x4a/0x60 [ixgbe]
	ixgbe_clock_in_i2c_byte+0xc0/0x120 [ixgbe]
	ixgbe_read_i2c_byte_generic_int+0x20f/0x270 [ixgbe]
	ixgbe_read_12c_byte_generic+0x1b/0x20 [ixgbel
	ixgbe_read_i2c_eeprom_generic+0x21/0x30 [ixgbe]
	ixgbe_get_module_eeprom+0x6f/0x100 [ixgbe]
	ethtool_get_module_eeprom_call+0x5b/0x70
	ethtool_get_any_eeprom+0xf9/0x1b0
	dev_ethtool+0x1e9a/0x2980
	dev_ioctl+0x145/0x530
	sock_do_ioctl+0xa9/0x100
	sock_ioctl+0xef/0x310
	__x64_sys_ioctl+0x91/0xc0
	do_syscall_64+0x5c/Oxc0
	entry_SYSCALL_64_after_hwframe+0x44/Oxae

	COMMAND: ksoftirqd/2 PID: 28 LATENCY: 227ms trace_irqoff_record+0x2a6/0x330 [trace_irqoff]
	trace_irqoff_timer_handler+0x48/0x80 [trace_irqoff]
	call_timer_fn+0x2e/0x110
	run_timer_softirq+0x36e/0x480
	__do_softirq+0xf0/0x33e
	run_ksoftirqd+0x2b/0x40
	smpboot_thread_fn+0xba/0x150
	kthread+0x12a/0x150
	ret_from_fork+0x22/0x30</code></pre>

<p>看到下面的进程 ksoftirqd&#x2F;2 的栈，延迟时间是 227ms。ksoftirqd 进程是 kernel 中处理 softirq 的进程。因此这段栈是没有意义的，因为元凶已经错过了。所以此时，可以借鉴上面的栈信息，看到当 softirq 被延迟 29+ms 的时候，当前 CPU 正在执行的进程是 ethtool。ethtool 的 lantency 提示信息 <strong>29+ms</strong> 是阈值信息，并非实际 latency（所以后面添加一个 ‘+’ 字符，表示 latency 大于 29ms）。实际的 latency 是 ksoftirqd&#x2F;2 显示的 <strong>227ms</strong>。原来是有人用 ethtool 读 eeprom 导致网卡阻塞丢包了。</p>
<p>团队同事使用以下命令，扫描机器上可执行程序：</p>
<pre><code class="hljs sh">$&gt; find /usr/bin /usr/sbin /usr/local/bin /usr/local/sbin  -<span class="hljs-built_in">type</span> f -executable ! -path <span class="hljs-string">&quot;/usr/sbin/ethtool&quot;</span> -print0 | xargs -0 strings -f | grep -w <span class="hljs-string">&#x27;ethtool&#x27;</span>
/usr/bin/node-exporter: ethtool
/usr/bin/udevadm: ../src/shared/ethtool-util.c
...</code></pre>

<p>因为是问题是持续定时发生的，识别过滤出两个常驻后台的可执行程序，逐一确认。</p>
<p>经相关同事确认，故障出现的前一两天确实灰度了光模块监控，会调用 <code>ethtool -m</code> 读取光模块的信息。程序灰度时间与问题出现的时间一致，程序回滚之后问题恢复。原来是程序是被逐个机器遍历的远程调用完成数据抓取，并且根据上次完成的时间偏移固定的时间来启动下次数据抓取。也就解释了为何会出现背景中描述的毛刺特征。</p>
<h3 id="问题复盘"><a href="#问题复盘" class="headerlink" title="问题复盘"></a>问题复盘</h3><p>MTR 能探测主机丢包么？要回答这个问题首先要了解以下几个问题：</p>
<ol>
<li>MTR 是怎么探测是否有丢包的？</li>
<li>TCP 主机上是怎么负载均衡的 ？</li>
<li>主机有哪些环节可能导致丢包？</li>
</ol>
<h4 id="MTR-原理"><a href="#MTR-原理" class="headerlink" title="MTR 原理"></a>MTR 原理</h4><p>在使用 ICMP（TCP） 探测时，mtr 发送 ICMP ECHO（TCP SYN） 数据包到目标主机（的指定端口）。目标主机收到数据包后，会响应 ICMP ECHO REPLY（TCP SYN-ACK）数据包。mtr 记录下从发送数据包到接收到响应数据包之间的延迟，并将这些信息显示给用户。</p>
<p>当网络数据包到达网卡时，硬件中断会被触发，然后系统会调度 <code>ksoftirqd</code> 线程来处理数据包，进行协议栈的进一步处理。并在软中断上下文中完成 ICMP（TCP）协议响应（以及 TCP 的连接状态管理，如 SYN、ACK、FIN 等）。以 ICMP 为例，相关内核逻辑如下</p>
<pre><code class="hljs c++"><span class="hljs-comment">// https://elixir.bootlin.com/linux/v4.6/source/net/ipv4/icmp.c#L893</span>
<span class="hljs-comment">/*</span>
<span class="hljs-comment"> *	Handle ICMP_ECHO (&quot;ping&quot;) requests.</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> *	RFC 1122: 3.2.2.6 MUST have an echo server that answers ICMP echo</span>
<span class="hljs-comment"> *		  requests.</span>
<span class="hljs-comment"> *	RFC 1122: 3.2.2.6 Data received in the ICMP_ECHO request MUST be</span>
<span class="hljs-comment"> *		  included in the reply.</span>
<span class="hljs-comment"> *	RFC 1812: 4.3.3.6 SHOULD have a config option for silently ignoring</span>
<span class="hljs-comment"> *		  echo requests, MUST have default=NOT.</span>
<span class="hljs-comment"> *	See also WRT handling of options once they are done and working.</span>
<span class="hljs-comment"> */</span>

<span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">bool</span> <span class="hljs-title">icmp_echo</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
	<span class="hljs-keyword">struct</span> <span class="hljs-title class_">net</span> *net;

	net = <span class="hljs-built_in">dev_net</span>(<span class="hljs-built_in">skb_dst</span>(skb)-&gt;dev);
	<span class="hljs-keyword">if</span> (!net-&gt;ipv4.sysctl_icmp_echo_ignore_all) &#123;
		<span class="hljs-keyword">struct</span> <span class="hljs-title class_">icmp_bxm</span> icmp_param;

		icmp_param.data.icmph	   = *<span class="hljs-built_in">icmp_hdr</span>(skb);
		icmp_param.data.icmph.type = ICMP_ECHOREPLY;
		icmp_param.skb		   = skb;
		icmp_param.offset	   = <span class="hljs-number">0</span>;
		icmp_param.data_len	   = skb-&gt;len;
		icmp_param.head_len	   = <span class="hljs-built_in">sizeof</span>(<span class="hljs-keyword">struct</span> icmphdr);
		<span class="hljs-built_in">icmp_reply</span>(&amp;icmp_param, skb);
	&#125;
	<span class="hljs-comment">/* should there be an ICMP stat for ignored echos? */</span>
	<span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;
&#125;</code></pre>

<blockquote>
<p>与 TCP 协议相关的定时器（例如 TCP 重传定时器），是通过 <code>kworker</code> 内核线程处理的。定时器触发时，内核线程会进行重传、ACK 处理等操作。</p>
</blockquote>
<h4 id="RSS-硬件多队列"><a href="#RSS-硬件多队列" class="headerlink" title="RSS 硬件多队列"></a>RSS 硬件多队列</h4><p>多数主机网卡都支持 RSS（Receive Packet Steering）功能，网卡会有多个接受队列，旨在根据接收到的数据包计算哈希值，并将包分配到不同的接收队列，以便多个 CPU 核心并行处理数据包。查看网卡队列数量：</p>
<pre><code class="hljs sh">$ ethtool -l eno1
Channel parameters <span class="hljs-keyword">for</span> eno1:
Pre-<span class="hljs-built_in">set</span> maximums:
RX:		0
TX:		0
Other:		1
Combined:	128
Current hardware settings:
RX:		0
TX:		0
Other:		1
Combined:	48    <span class="hljs-comment"># 启用的网卡队列数</span></code></pre>

<p>RSS 的负载均衡通常基于数据包的 <strong>五元组</strong>，包括：</p>
<ul>
<li>源 IP 地址</li>
<li>目的 IP 地址</li>
<li>源端口（TCP&#x2F;UDP）</li>
<li>目的端口（TCP&#x2F;UDP）</li>
<li>协议类型（TCP&#x2F;UDP&#x2F;<strong>ICMP</strong>）</li>
</ul>
<p>当使用 MTR 进行探测时，可以指定所使用的协议类型 <code>ICMP</code> 或 <code>TCP</code>。RSS 在处理 ICMP 包时，只会基于三元组：</p>
<ul>
<li><strong>源 IP 地址</strong></li>
<li><strong>目的 IP 地址</strong></li>
<li><strong>协议类型（ICMP）</strong></li>
</ul>
<p>当 RSS 处理 ICMP 包时，网卡会基于这三元组计算一个哈希值，随后将该哈希值与网卡的队列数量进行取模运算，决定数据包被分配到哪个硬件队列，所以<strong>具有相同源 IP、目的 IP 和协议的 ICMP 流量通常会被固定分配到某个特定的队列</strong>。</p>
<p>对比来看，TCP 协议会不断更改请求包的来源端口，进而可以覆盖所有队列。</p>
<p><img src="/images/redis-latency-irqoff/Redis%20%E5%BB%B6%E8%BF%9F%E6%AF%9B%E5%88%BA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-%E8%BD%AF%E4%B8%AD%E6%96%AD%E7%AF%87-20240917205825-1.jpeg"></p>
<p>对于低概率的丢包事件，除了考虑负载均衡，还要考虑探测的频率。 MTR 默认的发包频率是 1 秒，root 用户可以通过 <code>-i</code> 参数来指定 0 到 1 之间的值以提高探测频率，并且保障一定的时长来检测丢包。抑或使用 <code>hping3</code> 直接向终点 IP 发送数据包，而不对中间的路由跳数进行探测。</p>
<pre><code class="hljs sh">$&gt; hping3 -S  10.129.114.203 -p 80
HPING 10.129.114.203 (bond0.1000 10.129.114.203): S <span class="hljs-built_in">set</span>, 40 headers + 0 data bytes
len=46 ip=10.129.114.203 ttl=61 DF <span class="hljs-built_in">id</span>=0 sport=80 flags=RA <span class="hljs-built_in">seq</span>=0 win=0 rtt=3.7 ms
len=46 ip=10.129.114.203 ttl=61 DF <span class="hljs-built_in">id</span>=0 sport=80 flags=RA <span class="hljs-built_in">seq</span>=1 win=0 rtt=3.7 ms
len=46 ip=10.129.114.203 ttl=61 DF <span class="hljs-built_in">id</span>=0 sport=80 flags=RA <span class="hljs-built_in">seq</span>=2 win=0 rtt=7.6 ms</code></pre>

<h4 id="RPS-软件多队列"><a href="#RPS-软件多队列" class="headerlink" title="RPS 软件多队列"></a>RPS 软件多队列</h4><p>对于不支持多队列或队列数显著少于 CPU 数的主机（如：基于 <a target="_blank" rel="noopener" href="https://github.com/intel/ethernet-linux-ixgbe">82598</a> 网络连接的 Intel 网卡仅支持 16 个队列），需要开启软件实现的多队列，即 RPS。RPS 类似的基于数据包的<strong>五元组</strong>（源 IP、目的 IP、源端口、目的端口、协议类型），将接收队列的网络数据包分发到多个 CPU 核的 backlog 队列。再由各个 CPU 上软中断线程将数据包交给 L2、L3、L4 协议解析，最终到达 socket 缓存区。如此旧避免网络处理集中在单个（部分） CPU 核上，从而造成瓶颈或资源不平衡。整体流程参考：<a href="https://www.cyningsun.com/04-24-2023/monitoring-and-tuning-the-linux-networking-stack-recv-cn.html#Receive-Packet-Steering-RPS">译｜Monitoring and Tuning the Linux Networking Stack - Receiving Data</a></p>
<p><img src="/images/redis-latency-irqoff/Redis%20%E5%BB%B6%E8%BF%9F%E6%AF%9B%E5%88%BA%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-%E8%BD%AF%E4%B8%AD%E6%96%AD%E7%AF%87-20240914205807-1.jpeg"></p>
<h4 id="主机丢包环节"><a href="#主机丢包环节" class="headerlink" title="主机丢包环节"></a>主机丢包环节</h4><p>对于本次故障的场景，由于没有连接异常断开，所有长连接均处于 ESTABLISHED 状态。那么，连接建立阶段的丢包的因素就可以不用考虑。因此就可以重点考虑最关键的三个队列是否溢出：RX 队列、backlog 队列、Socket 接收缓存区。</p>
<p>由于 TCP 是面向连接的协议，有流控机制，当接收缓冲区满时，发送方会停止发送数据，直到缓冲区有空闲空间为止，因此 TCP 丢包的概率较小。其他两个队列的丢包情况，则可以通过 ethtool 查看，即上文提及的排查命令。</p>
<p>推而广之，怎么覆盖上层协议栈的丢包呢？使用 <code>netstat -s</code> 命令，可以查看网络协议栈各层的详细统计信息，包括 IP、TCP、UDP、ICMP。如果具体到定位丢包原因，则需要其他可观测性的工具。</p>
<p>考虑到数据包处理路径的复杂度，Linux 内核从 5.15 版本开始引入了 <code>skb_drop_reason</code> 以追溯根因。它通过为丢包原因提供一组标准化的枚举值 <a target="_blank" rel="noopener" href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/net/dropreason-core.h?h=v6.4-rc1#n88"><code>skb_drop_reason enum</code></a> ，让开发者能够更清楚地看到丢包的具体原因，并可以通过工具在 <code>skb:kfree_skb</code> 跟踪点上添加探测器来监控包丢弃情况。</p>
<pre><code class="hljs sh">$&gt; perf record -e skb:kfree_skb curl https://localhost
curl: (7) Failed to connect to localhost port 443: Connection refused
[ perf record: Woken up 1 <span class="hljs-built_in">times</span> to write data ]
[ perf record: Captured and wrote 0.040 MB perf.data (4 samples) ]

$&gt; perf script
            curl 163406 [036] 7681948.959483: skb:kfree_skb: skbaddr=0xffff8a68e752cc00 protocol=0 location=0xffffffff8efced8e reason: NOT_SPECIFIED
            curl 163406 [036] 7681948.959574: skb:kfree_skb: skbaddr=0xffff8a68ed61d2e0 protocol=34525 location=0xffffffff8f0177e9 reason: NOT_SPECIFI&gt;
            curl 163406 [036] 7681948.959728: skb:kfree_skb: skbaddr=0xffff8a68ed61d2e0 protocol=2048 location=0xffffffff8ef64c2b reason: NO_SOCKET
            curl 163406 [036] 7681948.959779: skb:kfree_skb: skbaddr=0xffff8a68ed61d2e0 protocol=2048 location=0xffffffff8ef64c2b reason: NO_SOCKET</code></pre>

<p>腾讯、字节等厂在此基础上进行了更加友好的封装：<a target="_blank" rel="noopener" href="https://github.com/OpenCloudOS/nettrace">nettrace</a>、<a target="_blank" rel="noopener" href="https://github.com/bytedance/netcap">netcap</a></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>针对该类偶现问题，由于短期波动对整体趋势影响较小，抓取现场获取瞬时值（即时值）的难度颇高。相反，累计值能够保存历史记录，并且随着时间的推移，累计值的数据量可能变得非常大，更适合分析。</p>
<p><strong>本文作者</strong> ： cyningsun<br /><strong>本文地址</strong> ： <a href="https://www.cyningsun.com/09-17-2024/redis-latency-irqoff.html">https://www.cyningsun.com/09-17-2024/redis-latency-irqoff.html</a> <br /><strong>版权声明</strong> ：本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>

    </div>
    
<div class="post-subject">
    
    <a href="/subjects#Performance" rel="category"># Performance</a>
    
</div>


    



  <ol class="related">
      
            <li><span><a href="/04-13-2025/flamegraph-summary.html">Flame Graph 机制小结</a></span></li>
          
            <li><span><a href="/12-22-2023/redis-latency-spike.html">记一次 Redis 延时毛刺问题定位</a></span></li>
          
            <li><span><a href="/10-27-2020/thinking-clearly-about-performance-cn-part-two.html">译｜Thinking Clearly about Performance (Part 2)</a></span></li>
          
            <li><span><a href="/10-21-2020/thinking-clearly-about-performance-cn-part-one.html">译｜Thinking Clearly about Performance (Part 1)</a></span></li>
          
  </ol>


    <ul class="pager">
     
     <li class="next"><a href="/12-11-2024/linux-page-cache-minibook-cn.html">Newer &rarr;</a></li>
    
    
    <li class="previous"><a href="/06-27-2024/iocost-block-io-control-for-containers-in-datacenters-cn.html">&larr; Older</a></li>
    
</ul>
</div>

<div id="comment"  class="typo">
			<!-- Comment BEGIN -->
      <script src="https://utteranc.es/client.js"
            repo="cyningsun/blog-sidecar"
            issue-term="title"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>


<!-- Comment END -->
</div>
      </div>
      <div class="container">
  <footer>
    <p class="text-muted credit">Copyright ©2025 cyningsun
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <a href="  https://www.cyningsun.com">Powered by Hexo</a></p>
  </footer>
</div>

  <script src='https://unpkg.com/mermaid@8.6.4/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'neutral'});
    }
  </script>

    </div>
    <!-- Bootstrap core JavaScript-->

<script src="/js/jquery-1.10.2.min.js"></script>


<script src="/js/bootstrap.min.js"></script>


<script src="/js/hc.js"></script>

<script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

<script src="/js/syntax.js"></script>

  </body>
</html>
