<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>有疑说</title>
  
  <subtitle>博学、慎思、明辨、笃行</subtitle>
  <link href="https://www.cyningsun.com/feed.xml" rel="self"/>
  
  <link href="https://www.cyningsun.com/"/>
  <updated>2023-03-29T16:10:44.438Z</updated>
  <id>https://www.cyningsun.com/</id>
  
  <author>
    <name>cyningsun</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>TCP/IP 网络传输</title>
    <link href="https://www.cyningsun.com/03-30-2023/network-transmission.html"/>
    <id>https://www.cyningsun.com/03-30-2023/network-transmission.html</id>
    <published>2023-03-29T16:00:00.000Z</published>
    <updated>2023-03-29T16:10:44.438Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>作者序</strong></p><p>本文所谈的绝大部分内容在众多文章中都有讲到，再复述一遍并非本意。本文的目的是了解各种工具、定量分析网络状态；当遇到网络性能问题的时候，根据原理和出现的可能性，有的放矢。</p><ol><li>MSS vs MTU 有什么区别？</li><li>发送窗口 vs 接收窗口 vs 拥塞窗口 ？</li><li>RTT &amp; RTO 是什么含义</li><li>哪些常见的工具可以探查网络状态？</li><li>如何定量分析延迟、吞吐等性能问题？</li></ol><p>其他说明：</p><ul><li>文中 Wireshark 相关的使用，来源于 《Wireshark 网络分析就这么简单》、《Wireshark 网络分析的艺术》</li></ul></blockquote><h3 id="IP-协议与机制"><a href="#IP-协议与机制" class="headerlink" title="IP 协议与机制"></a>IP 协议与机制</h3><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234233.png" alt=""></p><h4 id="MTU"><a href="#MTU" class="headerlink" title="MTU"></a>MTU</h4><p>应用程序发送到协议栈的数据长度是由应用程序本身决定的。不同的应用程序有不同的实现方式，有些应用程序一次性发送所有数据，而有些应用程序则会逐字节或逐行发送数据。最终，发送到协议栈的数据量由应用程序决定，协议栈无法控制这种行为。</p><p>如果协议栈一接收到数据就立即发送，可能会发送大量的小数据包，导致网络效率降低。因此，需要在累积一定数量的数据后再发送。但是，累积多少数据才能发送取决于操作系统的种类和版本。</p><p>现在，假设有一个需要写入的操作比较大，例如 4000 字节，那么 TCP 层会如何处理呢？是否只需添加 TCP 标头并将其发送到网络层呢？</p><p>答案是否定的。因为网络对数据包大小有限制，最大传输单元（MTU，Maximum transmission unit）指的是网络可以传输的最大数据包大小。大多数网络的 MTU 为 1500 字节，这意味着 4000 字节的数据包要么会被丢弃，要么会被分片。如果数据包被丢弃，传输将彻底失败。如果数据包被分片，将会导致传输效率降低。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234233-1.png" alt=""></p><p>那被切分的包又该怎么重组呢？</p><p>仍然以一个数据包大小为 4000 字节，MTU 为 1500 字节为例，当发送端的 IP 层将该数据包发送到网络层时，会检查数据包大小是否超过 MTU 限制。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234233-2.png" alt=""></p><p>如果超过了，IP 层会将该数据包分成三个分片，分别是：</p><ul><li>第一个分片，偏移量为 0，大小为 1500 字节；</li><li>第二个分片，偏移量为 1480（前一个分片占去了 20 字节的 IP 头部空间），大小为 1500 字节；</li><li>第三个分片，偏移量为 2960（前两个分片占去了 2960 字节的空间），大小为 1020 字节。</li></ul><p>分片的重组需要依据 IP Header 中的标识（Identification）和标志（Flags）字段来完成。标识字段用于标识分片属于哪个数据报，而标志字段用于标识分片是否允许再分片和是否为最后一片。具体而言，同一个数据报的所有分片都应该具有相同的标识字段值，而 DF（Don’t Fragment，不分片）和 MF（More Fragments，还有更多分片）标志则用于标识分片是否允许再分片和是否为最后一片。</p><p>在接收端，当接收到这些分片时，它们会根据标识字段进行分类。如果一个数据报的所有分片都到达了接收端，那么接收端就可以使用偏移量和分片大小将这些分片按正确的顺序重新组装成原始数据包。如果某个分片没有到达接收端，那么接收端会等待一段时间，如果超时后仍然没有收到该分片，那么接收端就会向发送端发送一个请求重传的消息。</p><p>假设客户端和服务器的 MTU 大小分别为 1500 和 1200 字节。在这种情况下，客户端最大能发出多少字节的包呢？</p><p>根据上面的结论，发包的大小是由 MTU 较小的一方决定的，因此客户端最大只能发送 1200 字节的包。如果客户端尝试发送 1500 字节的包，那么这个包将被分片成两个部分，每个部分的大小分别为 1200 字节和 300 字节。如果 DF 标志位设置为 1，表示不允许分片，因此这个数据包会则会被丢弃，传输失败。</p><h4 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h4><p>每个 IP 包都有一个 TTL 字段，表示该包的生存时间。每当一个 IP 包经过一个路由器，TTL 字段就会减 1，当 TTL 为 0 时，该包就会被丢弃。根据 TTL 的特性，只需翻出网络拓扑图，就能大概知道该包是哪台设备发出。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230329002451.png" alt=""></p><p>除此之外，TTL 还可以用于检测网络劫持和请求延迟问题。如果我们怀疑网络连接被劫持，可以通过检查 TTL 值来确定是否存在额外的跳数。而如果请求延迟较高，也可以通过检查 TTL 值来确定是否存在较远的跳数，从而进一步分析网络瓶颈所在。</p><h3 id="TCP-协议与机制"><a href="#TCP-协议与机制" class="headerlink" title="TCP 协议与机制"></a>TCP 协议与机制</h3><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234233-4.png" alt=""></p><h4 id="MSS"><a href="#MSS" class="headerlink" title="MSS"></a>MSS</h4><p>由于 IP 层 MTU 的存在，TCP 协议需要控制 MTU，从而避免数据过大而需要分包传输的问题，提高网络传输效率。</p><p>在 TCP 连接建立过程中，客户端和服务器会互相通告各自的 MSS（Maximum Segment Size，最大分段大小），MSS 是指 TCP 数据段中数据部分的最大长度。MSS 加上 TCP 头和 IP 头的长度，就是双方可以承载的最大 MTU。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234233-5.png" alt=""></p><h4 id="RTT"><a href="#RTT" class="headerlink" title="RTT"></a>RTT</h4><p>RTT（往返时延）是指从发送方发送数据到发送方接收到来自接收方的确认消息所经过的时间。在网络通信中，RTT 时延不仅与<strong>链路的传播时间</strong>有关，还包括路由器等网络中间节点的<strong>缓存和排队时间</strong>，以及<strong>末端系统的处理时间</strong>。</p><p>尽管在同一条链路上，报文的传输时间和应用处理时间相对固定，但网络设备和末端系统的网络拥堵情况下，排队时间的增加会导致 RTT 时延波动。</p><p>此外，<strong>流量负载均衡</strong>的存在会导致选择的传输路径和经过的网络设备不同，即使是同一个上下游服务的请求，也会出现 RTT 时延的差异。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234233-6.png" alt=""></p><blockquote><p>MTR（My Traceroute）是一种网络诊断工具，可以通过在连续的时间间隔内将网络节点的 traceroute（跟踪路由）操作的结果显示在同一屏幕上，从而提供更详细的网络信息。</p><p>使用 MTR 可以帮助我们了解数据包在网络中的路径和每个跃点的 RTT，从而更方便地定位网络问题。例如，如果我们发现某些数据包延迟较高，我们可以使用 MTR 查看这些数据包的路径和每个跃点的 RTT，以确定延迟出现的具体位置。此外，MTR 还可以通过连续的监测，提供有关网络稳定性和性能的有用信息，从而帮助我们优化网络性能</p></blockquote><h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><p>在我们日常生活中，排队和拥挤现象时常发生，如医院看病、邮局等候服务等。除了实际排队之外，还有一种无形的排队，即网络拥堵导致的网速变慢。</p><p>为了减少排队现象，增加服务窗口是一个可行的解决方案，但这也会增加服务成本。反之，缩小服务窗口可以提高窗口的利用率，降低成本，但会增加用户排队等待的时间。这两者是相互矛盾的。</p><p>为了在保证用户满意度（响应时间）的前提下，最大限度地挖掘系统潜力、提高利用率（控制成本），TCP 通过窗口（发送窗口/拥塞窗口）大小来实现这一目标。</p><h5 id="发送窗口"><a href="#发送窗口" class="headerlink" title="发送窗口"></a>发送窗口</h5><p>由于无法确认接收方是否能及时接收数据包，TCP 传输中不适合每发一个数据包就停下来等待确认，因为这样传输效率太低。最好的方式是一次性将所有数据包发送出去，然后一起等待确认。但是，实际情况存在一些限制：</p><ul><li>接收方的缓存（接收窗口）可能无法一次性接收所有数据；</li><li>网络的带宽也不一定足够大，一次性发送过多的数据包可能导致数据丢失。</li></ul><p>因此，在 TCP 传输中，发送窗口通过限制发送数据包的数量来平衡传输效率和数据可靠性。<strong>发送窗口的大小计算公式为 wnd = min(rwnd, cwnd * mss)，其中 rwnd 表示接收方告知的接收窗口大小，cwnd 表示发送方的拥塞窗口大小</strong>。在此限制范围内，尽可能多地发送数据包，一次可以发送的数据量即为 TCP 发送窗口。</p><p>发送窗口大小对传输性能的影响非常大。下图显示了发送窗口大小为 1 个 MSS（即每个 TCP 包所能携带的最大数据量）和 2 个 MSS 时的差别。在相同的往返时间内，发送窗口大小为 2 个 MSS 时，传输的数据量是发送窗口大小为 1 个 MSS 的两倍。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230329004649.png" alt=""></p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230329004710.png" alt=""></p><p>在实际应用中，发送窗口通常可以达到数十个 MSS 的大小，因此发送窗口的大小会对 TCP 传输的效率和可靠性产生巨大影响。</p><blockquote><p><strong>发送窗口</strong> VS <strong>MSS</strong></p><p>发送窗口决定了一口气能发多少字节，而 MSS 决定了这些字节要分多少个包发完。例如：</p><p>发送窗口为 16000 字节，MSS 为 1000 字节时，需要发送 16000/1000=16 个包；而如果 MSS 等于 8000，那要发送的包数就是 16000/8000=2。</p></blockquote><h5 id="接收窗口"><a href="#接收窗口" class="headerlink" title="接收窗口"></a>接收窗口</h5><p>在 TCP 协议中，接收窗口是一项非常重要的参数，它决定了发送方在一个确定时间内可以发送多少数据。</p><p>在 TCP 协议初期，网络带宽非常有限，因此 TCP 的最大接收窗口被定义为 65535 字节。但随着网络带宽的提高，这个值已经无法满足现代网络传输的需求了。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234233-8.png" alt=""></p><blockquote><ul><li>如果抓包时没有抓到三次握手，Wireshark 就不知道该如何计算，所以有时候会很莫名地看到一些极小的接收窗口值。</li><li>如果防火墙识别不了 Window Scale，因此对方无法获得 Shift count，最终导致严重的性能问题。</li></ul></blockquote><p>1992 年，RFC 1323 提出了一种解决方案，即在三次握手时向对方发送自己的 Window Scaling 信息，Window Scaling 是一个 2 的指数，通过它可以计算出实际的 TCP 接收窗口大小。这个方案的好处是可以不需要修改 TCP 头的设计。</p><pre><code class="hljs bash"><span class="hljs-comment"># 查看 Linux 内核 TCP Window Scaling</span>sysctl net.ipv4.tcp_window_scaling&gt; net.ipv4.tcp_window_scaling = 1<span class="hljs-comment"># 设置 Linux 内核 TCP Window Scaling</span>sudo sysctl -w net.ipv4.tcp_window_scaling=0&gt; net.ipv4.tcp_window_scaling = 0</code></pre><h5 id="拥塞窗口"><a href="#拥塞窗口" class="headerlink" title="拥塞窗口"></a>拥塞窗口</h5><p>拥塞控制的基本思想是发送方通过维护一个虚拟的拥塞窗口，控制数据包的发送速度，以防止网络拥塞。</p><ol><li>在连接建立初期，发送方对网络状况一无所知。由于一次发送过多数据可能会遭遇拥塞，因此发送方需要将拥塞窗口的初始值设置得很小。根据 RFC（请求评论文档）的建议，初始值为 2 个、3 个或者 4 个 MSS（最大报文段长度），具体取决于 MSS 的大小。</li><li>在慢启动过程中，拥塞窗口大小随着时间的推移而逐渐增加。此时，传输速度比较快，触碰拥塞点的风险也增加。因此，不能继续采用翻倍的慢启动算法，而是要缓慢增加拥塞窗口大小。根据 RFC 的建议，在每个往返时间中增加 1 个 MSS。例如，如果发送了 16 个 MSS 并得到全部确认，则拥塞窗口大小增加到 16+1=17 个 MSS。随后，拥塞窗口大小会增加到 18、19 等，这个过程称为拥塞避免。</li><li>在慢启动过渡到拥塞避免的临界窗口值方面，需要根据之前是否发生过拥塞来确定。如果发生过拥塞，则应将该拥塞点作为参考。如果从未发生过拥塞，则可以选择一个较大的值，例如与最大接收窗口相等。</li></ol><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234233-9.png" alt=""></p><p><strong>具体怎么知道窗口多大会触发拥塞呢？</strong></p><p>假设我们要计算的是某个 TCP 连接的拥塞点，而在该连接中存在一连串重传包。首先，我们需要找到重传包序列中的第一个包，然后根据其 Seq 值找到其对应的原始包，进而计算出原始包发送时刻的在途字节数。因为网络拥塞发生在该原始包发送的时刻，因此该时刻的在途字节数大致代表了拥塞点的大小。</p><p>在途字节数的计算公式应该是：</p><blockquote><p>在途字节数 = Seq + Len - Ack</p></blockquote><p>其中，Seq 是指包的序列号，Len 是包的长度，Ack 是指确认号。</p><p>具体步骤：</p><ol><li>Wireshark 上单击 Analyze 菜单，再单击 Expert Info 选项，得到重传统计表。<img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234233-10.png" alt=""></li><li>点击 Apply 过滤之后得到了原始包 No. 1053<br><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234234.png" alt=""></li><li>选定 1053 号包，然后点击 Clear 清除过滤。可见上一个来自服务器端的包是 1051 号包<br><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234234-1.png" alt=""></li><li>利用上述公式，可知当时的在途字节数为 1012852（No.1053 的 Seq）+816（No.1053 的 Len）-910546（No.1051 的 Ack）=103122 字节。</li></ol><h4 id="重传"><a href="#重传" class="headerlink" title="重传"></a>重传</h4><p>在传输数据时，由于网络拥塞、硬件故障等原因导致数据包未能及时到达接收方，发送方会重新发送该数据包。</p><h5 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h5><p>在网络传输过程中，丢包是很常见的问题，不过有时候出现的丢包症状并不像严重拥塞时那么明显。一些因素如校验码不对可能导致单个包的丢失，或者只有少量的包丢失。当这些包的后续包能够正常到达接收方时，接收方会发现其 Seq 号比期望的大，为了提醒发送方重传这些包，接收方会每收到一个包就 Ack 一次期望的 Seq 号。当发送方接收到三个或以上的重复确认（Dup Ack）时，发送方便会意识到相应的包已经丢失，于是立即重传它。这个过程称为快速重传，与超时重传不同，它无需等待一段时间。</p><p>为什么要规定收到 3 个或以上的重复确认才会重传呢？这是因为网络包有时会乱序，乱序的包同样会触发重复的 Ack，但是为了乱序而重传却是不必要的。因为一般乱序的距离不会相差太大，比如 2 号包也许会跑到 4 号包后面，但不太可能跑到 6 号包后面。所以规定收到三个或以上的重复确认，可以在很大程度上避免因乱序而触发快速重传。</p><p>如下图所示，2 号包的丢失凑满了 3 个 Dup Ack，所以触发快速重传。而在右图中，2 号包跑到 4 号包后面，但因为凑不满 3 个 Ack，所以没有触发快速重传。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234234-2.png" alt=""></p><p>如果在拥塞避免阶段发生了快速重传，是否需要像发生超时重传一样处理拥塞窗口呢？</p><p>在拥塞避免阶段，如果发生了快速重传，是否需要像发生超时重传一样处理拥塞窗口呢？其实并没有必要。因为如果后续的包都能正常到达，那么说明网络并没有严重拥塞，只需要在接下来传输数据时减缓一些速度即可。</p><p>然而，有些人持有不同的观点。例如 RFC 5681 规定，在发生拥塞时还没被确认的数据量的 1/2（但不能小于 2 个 MSS）设为临界窗口值。然后将拥塞窗口设置为临界窗口值加 3 个 MSS，继续保留在拥塞避免阶段。这个过程被称为快速恢复，其拥塞窗口的变化可以用下图表示：</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234234-3.png" alt=""></p><h5 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h5><p>在网络中，发生拥塞后会影响到发送方，因为发送方发送的数据包可能无法像往常一样得到及时的确认。当无法收到确认时，发送方会等待一段时间来判断是否存在网络延迟。如果超过了一定时间仍然没有收到确认，发送方就会认为这些数据包已经丢失，只能通过重传来保证数据的正确性。这个过程被称为超时重传，而从发送原始数据包到重传该数据包的这段时间被称为 RTO。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234234-4.png" alt=""></p><p>在 Linux 内核编译时，RTO 的最小值就已被确定，默认值为：200 ms</p><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TCP_RTO_MAX ((unsigned)(120*HZ))</span><span class="hljs-meta">#<span class="hljs-keyword">define</span> TCP_RTO_MIN ((unsigned)(HZ/5))</span></code></pre><p>然而，超时重传对传输性能有严重的影响。</p><ul><li>首先，发送方在等待 RTO 的过程中不能传输数据，相当于浪费了一段时间。</li><li>其次，拥塞窗口会急剧减小，这将导致接下来的传输速度变慢。</li></ul><p>即使是一次万分之一的超时重传，也可能对传输性能产生不可忽视的影响。</p><p>如何检查重传情况呢？</p><p>Wireshark 单击 Analyze—&gt;Expert Info Composite 菜单，就能在 Notes 标签看到它们了，如图所示。点开 + 号还能看到具体是哪些包发生了重传。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234234-5.png" alt=""></p><p>从 Notes 标签中看到 Seq 号为 1458613 的包发生了超时重传。于是用该 Seq 号过滤出原始包和重传包（只有在发送方抓的包才看得到原始包），发现 RTO 竟长达 1 秒钟以上。这对性能的影响实在太大了。找出瓶颈彻底消除重传之后：</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234234-6.png" alt=""></p><h5 id="SACK"><a href="#SACK" class="headerlink" title="SACK"></a>SACK</h5><p>SACK（Selective Acknowledgment 选择性确认）是一种重传机制，其可以<strong>向发送方发送接收状态信息</strong>。通过 SACK，发送方可以准确地知道哪些数据包已经被接收，哪些数据包还未接收到，从而<strong>只需要重传丢失的数据包</strong>。</p><p>在真实环境中，我们可以抓取到 SACK 的实例。结合“Ack = 991851”和“SACK = 992461-996175”这两个条件，发送方可以知道 992461-996175 的数据已经被接收，而 991851-992460 的数据则还未被接收。这为重传丢失的数据包提供了有力的指引。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234234-7.png" alt=""></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>除了众所周知的算法外，Linux 内核还提供了多个 TCP 拥塞控制算法，这些算法具有不同的传输特性，可以在 TCP 传输的重要指标，如往返传输时延（RTT）和吞吐量方面表现出不同的效果，包括：Reno、Cubic、BIC、Westwood+、Highspeed、Hybla 等。</p><pre><code class="hljs bash"><span class="hljs-comment"># 查询支持的TCP拥塞控制算法</span>sysctl net.ipv4.tcp_available_congestion_control&gt; net.ipv4.tcp_available_congestion_control = reno cubic bbr<span class="hljs-comment"># 查询应用的TCP拥塞控制算法</span>sysctl net.ipv4.tcp_congestion_control&gt; sysctl net.ipv4.tcp_congestion_control</code></pre><p>在实际应用中，我们可以根据具体需求和网络环境选择合适的 TCP 拥塞控制算法，以达到最佳的网络传输效果。</p><h3 id="小包问题（Small-packet-problem）"><a href="#小包问题（Small-packet-problem）" class="headerlink" title="小包问题（Small packet problem）"></a>小包问题（Small packet problem）</h3><p>为了保证数据的可靠性，它使用了流量控制、拥塞控制、确认机制等多种技术，这些技术都需要消耗网络带宽和处理资源。</p><p>当发送端发送的数据包大小过小时，就会导致网络中出现大量的TCP头部、IP头部等固定长度的协议头。因为一个 TCP 包的头部和 IP 头部至少会占用 40 个字节的空间，而携带的数据很小时就像快递员开着大货车去送小包裹一样浪费。</p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230326234234.jpg" alt=""></p><p>协议头会占用大量的网络带宽和处理资源，从而导致网络传输效率下降。为了避免TCP小包问题，发送端可以使用一些方法来增加数据包的大小，比如使用 Nagle算法、延迟确认。</p><h4 id="Nagle-算法"><a href="#Nagle-算法" class="headerlink" title="Nagle 算法"></a>Nagle 算法</h4><p>Nagle 算法的原理是在发出去的数据还没有被确认之前，如果有小数据生成，就先把这些小数据收集起来，凑满一个最大报文段长度（MSS）再进行发送。这样可以减少网络中的小数据包，提高网络的利用率。</p><h4 id="延迟确认"><a href="#延迟确认" class="headerlink" title="延迟确认"></a>延迟确认</h4><p>延迟确认的原理是这样的：如果接收方收到一个数据包后没有需要立即回复的数据要发送给发送方，那么它就会延迟一段时间再发送确认信息。如果在这段时间内有需要发送的数据，那么确认信息和数据就可以在同一个数据包中一起发送出去。</p><p>当与 Nagle 算法同时启用时，<a href="http://www.stuartcheshire.org/papers/nagledelayedack/">延迟确认可能会导致性能下降</a></p><p><img src="/images/network-transmission/TCP%20IP%20网络传输-20230329233021.png" alt=""></p><h3 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h3><p>理解 TCP 协议的机制和字段含义，是为了当传输性能问题发生时，更好地应用它。</p><p>当出现延迟问题时：</p><pre><code class="hljs bash">延迟指标 = 新建连接耗时 + RTT           + （Retransmission + RTO）           + （Fast Retransmission + Dup ACK)           +  Retransmission（Out-Of-Order）           - SACK           + Delay ACK + Nagle Algorithm</code></pre><ul><li>首先，应查看连接状态（是否频繁新建连接）及 RTT 情况</li><li>其次，关注是否有重传，是那种类型的重传，以及 SACK 是否有开启</li><li>最后，确认延迟确认和 Nagle 算法对延迟的影响</li></ul><p>类似的，当出现吞吐问题时：</p><pre><code class="hljs bash">吞吐指标 = （总耗时 - (新建连接耗时 + 重传耗时 + RTO 耗时））/ RTT * MSS * （Cwnd / MSS）           - Retransmission</code></pre><ul><li>首先，应查看连接状态（是否频繁新建连接）、RTT 情况</li><li>其次，关注是否有重传，是哪种类型的重传</li><li>最后，确认窗口大小、MSS 等值的状态</li></ul><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/03-30-2023/network-transmission.html">https://www.cyningsun.com/03-30-2023/network-transmission.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;作者序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文所谈的绝大部分内容在众多文章中都有讲到，再复述一遍并非本意。本文的目的是了解各种工具、定量分析网络状态；当遇到网络性能问题的时候，根据原理和出现的可能性，有的放矢。&lt;/p&gt;
&lt;ol&gt;
&lt;l</summary>
      
    
    
    
    <category term="Network" scheme="https://www.cyningsun.com/category/Network/"/>
    
    
    <category term="Transmission" scheme="https://www.cyningsun.com/tag/Transmission/"/>
    
  </entry>
  
  <entry>
    <title>TCP/IP 网络设备与基础概念</title>
    <link href="https://www.cyningsun.com/03-19-2023/network-device-and-concept.html"/>
    <id>https://www.cyningsun.com/03-19-2023/network-device-and-concept.html</id>
    <published>2023-03-18T16:00:00.000Z</published>
    <updated>2023-03-21T02:06:52.848Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>作者序</strong></p><p>本文目的在于按照自己的理解，解释清楚网络中的一些基本概念，以及支撑概念落地的网络设备的工作原理。从而解决网络联通性问题，以及为定量分析网络性能问题打基础。如有错漏，欢迎指正：</p><ol><li>什么是 WAN vs LAN？</li><li>什么是子网、网关？</li><li>LAN vs 子网有什么区别？</li><li>路由器、交换机、集线器 有什么区别？</li><li>LAN vs VLAN ？</li><li>L2 交换机 vs L3</li><li>交换机有什么区别？</li></ol></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>网络世界与现实世界在许多方面运作方式相似。就像现实世界中的地址一样，划分国家、省市、街道、小区。邮递员以此高效的将快递正确送达每家每户。在网络世界中，IP 地址是用于唯一标识网络中的设备的，但是当网络规模变得很大时，就需要将 IP 地址进行划分，划分为若干个子网。子网使网络更高效。通过子网划分，网络流量传播距离更短，无需通过不必要的路由器即可到达目的地。</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131221.png" alt=""></p><p>子网划分的过程需要在网络层上进行，可以通过在 IP 地址中使用子网掩码（Subnet Mask）来划分子网。子网掩码是一个 32 位的二进制数，与 IP 地址进行逻辑运算，可以将网络号和主机号进行区分。</p><blockquote><p>例如，如果将 IP 地址（192.168.1.0）分成 4 个子网，可以使用 255.255.255.192 的子网掩码进行划分，得到四个子网：</p><ul><li>192.168.1.0/26</li><li>192.168.1.64/26</li><li>192.168.1.128/26</li><li>192.168.1.192/26</li></ul></blockquote><p>不难看出，网络世界的运作很类似“分治策略”，可以将以上网络模型简化为 “子问题”（广域网 WAN） + 初始值（局域网 LAN）</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131221-1.png" alt=""></p><p>局域网（LAN, Local Area Network）是指在较小的地理范围内，由计算机、打印机、服务器等设备组成的局域网，它们可以通过物理链路或者无线信号相互连接，形成一个逻辑上的网络。在 LAN 中，所有设备可以直接通信，不需要经过路由器进行 IP 路由，因此都处于同一个广播域内。</p><p>广域网（WAN, Wide Area Network）是一种大型计算机网络，用于远距离连接不同的计算机组。大型企业通常使用 WAN 来连接其办公网络；每一办事处通常有自己的局域网（或 LAN），这些 LAN 通过 WAN 相连。</p><p>在此模型下，首先回顾下协议栈的分层；然后，再来认识网络设备是如何落地协议栈，并完成工作的。</p><h3 id="协议栈"><a href="#协议栈" class="headerlink" title="协议栈"></a>协议栈</h3><p>TCP/IP 包含如下两个头部。</p><ul><li>MAC 头部（以太网协议）</li><li>IP 头部（IP 协议）</li></ul><blockquote><p>协议栈分层中 IP 和 Ethernet 分开的目的在于支撑除了以太网在内的各种通信技术，例如无线局域网、ADSL、FTTH 等。它们都可以替代以太网的角色帮助 IP 协议来传输网络包。</p></blockquote><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131222.png" alt=""><br>两个头部分别具有不同的作用。首先，发送方将包的目的地，也就是要访问的服务器的 IP 地址写入 IP 头部中。如此就知道这个包应该发往哪里，IP 协议就可以根据这一地址查找包的传输方向，从而找到下一个路由器的位置。接下来，IP 协议会委托以太网协议将包传输过去。IP 协议会查找下一个路由器的以太网地址（MAC 地址），将包将地址写入 MAC 头部中。如此，以太网协议就知道要将这个包发到哪一个路由器。</p><p>同时，也意味着，经过每一跳的网络设备都会经过“解包”和“封包”，最核心的变化是 MAC 地址会被更新为下一跳的网络设备的地址（IP 地址保持不变）</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131222-1.png" alt=""></p><h3 id="网络设备"><a href="#网络设备" class="headerlink" title="网络设备"></a>网络设备</h3><p>现如今，网络设备的集成度越来越高，像上图这样使用独立设备的情况很少见。例如家用路由器，集成了集线器和交换机的功能。</p><p>不过，把每个功能独立出来更容易理解，而且理解了这种模式之后，也就能理解集成多种功能的设备，因此下面将所有功能独立出来，逐个来进行探索。</p><ul><li>三层网络设备，支持物理层, 数据链路层及网络层协议，例如：路由器</li><li>二层网络设备，支持物理层和数据链路层协议，例如：以太网交换机</li><li>一层网络设备，只支持物理层协议，例如：HUB</li></ul><h4 id="路由器"><a href="#路由器" class="headerlink" title="路由器"></a>路由器</h4><p>路由器作为三层网络设备的代表，在其中扮演着非常重要的角色。路由器先构建路由表，以确定如何将数据包从一个网络转发到另外一个网络。</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131222-2.png" alt=""></p><p>路由的核心功能可以分为两个部分，“<strong>路由选择</strong>”（确定通过网络的最佳路径的任务） 和 <strong>“分组转发</strong>”（将数据包从一个接口移动到另一个接口的任务）。就像计算机一样，通过更换网卡（NIC），路由器不仅可以支持以太网，也可以支持无线局域网。</p><h5 id="路由选择"><a href="#路由选择" class="headerlink" title="路由选择"></a>路由选择</h5><p>路由表是路由器中的一个表格，包含着可用的路由信息，包括目标网络地址和下一跳路由器的地址。当路由器接收到一个数据包时，会将数据包的目标 IP 地址与每一条路由表项的目的 IP 地址进行匹配。如果有多条匹配的路由表项，则选择最长的前缀匹配，并将数据包转发到该前缀所对应的网络。</p><blockquote><p>最长的前缀匹配指的是，路由表项中目的 IP 地址的子网掩码位数最长的项。例如，路由表中有以下三条路由表项：</p><ul><li>10.0.0.0/8</li><li>10.1.0.0/16</li><li>0.0.0.0/0</li></ul><p>当路由器收到一个目标 IP 地址为 10.1.2.3 的数据包时，会先与第二个路由表项（10.1.0.0/16）进行匹配，因为它的前缀长度更长（16 位）比第一个路由表项（8 位）更精确。因此，路由器会将数据包转发到与第二个路由表项对应的下一跳路由器。</p></blockquote><p>路由器拥有内网的 IP 路由表，同时还拥有一条神奇的路由 0.0.0.0/0。0.0.0.0/0 路由是一种默认路由，也称为默认网关或缺省路由。它指示路由器在找不到更具体的路由表项来匹配目标 IP 地址时，将数据包发送到默认网关，最终到达核心网。</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131222-3.png" alt=""></p><p>路由器有一个非常独立的控制体系。先有控制层面，再有数据层面。先有控制层面，才会知道一个一个网络怎么走，知道网络怎么走之后，再基于数据层面，接收数据，查读路由表，来进行数据转发。路由表的构建方式有以下几种方式：</p><ol><li>直连路由：路由器会扫描每个接口，确定网络地址和掩码，并将其添加到路由表中。</li><li>静态路由：管理员可以手动配置静态路由信息，包括目标网络地址和下一跳路由器的地址。</li><li>动态路由协议：路由器可以使用动态路由协议来动态学习路由信息。常见的动态路由协议包括 OSPF、BGP、RIP 等。</li></ol><h5 id="分组转发"><a href="#分组转发" class="headerlink" title="分组转发"></a>分组转发</h5><p><strong>接收到的数据包由链路层协议控制器</strong>处理，该控制器处理物理链路（电缆）上使用的链路层协议，会检查接收到的帧的完整性（大小、校验和、地址等）。有效帧通过去除链路层报头（解封）转换为数据包，并在接收队列中排队。这通常是一个先进先出 (FIFO) 队列，通常采用内存缓冲区环的形式。</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131222-4.png" alt=""></p><p>每个传出数据包都需要添加一个新的链路层协议报头（封装），并将目标地址设置为下一个接收数据包的系统。链路协议控制器还维护与接口相关的 <strong>硬件地址表。</strong> 通常涉及使用地址解析协议 ( ARP) 找出直接连接到同一电缆（或 LAN ）的其他计算机或路由器的硬件（MAC 地址).  数据包最终使用媒体接口发送，硬件地址设置为下一跳系统。</p><h5 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h5><p>为了确保 IP 数据包在网络上具有有限的生存期，所有 IP 数据包都有一个 8 位的 TTL（IPv4）或 Hop Limit（IPv6）报头字段和值，当一个路由器接收到一个数据包时，它会将 TTL 或 Hop Limit 减 1，然后再将数据包转发到下一个路由器。如果 TTL 或 Hop Limit 的值减少到 0，路由器将丢弃数据包并向源主机发送 ICMP 错误消息，通知它数据包已经超时。</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131222-5.png" alt=""></p><h4 id="交换机"><a href="#交换机" class="headerlink" title="交换机"></a>交换机</h4><p>MAC 地址是硬件地址，与设备的网卡绑定，二层交换机通过学习连接的每个终端的 MAC 地址，将数据发送给对应的目 的终端上，避免将数据发送到无关端口，提供了网络利用率。下次再遇到相同的 MAC 地址时，可以直接从缓存中获取对应的端口信息。</p><p>另外一种情况，由于广播域（二层互通）的存在，每个设备都能够直接访问到同一广播域内的所有其他设备。如果是没有学习到的 MAC 地址，或者想跟网段内所有终端进行通信，交换机会使用广播方式，将数据帧进行泛洪，无需对目标设备进行地址解析和寻址，可以更快速地定位和转发数据包。然后只有相应的接收者才接收包，而其他设备则会忽略这个包。</p><blockquote><p>举例，有三台电脑连接同一台交换机，计算机的 MAC 地址简化为 AAA、BBB 和 CCC。现在，假设计算机 A 要向计算机 B 发送一些信息：</p><p>交换机将建立一个 MAC 地址表，并且只从源 MAC 地址中学习。此时，它刚刚得知计算机 A 的 MAC 地址在接口 1 上。它现在将在其 MAC 地址表中添加此信息。但交换机目前没有计算机 B 所在位置的信息。因此只能将此帧从其所有除来源之外的接口中洪泛出来。计算机 B 和计算机 C 将接收该以太网帧。</p><p>由于计算机 B 将其 MAC 地址视为该以太网帧的目的地，它知道它是为他准备的，计算机 C 将丢弃它。计算机 B 将响应计算机 A，构建一个以太网帧并将其发送给交换机。此时，交换机将学习计算机 B 的 MAC 地址。</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230319232033.png" alt=""></p></blockquote><h5 id="VLAN"><a href="#VLAN" class="headerlink" title="VLAN"></a>VLAN</h5><p>当同一个交换机下主机越来越多，网络规模越大，广播域就越大，泛洪流量也越来越大，降低通信效率。在一个广播域内的任意两台主机之间可以任意通信，通信数据有被窃取的风险。</p><p>有两种方案可以解决这个问题：</p><ol><li>物理隔离：使用更多的交换机，配置为不同的子网</li><li>逻辑隔离：即，VLAN，使用交换机虚拟出来多个子网</li></ol><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131222-7.png" alt=""></p><p>对于分布在不同交换机之下同一个 VLAN 的主机如何互达呢？对于支持 VLAN 的交换机，有一种口叫作 Trunk 口。它可以转发属于任何 VLAN 的口。交换机之间可以通过这种口相互连接，即可保证同一个 VLAN 互达。</p><h5 id="三层交换机"><a href="#三层交换机" class="headerlink" title="三层交换机"></a>三层交换机</h5><p>二层交换机通过使用 VLAN 分隔广播域，位于同一个 VLAN 下的终端才能进 行数据帧交互。对于不同 VLAN 的终端有通信需求时，就必须使用路由功能， 也就是需要额外添加路由器。二层交换机和路由器组合使用，才能完成跨 VLAN 的通信。基于类似的需求，三层交换机应运而生。使用三层交换机就不需要其它网络设备，能够直接完成不同 VLAN 之间的通信。</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131222-8.png" alt=""></p><h4 id="集线器"><a href="#集线器" class="headerlink" title="集线器"></a>集线器</h4><p>集线器工作在物理层，以太网 LAN 的一种中继器形式，具有多个端口（它们有时也称为“多端口中继器”或“活动星形网络”）。</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308131222-9.png" alt=""></p><p>每个端口（或接口）允许一台设备连接到集线器。通过端口 F 连接的系统正在向端口 C 连接的系统发送一帧数据。集线器由于工作于物理层，无法识别帧头中的地址，因此无法识别要发送到哪个端口到。因此，采用“广播模式”，每一帧都被发送到每个输出端口，然后让主机来判断是否需要。</p><h3 id="简单测试"><a href="#简单测试" class="headerlink" title="简单测试"></a>简单测试</h3><blockquote><p>举例来源：《Wireshark 网络分析就这么简单》</p></blockquote><p>两台服务器 A 和 B 的网络配置如下图，B 的子网掩码本应该是 255.255.255.0，被不小心配成了 255.255.255.224。它们还能正常通信吗？</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308150939.png" alt=""></p><ul><li>答案 1：“A 和 B 不能通信，因为……如果这样都行的话，子网掩码还有什么用？”（这位的反证法听上去很有道理！）</li><li>答案 2：“A 和 B 能通信，因为它们可以通过 ARP 广播获得对方的 MAC 地址。”（那子网掩码还有什么用？楼上的反证法用来反驳这位正好。）</li><li>答案 3：“A 和 B 能通信，但所有包都要通过默认网关 192.168.26.2 转发。”（请问这么复杂的结果你是怎么想到的？）</li><li>答案 4：“A 和 B 不能通信，因为 ARP 不能跨子网。”（这个答案听上去真像是经过认真思考的。）</li></ul><p>以上哪个答案是正确的？还是都不正确？如果这是你第一次听到这道题，不妨停下来思考一下。</p><p>答案揭晓：B 先把请求交给默认网关，默认网关再转发给 A。而 A 收到请求后直接回复给 B，形成如下所示的三角形环路。不知道你答对了吗？</p><p><img src="/images/network-device-and-concept/TCP%20IP%20网络基础概念-20230308151529.png" alt=""></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/03-19-2023/network-device-and-concept.html">https://www.cyningsun.com/03-19-2023/network-device-and-concept.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;作者序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文目的在于按照自己的理解，解释清楚网络中的一些基本概念，以及支撑概念落地的网络设备的工作原理。从而解决网络联通性问题，以及为定量分析网络性能问题打基础。如有错漏，欢迎指正：&lt;/p&gt;
&lt;ol&gt;</summary>
      
    
    
    
    <category term="Network" scheme="https://www.cyningsun.com/category/Network/"/>
    
    
    <category term="Device" scheme="https://www.cyningsun.com/tag/Device/"/>
    
  </entry>
  
  <entry>
    <title>如何使用 Redis 存储对象</title>
    <link href="https://www.cyningsun.com/03-12-2023/how-to-store-objects-in-redis.html"/>
    <id>https://www.cyningsun.com/03-12-2023/how-to-store-objects-in-redis.html</id>
    <published>2023-03-11T16:00:00.000Z</published>
    <updated>2023-03-20T08:23:26.994Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>作者序</strong></p><p>本文是一篇 AI 辅助创作的内容。作者的工作内容发生一些的变化，开始转变为不断提出问题、丰富和拓展内容、编辑校研内容。</p><p>毫无疑问，“AI 辅助” 将变革当前的工作方式，未来已来。</p></blockquote><p>在 <a href="/07-27-2020/how-to-write-rpc-interface.html#认识资源">如何设计 RPC 接口</a> 中讲到一个观点：</p><blockquote><p>资源在用户侧以 <a href="/06-29-2020/how-to-write-restful-api.html">hyper media</a> 存在；资源流到服务中以对象来组织；资源落到存储里就变成了<code>id</code> + <code>content</code>。索引 <code>content</code> 的 id，一般又以 <code>单个</code> 和 <code>集合</code> 的形态存在，具体到数据库中，id 以 聚簇索引存在，content 以聚簇索引叶节点存在</p><p>越来越多的产品按照先获取 <code>id</code> 再读取 <code>content</code> 来访问资源</p></blockquote><p>Redis 是一个高效的键值存储数据库，可以用来存储对象(Content)。 在 Redis 中，可以使用 String 和 Hash 来存储对象。<strong>在生产环境经常看到不少的误用，导致低效的空间利用率、存取性能、以及可靠性</strong>。<strong>怎么存就决定了怎么取</strong>，Redis 数据结构选择也能见方案设计者的设计功力。</p><p>在实际的应用场景中，常见的使用方式有以下三种：</p><h3 id="JSON-String"><a href="#JSON-String" class="headerlink" title="JSON + String"></a>JSON + String</h3><p>JSON 是一种轻量级的数据交换格式，常用于前后端之间的数据传输。Redis 中可以存储 JSON 对象，通常使用字符串类型（string）来存储 JSON 数据。将 JSON 对象序列化成字符串并将其存储在 Redis 中，然后在需要时将其反序列化回 JSON 对象。</p><p>优点：</p><ul><li>JSON 对象的结构清晰易读，易于维护和理解。</li><li>JSON 对象可跨多个语言和平台使用，具有很好的兼容性。</li><li>Redis 中的字符串类型是 Redis 支持的最基本的数据类型之一，具有高效的读写性能。</li></ul><p>缺点：</p><ul><li>JSON 对象存储为字符串类型<strong>可能</strong>会占用更多的存储空间（注：相比数值）。</li><li>JSON 对象存储为字符串类型需要手动进行序列化和反序列化，可能会增加代码复杂度和运行时间。</li></ul><blockquote><p>备注： JSON 也可以替换成 Protobuf，性能更好，成本更低，思路一致。</p></blockquote><h3 id="Multiple-String"><a href="#Multiple-String" class="headerlink" title="Multiple String"></a>Multiple String</h3><p>多个字符串（multiple string）是指将一个对象的多个属性分别存储在 Redis 中不同的字符串键值对中。例如，将一个用户对象的用户名、邮箱、密码等属性存储在不同的 Redis 字符串中。</p><p>优点：</p><ul><li>可以根据需要轻松地读取或<strong>更新对象的某些属性</strong>，而无需读取或更新整个对象。</li><li><strong>不同的属性可以使用不同的 Redis 命令（如 GET、SET、INCR 等）进行操作</strong>，具有更高的灵活性。</li></ul><p>缺点：</p><ul><li>对于包含多个属性的对象，可能会需要在 Redis 中存储大量的键值对，增加存储开销。</li><li><strong>多个字符串可能存放在不同的分片，同时读取时可用性更差</strong>。</li><li>如果需要同时读取或更新对象的多个属性，可能需要进行多个 Redis 操作，增加网络延迟和代码复杂度。</li></ul><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p>哈希（hash）是 Redis 中的一种特殊数据类型，可以将一个对象存储为一个 Redis 哈希，其中对象的属性存储为哈希的字段，属性的值存储为哈希的值。例如，将一个用户对象存储为 Redis 哈希，其中用户名、邮箱和密码是哈希的字段，相应的值是哈希的值。</p><p>优点：</p><ul><li>与多个字符串相比，使用哈希可以更轻松地管理对象的属性，因为所有属性都存储在单个 Redis 键值对中。</li><li>可以使用 Redis 提供的丰富的哈希命令（如 HSET、HGET、HINCRBY 等）对对象进行操作。</li></ul><p>缺点：</p><ul><li>对于包含大量属性的对象，Redis 中的哈希可能会占用更多的存储空间。</li><li>如果需要同时读取或更新对象的多个属性，可能需要进行多个 Redis 操作，增加网络延迟和代码复杂度。</li></ul><h3 id="空间与性能"><a href="#空间与性能" class="headerlink" title="空间与性能"></a>空间与性能</h3><p>除了需求，考虑存储空间和存取性能</p><p>对于存储空间而言，可以根据具体的数据结构来选择最合适的存储方式。如果数据结构比较简单，使用 JSON+String 可能是比较好的选择，因为 JSON 格式可以非常紧凑，而字符串类型也是 Redis 支持的最基本的数据类型之一，占用的空间比较小。如果数据结构比较复杂，可以考虑使用哈希来存储对象，因为哈希可以将多个属性存储在同一个键值对中，相比于多个字符串，可以减少存储空间的占用。</p><p>对于存取性能而言，可以根据具体的应用场景来选择最合适的存储方式。如果需要快速地读取或更新对象的某些属性，可以考虑使用多个字符串或哈希，因为这些方式可以通过对单个属性进行操作来实现，相比于读取或更新整个对象，可以减少网络延迟和代码复杂度。如果需要快速地读取或更新整个对象，可以考虑使用 JSON+String，因为这种方式可以将整个对象序列化成一个字符串，只需要一次读取或更新操作即可。具体来说，三者读取一个对象的性能数据基本等价于 “GET/SET key vs HMGET/HMSET key field [field …] vs Opt(Pipline GET/SET, MGET/MSET) key [key …]“。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>总体而言，JSON+String、Multiple String 和 Hash 都是在 Redis 中存储对象的有效方式，具体使用哪种方式取决于数据的结构和应用场景。如果数据结构简单，且需要跨多个语言和平台使用，那么使用 JSON+String 可能是比较好的选择。如果需要更灵活地管理对象的属性，或者需要根据需要读取或更新对象的某些属性，那么使用多个字符串或哈希可能更适合。在实际使用中，可以根据具体的数据结构和应用场景选择最适合的方式。</p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/03-12-2023/how-to-store-objects-in-redis.html">https://www.cyningsun.com/03-12-2023/how-to-store-objects-in-redis.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;作者序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文是一篇 AI 辅助创作的内容。作者的工作内容发生一些的变化，开始转变为不断提出问题、丰富和拓展内容、编辑校研内容。&lt;/p&gt;
&lt;p&gt;毫无疑问，“AI 辅助” 将变革当前的工作方式，未来已来。</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.cyningsun.com/category/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="Redis" scheme="https://www.cyningsun.com/tag/Redis/"/>
    
  </entry>
  
  <entry>
    <title>系统为何如此脆弱</title>
    <link href="https://www.cyningsun.com/03-12-2023/why-is-the-system-so-fragile.html"/>
    <id>https://www.cyningsun.com/03-12-2023/why-is-the-system-so-fragile.html</id>
    <published>2023-03-11T16:00:00.000Z</published>
    <updated>2023-03-20T08:23:26.994Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/why-is-the-system-so-fragile/系统为何如此脆弱-20230310233733.png" alt=""></p><p>积木可以帮助儿童培养创造力和空间想象力，也可以被用来帮助人们理解系统稳定性的概念。</p><p>在系统稳定性中，积木可以被视为一个模型，代表系统的组成部分。每个组成部分都会相互影响，从而影响整个系统的稳定性。就像在积木塔中，每个积木都要与其它积木相互连接，以确保整个积木塔的稳定性。如果其中一个积木被移动或摇晃，可能会导致整个积木塔崩塌。</p><h3 id="脆弱性来源"><a href="#脆弱性来源" class="headerlink" title="脆弱性来源"></a>脆弱性来源</h3><p>一个系统的脆弱性取决于其在面对外部压力或内部故障时能否维持其功能或性能，影响系统脆弱的因素包括：</p><ol><li>单点故障：如果一个系统的某个关键部件出现故障，整个系统可能会受到影响。如果系统没有设计良好的冗余机制或备用部件，就可能会导致系统崩溃。</li><li>缺乏弹性：系统的弹性是指它在受到压力或负载变化时能否适应和调整。如果系统缺乏弹性，就可能会因为某个部分的失效或超负荷而崩溃。</li></ol><p>当资源使用率都处在低位，或者请求量保持在处理能力之下，流量再大无非面多加水，水多加面；当机器全新或在保，硬件故障频率保持在低位；环境宽松，会有一种错觉：怎么做都是对的。当需要缩容提升资源使用率，请求延迟毛刺让你无从下手；当每季度数台机器硬件故障，让你疯狂救火；就会倒逼产品在可用性方面下硬功夫。</p><p>接下来的部分以 Redis 架构来说明，技术决策是如何影响系统可用性的</p><h3 id="请求扇出"><a href="#请求扇出" class="headerlink" title="请求扇出"></a>请求扇出</h3><p>在 Codis 架构下，所有的数据按照 Key 对数据进行分片，每个分片提供一部分数据的访问能力。每个 Cmd 无论 Key 数量多少，都只能请求一个分片。整体架构如下：</p><p><img src="/images/why-is-the-system-so-fragile/系统为何如此脆弱-20230310233733-1.png" alt=""></p><p>实际情况是，用户的一次请求所需要的数据，可能会存储在多个分片内，譬如：搜索结果页。</p><p>为了满足类似需要，国内云厂商的 Redis 提供了跨分片请求的功能，以降低复杂度、吸引用户。当一个 MGET 的多 Key 请求发送到 Proxy 之后，由 Proxy 实现多个分片的命令拆分、聚合运算。整体架构如下：</p><p><img src="/images/why-is-the-system-so-fragile/系统为何如此脆弱-20230310233733-2.png" alt=""></p><h3 id="单点故障"><a href="#单点故障" class="headerlink" title="单点故障"></a>单点故障</h3><p>客户收获了自由，可以放飞自我。不用考虑请求跨多少分片，一次性 MGET 数百 Key 稀松平常；云厂商吸引了用户，财报靓丽。</p><p>突然有一天，有一个分片的机器降频了，处理能力大幅下降，请求量超过了分片处理能力；紧接着请求在 Proxy 大量堆积，一个分片开始超时报错；再接着业务发起大量重试，其他分片也因为重试导致带来的额外压力而积压。最终整个集群雪崩，业务整体崩溃。</p><p>聪明的朋友可能会有疑问：一个分片失败，只重试失败的分片不就可以了，为何还要重试其他已经成功的分片？</p><p>你抓住了重点，Proxy 能否支持部分失败呢？</p><p>答案是：可以。</p><p>Redis 刚开始是没有集群模式的，即使是 Redis Cluster 也是不支持跨 Slot 请求的，因此每次请求都只有两种结果：成功、失败。</p><p>完美支持“部分失败”需要依赖 RESP 协议、SDK、业务代码的支持，如此一来整体使用复杂度与自行分片请求已所差无几。</p><p>RESP：</p><pre><code class="hljs markdown">RESP Arrays are sent using the following format:<span class="hljs-bullet">-</span> A <span class="hljs-code">`*`</span> character as the first byte, followed by the number of elements in the array as a decimal number, followed by CRLF.<span class="hljs-bullet">-</span> An additional RESP type for every element of the Array.</code></pre><p>SDK：</p><pre><code class="hljs go"><span class="hljs-comment">// https://github.com/redis/go-redis</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(r *Reader)</span></span> readSlice(line []<span class="hljs-type">byte</span>) ([]<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>) &#123;n, err := replyLen(line)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err&#125;val := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">interface</span>&#123;&#125;, n)<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-built_in">len</span>(val); i++ &#123;v, err := r.ReadReply()<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<span class="hljs-keyword">if</span> err == Nil &#123;val[i] = <span class="hljs-literal">nil</span><span class="hljs-keyword">continue</span>&#125;<span class="hljs-comment">// 正确处理</span><span class="hljs-keyword">if</span> err, ok := err.(RedisError); ok &#123;val[i] = err<span class="hljs-keyword">continue</span>&#125;<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err&#125;val[i] = v&#125;<span class="hljs-keyword">return</span> val, <span class="hljs-literal">nil</span>&#125;</code></pre><p>业务代码：</p><pre><code class="hljs go">   <span class="hljs-comment">// 定义要查询的key数组</span>   keys := []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;key1&quot;</span>, <span class="hljs-string">&quot;key2&quot;</span>, <span class="hljs-string">&quot;key3&quot;</span>&#125;   <span class="hljs-comment">// 使用MGET命令获取多个key对应的value值</span>   values, err := client.MGet(keys...).Result()   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;       <span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;redis request failed:%s&quot;</span>, v)   &#125;   <span class="hljs-comment">// 输出结果</span>   <span class="hljs-keyword">for</span> _, val := <span class="hljs-keyword">range</span> values &#123;    strVal, ok := v.(<span class="hljs-type">string</span>)  <span class="hljs-comment">// 结果类型判断，避免类型强转导致 Panic</span><span class="hljs-keyword">if</span> !ok &#123;<span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;invalid redis response type:%s&quot;</span>, v)&#125;       fmt.Printf(<span class="hljs-string">&quot;key:%s, value:%v\n&quot;</span>, keys[i], strVal)   &#125;<span class="hljs-comment">// 手动重试失败的 Key ...</span></code></pre><h3 id="扇出数量"><a href="#扇出数量" class="headerlink" title="扇出数量"></a>扇出数量</h3><p>在扇出的情况下，不同类型的 RPC 请求对于服务的影响巨大。Unary RPC 需要等待所有扇出请求全部返回，重组完毕才能一次性返回给主调方。</p><p><img src="/images/why-is-the-system-so-fragile/系统为何如此脆弱-20230310233734.png" alt=""></p><p>当 Proxy 接收的请求数没有变化的前提下，不同大小的 Key 数量，最终会得到不一样的扇出数。<strong>切分和重组并非是无代价的，都需要额外的计算资源，导致 Proxy 的 CPU 使用率尖峰</strong>；Proxy 请求的整体响应耗时就取决于耗时最长的扇出请求，而该扇出请求的耗时又受 Key 数量的影响。以 MGET 1000 个 Key 为例，可能会切分成：</p><blockquote><p>1）1000 个 Slots，每 Cmd 1 个 Key，并发请求 1000 个 Slots 的Redis 节点<br>2）1 个 Slot，该 Cmd 1000 个  Key<br>3）10 个 Slots，每 Cmd 100 个 Key，并发请求 1 个 Redis 节点，Redis 顺序执行</p></blockquote><p>首先，情况 1）的概率最大：</p><p><strong>Redis Cluster 的固定槽位数量 “16384”，1000 有着数量级上的差距，因此在不使用 Hashtag 的情况下基本是分布在不同的 Slots。</strong> 扇出暴增，将导致 Proxy 网络IO和内存的使用量急剧增加。</p><p>其次，情况 2）请求的 Key 最终落到同一 Slot。在正常的业务情况下，每次请求的 Key 数量一般会符合正态分布，请求的数量一般分布在一定的区间。</p><p><img src="/images/why-is-the-system-so-fragile/系统为何如此脆弱-20230312092029.png" alt=""></p><p>假设请求 Key 数量的中位数为 75 个 Key，Key 数量可能会有如下分布：</p><ul><li>10% 的请求为 1～50 个 Key；</li><li>80% 的请求为 50～100 个 Key；</li><li>9% 的请求为 100～200 个 Key；</li><li>1% 的请求为 200～1000 个 Key；</li></ul><p><img src="/images/why-is-the-system-so-fragile/系统为何如此脆弱-20230312110314.png" alt=""></p><p>Redis 服务器在处理 1% 的请求时就会出现阻塞，从而影响其他 99% 的请求延迟。整体效果如下：</p><p><img src="/images/why-is-the-system-so-fragile/系统为何如此脆弱-20230310233734-2.png" alt=""></p><p>根据具体情况，选择合适的批量操作方式（比如分批次获取）以及使用 Redis 的 pipelining 技术等，就可以避免阻塞得到更稳定的服务：</p><p><img src="/images/why-is-the-system-so-fragile/系统为何如此脆弱-20230310233734-3.png" alt=""></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>针对 Redis 的场景，Redis 官方博客提供了<a href="https://redis.com/blog/redis-clustering-best-practices-with-keys/">一些建议</a>，包括：</p><ul><li>认真考虑 Key 空间。Key 是否有共同的特征，可以以智能的方式（按用户、按操作、按时间等）切分负载。使用 hashtag 将 Key 巧妙地分配到哈希槽。</li><li>评估 MULTI/EXEC 事务。看看您是否真的需要交易，或者管道是否可以。 不要忘记考虑多键命令以及它们是否可以被多个命令替换。</li></ul><p><strong>针对所有场景，一次用户请求响应的过程，其实就是数据读取、计算、展示的过程。请求精细划分，可以把计算从在线转移到离线；从读取转移到写入，一次计算，次次读取。简单来说，<a href="/12-03-2023/how-to-store-objects-in-redis.html">怎么存就决定了怎么取</a></strong>。</p><p><strong>读取的数据确定、展示的样式确定，计算的复杂度不会消失不见</strong>。如果只是将计算从业务系统，转移到基础架构(从北向服务转移到南向服务)；从无状态服务转移到有状态服务。实现方案简单了，系统也脆弱了。</p><p>万事皆有缘由，世事岂无因果。</p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/03-12-2023/why-is-the-system-so-fragile.html">https://www.cyningsun.com/03-12-2023/why-is-the-system-so-fragile.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/images/why-is-the-system-so-fragile/系统为何如此脆弱-20230310233733.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;积木可以帮助儿童培养创造力和空间想象力，也可以被用来帮助人们理解系统稳定性的概念。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="System Design" scheme="https://www.cyningsun.com/category/System-Design/"/>
    
    
    <category term="Fan-out" scheme="https://www.cyningsun.com/tag/Fan-out/"/>
    
  </entry>
  
  <entry>
    <title>Redis cluster 细节与技术选型</title>
    <link href="https://www.cyningsun.com/02-14-2023/details-about-redis-cluster.html"/>
    <id>https://www.cyningsun.com/02-14-2023/details-about-redis-cluster.html</id>
    <published>2023-02-13T16:00:00.000Z</published>
    <updated>2023-03-10T05:15:54.934Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据面"><a href="#数据面" class="headerlink" title="数据面"></a>数据面</h2><h3 id="Gossip"><a href="#Gossip" class="headerlink" title="Gossip"></a>Gossip</h3><p>集群是一个分片内的所有副本不能共一台机器，如果不同分片的副本共一台机器。<strong>该部署方式会导致单机故障影响多个副本，集群可用性低，共识达成慢，故障恢复时间较长。</strong></p><blockquote><p>N 个 Master 的集群，1 个 Master 节点挂掉仍然可用的概率是： <code>1-(1/(N*2-1))</code> </p></blockquote><h3 id="代理模式-Proxy-Mode"><a href="#代理模式-Proxy-Mode" class="headerlink" title="代理模式 Proxy Mode"></a>代理模式 Proxy Mode</h3><p><code>cross-slots query</code> ，等同于在 Proxy 层扇出。单一分片故障的情况下，业务侧的重试会增加集群其他分片的流量，进而影响服务的稳定性。其次，由于 Redis 自身原子性的保证，目前 Redis 协议并不支持部分失败。</p><h3 id="哈希槽-vs-分片"><a href="#哈希槽-vs-分片" class="headerlink" title="哈希槽 vs 分片"></a>哈希槽 vs 分片</h3><p>在限流、熔断等场景下，节点 IP 并不适合作为逻辑概念使用。其一在于会发生主从切换，其二在于硬件维护场景下节点迁移 IP 会发生变化。而 Slot 代表的是数据的逻辑概念，跟机器并不存在绑定关系。<strong>缺少 Shard 的概念，将难以基于 Shard 实现相关功能</strong></p><blockquote><p>备注：Redis 7.2 加入了 Shard 的概念，CLUSTER SLOTS 的相关命令也逐渐被 CLUSTER SHARDS 替代</p></blockquote><h3 id="重新分片-Resharding"><a href="#重新分片-Resharding" class="headerlink" title="重新分片 Resharding"></a>重新分片 Resharding</h3><p>当正在对 key 所属的 hash slots 进行重新分片时，<strong>多 key 操作可能变得不可用</strong>。</p><blockquote><pre><code>更具体地说，即使在重新分片期间，针对所有存在且仍哈希到同一 hash slot（重新分片的源节点或目标节点）的多 key 操作仍然可用。  对不存在的 key 或在重新分片期间被拆分到源节点和目标节点之间 key 的多 key 操作将产生 -TRYAGAIN 错误。客户端可以在一段时间后尝试该操作，或报告错误。  一旦指定 hash slot 的迁移终止，该 hash slot 的所有多 key 操作都将再次可用。</code></pre></blockquote><p>同步搬迁遇到 <strong>Big key 会阻塞 Redis 处理请求，导致请求（延迟）毛刺</strong></p><h3 id="从可读-Read-from-Slave"><a href="#从可读-Read-from-Slave" class="headerlink" title="从可读 Read from Slave"></a>从可读 Read from Slave</h3><p>因为 migrating 状态没有被同步到副本，所以当重新分片期间被拆分到源节点和目标节点之间 key 的多 key 操作，<strong>存在在另外一个节点的 key 读取到的数据为 nil</strong></p><h3 id="复制-Replication"><a href="#复制-Replication" class="headerlink" title="复制 Replication"></a>复制 Replication</h3><p><strong>全量同步导致内存翻倍、数据复制导致 CPU 毛刺</strong></p><blockquote><p>Redis 并不适合绑定在单个 CPU 上。Redis fork 会运行 CPU 密集型的后台任务，如BGSAVE 或 BGREWRITEAF。如果 Redis 实例绑定在给定核心上，后台作业也将在同样的核心，抢占 CPU 核心，与 Redis 事件竞争 CPU 的循环。它产生了巨大的性能 Redis 实例的降级（延迟、吞吐量）</p><p>最好将 Redis 绑定到 NUMA 节点（即多个核心），并在此基础上保持至少一个核心空闲支持后台任务</p></blockquote><p><strong>数据写入量大，主从同步落后，导致频繁全量同步</strong></p><p>在使用 Redis 复制的设置中，<strong>强烈建议在主服务器和副本中启用持久化</strong>。当这不能实现时，例如，由于磁盘速度非常慢导致的延迟问题，应配置实例以 <strong>避免 reboot 后自动重启</strong>。</p><blockquote><p>为了更好地理解为什么将持久化关闭的 master 配置为自动重新启动是危险的，请防止以下故障模式，即<strong>从 master 及其所有副本中擦除数据</strong>：</p><ul><li>有一个设置，节点 A 充当 master 节点，持久化被关闭，节点 B 和 C 从节点 A 复制。</li><li>节点 A 崩溃，但它有配置自动重启可以重启进程。但是，由于持久化已关闭，节点将以空数据集重新启动。</li><li>节点 B 和 C 将从空的节点 A 复制，因此它们将实际上销毁已有的数据副本。</li></ul><p>当 Redis Sentinel 用于高可用性时，关闭主机上的持久化，并且配置自动重启进程，是危险的。例如，Master 节点可能快速重启，使 Sentinel 无法检测到故障，从而出现上述故障模式。</p></blockquote><p>默认情况下，副本将忽略  “maxmemory”（除非在故障切换后或手动将其升级为 Master 副本）。副本不会主动淘汰数据，而会等待 Master 的 DEL 命令。最终可能会使用比  maxmemory 设置更多的内存（因为复制副本上有某些缓冲区可能更大，或者数据结构有时会占用更多内存等等）。要更改此行为，可以允许复制副本不忽略最大内存。要使用的配置指令是：</p><blockquote><p>replica-ignore-maxmemory no</p></blockquote><h3 id="故障转移-Failover"><a href="#故障转移-Failover" class="headerlink" title="故障转移 Failover"></a>故障转移 Failover</h3><p>执行手动故障切换时，连接到 <strong>Master 节点的客户端都会被停止（延迟毛刺）</strong>。同时，Master 将复制偏移量发送给副本，副本等待该侧的偏移量到达。</p><p>当达到复制偏移量时，故障切换将启动，并通知旧 Master 有关配置切换的信息。旧 Master 取消阻止客户端时，它们将重定向到新 Master。</p><blockquote><p>当副本想要成为 Master 时，没有分配 slots 的 Master 不参与选举过程。</p></blockquote><h3 id="容灾-Disaster-recovery"><a href="#容灾-Disaster-recovery" class="headerlink" title="容灾 Disaster recovery"></a>容灾 Disaster recovery</h3><p>Redis 环境中的灾难恢复与备份基本相同，而且能够在许多不同的外部数据中心传输这些备份。即使在某些灾难性事件影响到运行 Redis 并生成其快照的主数据中心的情况下，也可以通过这种方式保护数据。<br>- 备份 RDB  </p><pre><code>- RPO：小时级  - RTO：小时级  </code></pre><p>- 备份 AOF（Redis 7.0.0 以上）  </p><pre><code>- RPO：分钟级  - RTO：分钟级</code></pre><blockquote><p><strong>RPO 和 RTO 较高<br>异构 DR 实现难度高</strong></p></blockquote><h2 id="控制面"><a href="#控制面" class="headerlink" title="控制面"></a>控制面</h2><h3 id="重新分片-Resharding-1"><a href="#重新分片-Resharding-1" class="headerlink" title="重新分片 Resharding"></a>重新分片 Resharding</h3><p><strong>搬迁数据只能顺序进行，速度慢。</strong></p><p><strong>迁移状态不会广播给从节点，迁移过程中发生 failover，新的 master 迁移状态会丢失，需要重新设置</strong></p><p><strong>因为 SET SLOT 是先生效再共识，迁移过程 SET SLOT 的操作需要严格有序，先设置 Dst Node 确认生效再设置 Src Node。</strong></p><h3 id="移除节点-Forget-node"><a href="#移除节点-Forget-node" class="headerlink" title="移除节点 Forget node"></a>移除节点 Forget node</h3><p>移除节点需要在 <strong>1 分钟内通知所有节点，该节点下线。否则节点会可能再次加入集群</strong></p><h3 id="监控指标-Metrics"><a href="#监控指标-Metrics" class="headerlink" title="监控指标 Metrics"></a>监控指标 Metrics</h3><p>Prometheus 一般 <strong>间隔</strong> 通过 Redis Exporter 调用 INFO 命令拉取 Redis 监控数据。<strong>有些指标是瞬时值，可能不会被记录下来</strong>。 例如 Loading 状态</p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/02-14-2023/details-about-redis-cluster.html">https://www.cyningsun.com/02-14-2023/details-about-redis-cluster.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;数据面&quot;&gt;&lt;a href=&quot;#数据面&quot; class=&quot;headerlink&quot; title=&quot;数据面&quot;&gt;&lt;/a&gt;数据面&lt;/h2&gt;&lt;h3 id=&quot;Gossip&quot;&gt;&lt;a href=&quot;#Gossip&quot; class=&quot;headerlink&quot; title=&quot;Gossip&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.cyningsun.com/category/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="Redis" scheme="https://www.cyningsun.com/tag/Redis/"/>
    
  </entry>
  
  <entry>
    <title>etcd 实现与选型分析</title>
    <link href="https://www.cyningsun.com/01-27-2023/etcd-implement-and-tech-selection.html"/>
    <id>https://www.cyningsun.com/01-27-2023/etcd-implement-and-tech-selection.html</id>
    <published>2023-01-26T16:00:00.000Z</published>
    <updated>2023-03-10T05:15:54.934Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>随着在 Kubernetes 场景打磨下不断成长， etcd 逐渐成为技术圈众所周知的开源产品。</p><ul><li>多版本并发控制</li><li>事务</li><li>租约</li><li>变更通知</li></ul><p>etcd 因其丰富的功能，并被越来越多的选择，甚至于被当作 “银弹” 过度使用。本文的重点在于了解其发展历程、实现细节，并针对技术方案选型给出自己的理解。</p><blockquote><p>本文所有内容基于 etcd v3.5.0</p></blockquote><h4 id="起源"><a href="#起源" class="headerlink" title="起源"></a>起源</h4><p>2013 年，有一个叫 CoreOS 的创业团队，需要一个协调服务来存储服务配置信息、提供分布式锁等能力，来构建一款叫做 Container Linux 的产品。当分析过需求场景、痛点和核心目标，并评估社区开源的选项之后，CoreOS 团队最终选择自己造轮子，从 0 到 1 开发 etcd 以满足其需求。</p><h4 id="时间线"><a href="#时间线" class="headerlink" title="时间线"></a>时间线</h4><p><img src="/images/etcd-implement-and-tech-selection/etcd%20实现与选型分析-1674747425540.png" alt=""></p><h3 id="基础架构"><a href="#基础架构" class="headerlink" title="基础架构"></a>基础架构</h3><h4 id="集群架构"><a href="#集群架构" class="headerlink" title="集群架构"></a>集群架构</h4><p><img src="/images/etcd-implement-and-tech-selection/etcd%20实现与选型分析-20230126170737%201.png" alt=""></p><p><strong>架构说明</strong></p><ul><li>集群由一个 Leader 节点和 多个 Follower 节点组成，通过 Raft 协议达成共识</li><li>写请求：只有 Leader 节点能处理写请求，如果当前节点只是一个 Follower，则它会把请求转发给 Leader 处理。</li><li>读请求：<ul><li>串行读：直接读状态机数据返回、无需通过 Raft 协议与集群进行交互。</li><li>线性读：如果当前节点只是一个 Follower，它首先会从 Leader 获取集群最新的已提交的日志索引 (committed index)。然后等待直到状态机已应用索引 (applied index) 大于等于 Leader 的已提交索引时 (committed Index)，再读取数据返回。</li></ul></li></ul><h4 id="单机架构"><a href="#单机架构" class="headerlink" title="单机架构"></a>单机架构</h4><p><img src="/images/etcd-implement-and-tech-selection/etcd%20实现与选型分析-20230126170737-1.png" alt=""></p><p><strong>架构说明</strong></p><ul><li><strong>Client（客户端层）</strong>：包含 Client v2 和 v3 两个⼤版本 API 客户端。</li><li><strong>API（网络层）</strong>：<ol><li>包含 Client 访问 Server、Server 节点之间的通信协议</li><li>Client 访问 Server 协议有两个版本：v2 API 采⽤ HTTP/1.x 协议，v3 API 采用 gRPC 协议</li><li>Server 节点之间使用 HTTP 协议，通过 Raft 算法实现数据复制和 Leader 选举等功能</li></ol></li><li><strong>Raft（一致性算法层）</strong>：维护节点的 Raft 状态机、Raft 日志等保障 etcd 多节点间的数据⼀致性</li><li><strong>Server（业务逻辑层）</strong>：<ol><li>包括：Auth 鉴权模块、Quota 配额模块、KV 模块、Raftnode 一致性模块、Rafthttp 一致性通信模块、Lease 租约模块、Apply 持久化应用模块、MVCC 多版本并发控制模块、Watch 变更通知模块等</li><li>MVCC 模块主要由 treeIndex B 树索引模块和 boltdb B+ 树数据库模块组成</li></ol></li><li><strong>Storage</strong>：存储层<ol><li>包含 WAL 预写⽇志模块、Snapshot 快照模块、boltdb 数据库模块</li><li>WAL 保障异常后数据不丢失，boltdb 则保存了集群元数据和写⼊的数据</li></ol></li></ul><h3 id="核心工作流"><a href="#核心工作流" class="headerlink" title="核心工作流"></a>核心工作流</h3><h4 id="数据写入"><a href="#数据写入" class="headerlink" title="数据写入"></a>数据写入</h4><p><img src="/images/etcd-implement-and-tech-selection/etcd%20实现与选型分析-1674748261952.png" alt=""></p><p><strong>步骤</strong>：</p><ol><li>客户端发送一个 Put 请求给 KVServer。</li><li>KVServer 将请求数据进行适当的封装处理之后，调用 Raft 模块的 Propose 接口方法（步骤 2），由 raft 模块来处理写请求。</li><li>Raft 模块将记录 (entry) 添加到当前节点的 raftLog (步骤 3），并通知 RaftNode 模块执行相关操作 (步骤 4）</li><li>RaftNode 模块<ul><li>首先，广播给其他节点(Follower)（步骤 5）</li><li>同时，将记录保存到本地 WAL 文件中（步骤 6）</li><li>最后，告诉 Raft 模块开始等待其他节点提交响应（步骤 7）</li></ul></li><li>其它节点(Follower)接收到记录，并写到本地 raftlog 之后，就会给 Leader 发送一个响应。当 Leader 接收到超过半数节点的响应后，就认为这条记录已经 commit ，会更新本地 raftlog 的 commitID（步骤 8）。</li><li>一旦记录被 Raft 模块 commit 了，就开始通知 RaftNode 模块执行相关操作（步骤 9）。 RaftNode 模块应用（apply）数据记录（步骤 10），同时也将 commitID 广播给其它节点（步骤 11），然后通知 Raft 模块数据已经提交（步骤 12）。</li><li>MVCC 模块异步 将数据应用（apply）到本地存储（步骤 13），并通知 KVServer。</li><li>最后 KVServer 将结果返回给 client，整个过程就处理结束了。</li></ol><p>从上面的流程可以看出，一条记录首先是写入本地的 raftlog。然后发送给其它节点，当超过半数的节点接收到这条记录时，那么该记录就被认为已经 commit 了。最后才能被 KVServer apply。 所以下面的条件永远成立：</p><pre><code class="hljs abnf">ApplyId &lt;<span class="hljs-operator">=</span> CommitId &lt;<span class="hljs-operator">=</span> RaftLogId</code></pre><h5 id="复制状态机"><a href="#复制状态机" class="headerlink" title="复制状态机"></a>复制状态机</h5><p>etcd 使用 <strong>Raft 协议来维护集群内各个节点状态的一致性</strong>。每个 etcd 节点都维护了一个状态机，并且任意时刻至多存在一个有效的主节点。主节点处理所有来自客户端写操作，通过 Raft 协议保证写操作对状态机的改动会可靠的同步到其他节点。</p><p><img src="/images/etcd-implement-and-tech-selection/etcd%20实现与选型分析-20230126170737-3.png" alt=""><br>步骤：</p><ol><li>Client 客户端向 KVServer 发送请求</li><li>Server 接收到请求后，向 Raft 模块提交 Proposal</li><li>Raft 模块获取到 Proposal 后，会为 Proposal 生成日志条目，并追加到本地日志</li><li>Leader 会向 Follower 广播消息，为每个 Follower 生成追加的 RPC 消息，包括复制给 Follower 的日志条目</li><li>Follower 会持久化消息到 WAL 日志中，并追加到日志存储</li><li>Follower 向 Leader 回复一个应答日志条目的消息，告知 Leader 当前已复制日志的最大索引</li><li>Leader 在收到 Follower 的应答后，将已复制日志的最大索引信息更新到跟踪 Follower 进展的 Match Index 字段</li><li>Leader 根据 Follower 的 MatchIndex 信息，计算出一个位置。如果该位置已经被一半以上的节点持久化，那么这个日志之前的日志条目都可以标记为已提交</li><li>Leader 发送消息到 Follower 节点时，告知目前已经提交的索引位置</li><li>各个节点根据已提交的日志条目，将内容应用（apply）到存储、状态机</li></ol><h4 id="租约"><a href="#租约" class="headerlink" title="租约"></a>租约</h4><p><img src="/images/etcd-implement-and-tech-selection/etcd%20实现与选型分析-1674749248679.png" alt=""><br><strong>创建租约</strong>：</p><ul><li>当 LeaseServer 收到 Client 的创建一个 Lease 请求后，会通过 Raft 模块<br>完成日志同步</li><li>随后 Apply 模块通过 Lessor 模块的 Grant 接口执行日志条目内容。<ul><li>首先 Lessor 的 Grant 接口会把 Lease 保存到内存的 ItemMap 数据结构中</li><li>然后它需要持久化 Lease，将 Lease 数据保存到 boltdb 的 Lease bucket</li><li>最终返回一个唯一的 LeaseID 给 client。</li></ul></li></ul><p><strong>附加租约</strong>：</p><ul><li>当用户新增一个带 租约的 Key 时，MVCC 模块它会通过 Lessor 模块的 Attach 方法，将 key 关联到 Lease 的 key 内存集合 ItemMap。</li></ul><p><strong>淘汰租约</strong>：</p><ul><li>淘汰过期 Lease 的工作由 Lessor 模块的一个异步 goroutine 负责。它会定时从最小堆中取出已过期的 Lease，执行删除 Lease 和其关联的 key 列表数据的 RevokeExpiredLease 任务。</li><li>Lessor 模块会将已确认过期的 LeaseID，保存在一个名为 expiredC 的 channel 中，而<br>etcd server 的主循环会定期从 channel 中获取 LeaseID，发起 revoke 请求，通过 Raft<br>Log 传递给 Follower 节点。</li><li>各个节点收到 revoke Lease 请求后，获取关联到此 Lease 上的 key 列表，从 boltdb 中 删除 key，从 Lessor 的 Lease map 内存中删除此 Lease 对象，最后还需要从 boltdb 的 Lease bucket 中删除这个 Lease。</li></ul><p><strong>注意</strong>：</p><p>租约影响性能因素源自多方面：</p><ul><li>首先是 TTL，TTL 过长会导致节点异常后，无法及时从 etcd 中删除，影响服务可用性，而过短，则要求 client 频繁发送续期请求。</li><li>其次是 Lease 数，如果 Lease 成千上万个，那么 etcd 可能无法支撑如此大规模的 Lease 数，导致高负载。</li><li>再次，Lease 过期会触发写请求，再加上变更通知产生的读请求，对 etcd server 压力非常大。</li><li>最后，如果因为网络异常无法续期，导致数据过期。网络恢复正常，同一份数据再次写入，将导致 DB 大小迅速增加（历史版本数据并没有真正删除，数据库压缩才会实际删除）。</li></ul><p>从实际使用场景上来，为了降低 Lease TTL 过期带来的影响，可以将 Lease 与 Key 独立开，由系统自行控制和判定存活状态和 Key 的删除。</p><p>为了降低 etcd server 的压力可以把多个 kv 关联在一个 lease 上的，比如：</p><blockquote><p>kubernetes 场景中有大量的 event，如果一个 event 一个 Lease， Lease 数量是非常多的，Lease 过期会触发大量写请求，再加上变更通知产生的读请求，对 etcd server 压力非常大。</p><p>为了解决这个问题对 etcd server 性能的影响，Lease 过期淘汰会默认限速每秒 1000 个。因此 kubernetes 场景为了优化 Lease 数，会将最近一分钟内产生的 event key 列表，复用在同一个 Lease，大大降低了 Lease 数。</p></blockquote><h4 id="变更通知"><a href="#变更通知" class="headerlink" title="变更通知"></a>变更通知</h4><p><img src="/images/etcd-implement-and-tech-selection/etcd%20实现与选型分析-1674749229867.png" alt=""></p><p><strong>概念</strong>：</p><p>etcd 通过对 watcher 进行分类，来实现事件的可靠性：</p><ul><li>synced watcher，此类 watcher 监听的数据都已经同步完毕，在等待新的变更。</li><li>unsynced watcher，此类 watcher 监听的数据还未同步完成，落后于当前最新数据变更，正在努力追赶。</li><li>victim watcher，此类 slower watcher 的推送 channel buffer 堆满，etcd 会将其移动到专门的队列中异步机制重试。</li></ul><p><strong>订阅流程</strong>：</p><ul><li>当 Client 发起一个 watch key 请求的时候，etcd 的 WatchServer 收到 watch 请求后，会创建一个 serverWatchStream, 它负责接收 client 的 gRPC Stream 的 create/cancel watcher 请求 (recvLoop goroutine)，并将从 MVCC 模块接收的 Watch 事件转发给 client(sendLoop goroutine)。</li><li>当 serverWatchStream 收到 create watcher 请求后，serverWatchStream 会调用 MVCC 模块的 WatchStream 子模块分配一个 watcher id，并将 watcher 注册到 MVCC 的 WatchableKV 模块。</li><li><p>etcd 启动后，WatchableKV 模块会运行 syncWatchersLoop 和 syncVictimsLoop goroutine，分别负责不同场景下的事件推送。</p><blockquote><p>etcd 使用 map 记录了监听单个 key 的 watcher，但是你要注意的是 Watch 特性不仅仅可以监听单 key，它还可以指定监听 key 范围、key 前缀，因此 etcd 还使用了区间树。当收到创建 watcher 请求的时候，它会把 watcher 监听的 key 范围插入到上面的区间树中，区间的值保存了监听同样 key 范围的 watcher 集合 /watcherSet。</p><p>当产生一个事件时，etcd 首先需要从 map 查找是否有 watcher 监听了单 key，其次它还需要从区间树找出与此 key 相交的所有区间，然后从区间的值获取监听的 watcher 集合。区间树支持快速查找一个 key 是否在某个区间内，时间复杂度 O(LogN)，因此 etcd 基于 map 和区间树实现了 watcher 与事件快速匹配，具备良好的扩展性。</p></blockquote></li></ul><p><strong>推送流程</strong>：</p><ul><li>当你创建完成 watcher 后，此时你执行 put hello 修改操作时，如上图所示，请求经过后的 mvccpb.KeyValue 保存到一个 changes 数组中。</li><li>在 put 事务结束时，它会将 KeyValue 转换成 Event 事件，然后回调 watchableStore.notify 函数。notify 会匹配出监听过此 key 并处于 synced watcherGroup 中的 watcher，同时事件中的版本号要大于等于 watcher 监听的最小版本号，才能将事件发送到此 watcher 的事件 channel 中。</li></ul><p><strong>注意</strong>：</p><p>若 watcher 监听的版本号已经小于当前 etcd server 压缩的版本号，历史变更数据就可能<br>已丢失，因此 etcd server 会返回 ErrCompacted 错误给 client。client 收到此错误后，需重新获取数据最新版本号后，再次 Watch。在业务开发过程中，使用 Watch API 最常见的一个错误之一就是未处理此错误。</p><p>其次，Watch 返回的  <code>WatchChan</code>  有可能在运行过程中失败而关闭，此时  <code>WatchResponse.Canceled</code>  会被置为  <code>true</code>，<code>WatchResponse.Err()</code>  也会返回具体的错误信息。所以在 range WatchChan 的时候，每一次循环都要检查  <code>WatchResponse.Canceled</code>，在关闭的时候重新发起 Watch 或报错。</p><h3 id="选型分析"><a href="#选型分析" class="headerlink" title="选型分析"></a>选型分析</h3><p>方案选型可以从业务系统的需求和 etcd 的特性、性能，两个方面着手。</p><h4 id="业务系统"><a href="#业务系统" class="headerlink" title="业务系统"></a>业务系统</h4><p>先看使用 etcd 提供服务的目标系统。如果你正在深入 Kubernetes 或开始使用服务网格，您可能会遇到术语“控制平面（<a href="https://en.wikipedia.org/wiki/Control_plane">control plane</a>）”和“数据平面（<a href="https://en.wikipedia.org/wiki/Forwarding_plane">data plane</a>）”。术语 “控制平面” 和 “数据平面” 都是关于关注点的分离，即系统内职责的明确分离。控制平面是一切与策略建立和下发有关的部分，而数据平面是一切与执行策略有关的部分。当控制平面出现故障，只会影响新的策略变更变更，但不会影响已有策略执行，即，数据平面的功能。</p><p><img src="/images/etcd-implement-and-tech-selection/etcd%20实现与选型分析-20230126170738.png" alt=""></p><p>以 Kubernetes 为例，其核心服务包括：</p><div class="table-container"><table><thead><tr><th>组件</th><th>描述</th></tr></thead><tbody><tr><td>kube-apiserver</td><td>提供了资源的唯一入口，并提供认证、授权、访问控制、API 注册和发现等</td></tr><tr><td>kube-scheduler</td><td>负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上</td></tr><tr><td>kube-controller-manager</td><td>负责维护集群的状态，比如故障检测、自动扩展、滚动更新等</td></tr><tr><td>etcd</td><td>存储整个集群的状态</td></tr><tr><td>kube-proxy</td><td>负责为 Service 提供 cluster 内部的服务发现和负载均衡</td></tr></tbody></table></div><p>以上服务故障，并不会影响当前已有 Pod 正常对外提供服务。</p><h4 id="Why-etcd"><a href="#Why-etcd" class="headerlink" title="Why etcd"></a>Why etcd</h4><p>再看 etcd 本身。要了解 etcd 适用的场景，质量最高的来源是其官网。</p><blockquote><p>介绍：<br>“etcd” 名字来源于两个想法：unix “/etc” 文件夹和 分布式（ “d”istributed）系统。“/etc” 文件夹是存储单个系统的配置数据的地方，而 etcd 存储大规模分布式系统的配置信息。因此，“d”istributed “/etc” 是 “etcd”。</p><p>etcd 被设计为大规模分布式系统的通用基座。这类系统永远不容忍裂脑操作，并愿意牺牲可用性来实现该目标。</p><p>分布式系统使用 etcd 用于配置管理、服务发现和协调分布式工作。etcd 的常见分布式模式包括领导者选举、分布式锁和监控机器活动。</p><p>使用场景：</p><ul><li>CoreOS 的 Container Linux：在 Container Linux 上运行的应用程序可以获得自动、零停机的 Linux 内核更新。Container Linux 使用 Locksmith 来协调更新。Locksmith 在 etcd 上实现了分布式信号量，以确保在任何给定时间只有集群的一个子集在重新启动。</li><li>Kubernetes 将配置数据存储到 etcd 中，用于服务发现和集群管理；etcd 的一致性对于正确调度和操作服务至关重要。Kubernetes API 服务器将集群状态持久化为 etcd。它使用 etcd 的 watch API 来监视集群并生效关键的配置变更。( 2016 年 Kubernetes 1.6 发布，默认启用 etcd v3，助力 Kubernetes 支撑 <strong>5000</strong> 节点集群规模)</li></ul><p>其他：</p><ul><li>最大可靠数据库大小： 数 GB</li><li>因为缺少数据分片，复制无法水平扩展</li><li>租约提供了一种用于减少中止请求数量的优化机制。</li></ul><p>——— 来源：<a href="https://etcd.io/docs/v3.5/learning/why/">etcd versus other key-value stores | etcd</a></p></blockquote><p>从基本介绍以及使用场景来看，etcd 的定位在于存储数据量小、更新频率低的数据，用于一致性要求高于可用性、无需水平扩展的场景。</p><h4 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h4><h5 id="硬件推荐"><a href="#硬件推荐" class="headerlink" title="硬件推荐"></a>硬件推荐</h5><p>以 <strong><a href="https://etcd.io/docs/v3.5/op-guide/hardware/">超大型集群</a></strong> 为例，一个超大型型集群服务的客户端超过 1500 个，每秒请求超过 10000 个，存储数据超过 1 GB。</p><div class="table-container"><table><thead><tr><th>云厂商</th><th>机型</th><th>CPU</th><th>内存 (GB)</th><th>最大并发 IOPS</th><th>磁盘带宽 (MB/s)</th></tr></thead><tbody><tr><td>AWS</td><td>m4.4xlarge</td><td>16</td><td>64</td><td>16,000</td><td>250</td></tr><tr><td>GCE</td><td>n1-standard-16 + 500GB PD SSD</td><td>16</td><td>60</td><td>15,000</td><td>250</td></tr></tbody></table></div><h5 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h5><p>压测的硬件配置：</p><blockquote><ul><li>Google Cloud Compute Engine</li><li>3 machines of 8 vCPUs + 16GB Memory + 50GB SSD</li><li>1 machine(client) of 16 vCPUs + 30GB Memory + 50GB SSD</li><li>Ubuntu 17.04</li><li>etcd 3.2.0, go 1.8.3</li></ul></blockquote><p><strong>写性能</strong></p><div class="table-container"><table><thead><tr><th>Key 数量</th><th>Key 大小 (byte)</th><th>Value 大小 (byte)</th><th>连接数</th><th>Client 数</th><th>目标 etcd server</th><th>平均写 QPS</th><th>平均请求延迟</th><th>平均服务 RSS</th></tr></thead><tbody><tr><td>10,000</td><td>8</td><td>256</td><td>1</td><td>1</td><td>leader only</td><td>583</td><td>1.6ms</td><td>48 MB</td></tr><tr><td>100,000</td><td>8</td><td>256</td><td>100</td><td>1000</td><td>leader only</td><td>44,341</td><td>22ms</td><td>124MB</td></tr><tr><td>100,000</td><td>8</td><td>256</td><td>100</td><td>1000</td><td>all members</td><td>50,104</td><td>20ms</td><td>126MB</td></tr></tbody></table></div><p><strong>读性能</strong></p><div class="table-container"><table><thead><tr><th>请求数</th><th>Key 大小 (byte)</th><th>Value 大小 (byte)</th><th>连接数</th><th>Client 数</th><th>一致性</th><th>平均读 QPS</th><th>平均请求延迟</th></tr></thead><tbody><tr><td>10,000</td><td>8</td><td>256</td><td>1</td><td>1</td><td>Linearizable</td><td>1,353</td><td>0.7ms</td></tr><tr><td>10,000</td><td>8</td><td>256</td><td>1</td><td>1</td><td>Serializable</td><td>2,909</td><td>0.3ms</td></tr><tr><td>100,000</td><td>8</td><td>256</td><td>100</td><td>1000</td><td>Linearizable</td><td>141,578</td><td>5.5ms</td></tr><tr><td>100,000</td><td>8</td><td>256</td><td>100</td><td>1000</td><td>Serializable</td><td>185,758</td><td>2.2ms</td></tr></tbody></table></div><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>一般 etcd 的集群为 3 或 5 个节点，Key 数量为 10w~ 规模下，预估集群性能如下：</p><ol><li>写请求只有 Leader 才能处理，所以写性能不随节点数增加而增加，只取决于单机配置，处理量级大概为 1w~ QPS，平均延迟在 10ms~50ms。</li><li>串行读取所有节点均可处理，无需共识，处理量级大概为 10w~ QPS，平均延迟在 5ms 以内。</li><li>线性读取所有节点均可处理，但需要请求 Leader 获取 ReadIndex，性能会稍差，节点数对其提升有限，且容易受写请求影响，处理量级大概为 10w QPS，平均延迟在 10ms 以内。</li></ol><h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><p>综合目标系统和 etcd 本身的细节来看：</p><ol><li>首先，不建议将 etcd 用于目标系统的数据面。例如，配置中心产品，不适合使用 etcd 作为存储；</li><li>其次，谨慎将 etcd 用于对数据分片和水平扩展有要求的控制面系统。例如：跨可用区的服务发现，可以对服务类型进行区分，尽量减少多个可用区之间需要复制同步的服务数据量。</li><li>最后，etcd 租约、变更通知等功能的复杂度偏高。技术可控要求较高的系统，应谨慎使用相关功能。</li></ol><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/01-27-2023/etcd-implement-and-tech-selection.html">https://www.cyningsun.com/01-27-2023/etcd-implement-and-tech-selection.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;随着在 Kubernetes 场景打磨下不断成长， etcd 逐渐成为技术圈众所周知的开源产品。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多版本并发控制&lt;</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.cyningsun.com/category/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="etcd" scheme="https://www.cyningsun.com/tag/etcd/"/>
    
  </entry>
  
  <entry>
    <title>译｜Design patterns for container-based distributed systems</title>
    <link href="https://www.cyningsun.com/11-13-2022/design-patterns-for-container-based-distributed-systems-cn.html"/>
    <id>https://www.cyningsun.com/11-13-2022/design-patterns-for-container-based-distributed-systems-cn.html</id>
    <published>2022-11-12T16:00:00.000Z</published>
    <updated>2023-03-10T05:15:54.933Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>译者序</strong></p><p>本文发表于 2016 年，作者为 Borg、Omega 和 Kubernetes 的主要开发： <strong><a href="https://www.linkedin.com/in/brendan-burns-487aa590/">Brendan Burns</a></strong> 和 <strong>David Oppenheimer</strong>， 其他相关论文包括：</p><ul><li>2015 <a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43438.pdf">《Large-scale cluster management at Google with Borg》</a> </li><li>2016 <a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/44843.pdf">《Borg, Omega, and Kubernetes：Lessons learned from three container management systems over a decade》</a></li></ul><p>文章总结了云原生下的多种设计模式，能够对如何设计分布式系统有所启发。从本论文中你也可以看到容器管理系统 ( Kubernetes )、Service Mesh (Istio)、 监控系统 ( Prometheus ) 等诸多明星系统的影子，进而推测未来云原生领域的发展方向。</p></blockquote><h3 id="1-导言"><a href="#1-导言" class="headerlink" title="1 导言"></a>1 导言</h3><p>在 1980 年代末和 1990 年代初，面向对象编程彻底改变了软件开发，普及了将应用构建为模块化组件集合的方法。 今天，我们在分布式系统开发中看到了类似的革命，基于容器化软件组件构建的微服务架构越来越受欢迎。 因为容器之间的隔离优势，容器 [15] [22] [1] [2] 特别适合作为分布式系统中的基本“对象”。 随着这种架构风格的成熟，我们看到了设计模式的出现，就跟面向对象程序所做的一个道理——以对象（或容器）的方式思考抽象掉代码的低级细节，最终揭示各种应用和算法共有的高级模式。</p><p>本文描述了我们在基于容器的分布式系统观察到的三种设计模式：容器管理的单容器模式、紧密协作容器的单节点模式和分布式算法的多节点模式。 与之前的面向对象模式一样，分布式计算的这些模式实现了最佳实践，简化了开发，让使用它们的系统更可靠。</p><h3 id="2-分布式系统设计模式"><a href="#2-分布式系统设计模式" class="headerlink" title="2 分布式系统设计模式"></a>2 分布式系统设计模式</h3><p>在使用面向对象编程多年之后，设计模式出现并被记录了下来[3]。 这些模式编码和规范化了解决特别常见编程问题的一般方法。 这种编码进一步提高了编程的总体水平，因为它使经验不足的程序员更容易产出高质量的代码；同时，它促进了可重用库的发展，使代码更可靠，开发速度更快。</p><p>当今分布式系统工程的最新技术看起来更像是 1980 年代早期的编程时期，而不是面向对象开发的时期。 然而，从 MapReduce 模式 [4] 将 “大数据” 编程的力量带到广阔的领域和开发者群体的成功中可以清楚地看出，建立正确的模式集可以显着提高分布式系统编程的质量、速度和可达性。 但即使 MapReduce 的成功很大程度上也仅限于单一的编程语言，因为 Apache Hadoop [5] 生态系统主要是用 Java 编写的。 为分布式系统设计开发一套真正完备的模式需要一个非常通用的、语言中立的工具来表示系统的原子元素。</p><p>值得庆幸的是，过去两年 Linux 容器技术的采用率急剧上升。容器和容器镜像正是分布式系统模式开发所需的抽象。到目前为止，容器和容器图像仅通过作为一种更好、更可靠的方法从开发到生产交付软件，就获得了广泛的应用。通过紧密的封装，依赖自治，并提供原子部署标记（“成功”/“失败”），它们极大地提升了以前在数据中心或云中部署软件的最先进技术的水平。但容器有可能不止于此——我们相信它们注定会类似于面向对象的软件系统中的对象，将使分布式系统设计模式的发展成为可能。在下面的部分中，我们解释了为什么我们认为必然如此，并描述了我们看到的一些模式，这些模式将在未来几年中规范和指导分布式系统的工程。</p><h3 id="3-单容器管理模式"><a href="#3-单容器管理模式" class="headerlink" title="3 单容器管理模式"></a>3 单容器管理模式</h3><p>与对象边界 ( boundary) 非常相似， 容器为定义接口提供了一个自然的边界 ( boundary) 。容器不仅可以通过此接口暴露应用特定的功能，还可以为管理系统暴露钩子 (hooks)。</p><p>传统的容器管理接口非常有限。容器有效地暴露三个动词：run() pause() 和 stop()。虽然此接口很有用，但更丰富的接口可以为系统开发和运维人员提供更多能力。鉴于几乎所有现代编程语言都普遍支持 HTTP Web 服务器，并且对 JSON 等数据格式的广泛支持，因此很容易定义一个基于 HTTP的管理 API，除了其主要功能之外，还可以通过让容器在特定端点 (endpoints) 托管 Web 服务器来“实现”其他功能。</p><p>在北向方面，容器可以公开一组丰富的应用信息，包括应用特定的监控指标（QPS、应用健康状况等）、开发者感兴趣的分析 (profiling) 信息（线程、堆栈、锁争用、网络消息统计信息） 等）、组件配置信息和组件日志。 作为此的实际例子，Kubernetes [6]、Aurora [7]、Marathon [8] 和其他容器管理系统允许用户通过特定的 HTTP 端点 ( endpoints )（例如 “/health”）定义健康检查。 对我们前面所描述的之外其他元素，北向 API 的标准化支持更为罕见。</p><p>在南向方面，容器接口提供了一个自然之选来定义生命周期，这使得编写受管理系统控制的软件组件变得更加容易。例如，集群管理系统通常会为任务分配“优先级”，即使集群超额订阅，高优先级任务也能保证运行。这种保证是通过驱逐已运行中的低优先级任务来实现的，低优先级任务将不得不等待资源可用再执行。驱逐可以通过简单地杀死优先级较低的任务来实现，但这会给开发人员带来不必要的负担，让他们应对代码中任意死亡的情况。相反，如果在应用和管理系统之间定义了一个规范的生命周期，遵从定义的契约以后，应用组件将变得更易于管理；同时，开发人员依赖契约以后，系统的开发变得更容易。例如，Kubernetes 使用 Docker 的“优雅删除”功能，通过 SIGTERM 信号警告容器它将被终止，然后在应用定义的时间窗口之后再发送 SIGKILL 信号。这允许应用完成运行中的操作、将状态刷新到磁盘等再干净地终止。可以想象扩展该机制以提供对状态序列化和恢复的支持，从而使有状态分布式系统的状态管理变得更加容易。 </p><p>考虑一个更复杂生命周期的例子，Android Activity 模型 [9]，它支持一系列回调（例如 onCreate()、onStart()、onStop() 等）和一个规范定义的系统如何触发回调的状态机。如果没有这个规范的生命周期，很难开发健壮、可靠的 Android 应用。 在基于容器的系统的上下文中，泛化为应用定义的在创建容器时、启动时、终止前等调用的钩子 (hooks)。另一个容器可能支持的南向 API 的例子是“复制 (replicate) 自己”（以横向扩容服务）。</p><h3 id="4-单主机多容器应用模式"><a href="#4-单主机多容器应用模式" class="headerlink" title="4 单主机多容器应用模式"></a>4 单主机多容器应用模式</h3><p>除了单个容器的接口之外，我们还看到了跨容器设计模式的出现。 我们先前确定了几种这样的模式 [10]。单节点模式由共同调度到单个主机上的共生容器组成。 容器管理系统支持将多个容器作为一个原子单元共同调度，抽象 Kubernetes 称为 “Pods”，Nomad [11] 称为“任务组”，这是启用我们在本节中描述的模式所必需的特性。</p><h4 id="4-1-边车-Sidecar-模式"><a href="#4-1-边车-Sidecar-模式" class="headerlink" title="4.1 边车 (Sidecar) 模式"></a>4.1 边车 (Sidecar) 模式</h4><p>多容器部署的第一种也是最常见的模式是边车模式。 边车容器扩展并增强了主容器。 例如，主容器可能是一个 Web 服务器，它可能与一个“logsaver” 边车容器配对，后者从本地磁盘收集 Web 服务器的日志并将它们流式传输到集群存储系统。 图 1 是边车模式的示例。 另一个常见例子是 Web 服务器，它从本地磁盘内容提供服务，该内容由边车容器填充，该容器定期同步来自 git 存储库、内容管理系统或其他数据源的内容。 这两个例子在谷歌都很常见。 边车模式之所以是可能的，是因为同一台机器上的容器可以共享本地磁盘卷。</p><p><img src="/images/design-patterns-for-container-based-distributed-systems-cn/1668265566715.png" alt=""></p><p>虽然总是可以将边车容器的功能构建到主容器中，但使用单独的容器有几个好处。</p><ul><li>首先，容器是资源核算和分配的单位，例如，可以配置 Web 服务器容器的 cgroup [15]，以便它为查询提供持续的低延迟响应，而 logsaver 容器配置为在Web 服务器不忙时利用空闲的 CPU 周期。</li><li>其次，容器是打包的单位，将服务和日志保存分离到不同的容器中，可以很容易地在两个独立的编程团队之间划分他们的开发责任，并允许他们独立测试，也可以一起测试。</li><li>第三，容器是重用的单元，因此边车容器可以与许多不同的“主要”容器配对（例如，log saver 容器可以与任何产生日志的组件一起使用）。</li><li>第四，容器提供了一个故障控制边界，使得整个系统可以优雅地降级（例如，即使 log saver 程序发生故障，Web 服务器也可以继续服务）。</li><li>最后，容器是部署单元，它允许对每个功能进行升级，并在必要时独立回滚。 （尽管应该注意的是，最后一个好处也有一个缺点——整个系统的测试矩阵必须考虑生产中可能出现的所有容器版本组合，这可能很大，因为容器集通常不能以原子方式升级。当然，虽然单体应用没有这个问题，但组件化系统在某些方面更容易测试，因为它们是由可以独立测试的较小单元构建的。）</li></ul><p>请注意，这五个好处适用于所有我们在本文其余部分描述的容器模式。</p><h4 id="4-2-特使-ambassador-模式"><a href="#4-2-特使-ambassador-模式" class="headerlink" title="4.2 特使  ( ambassador ) 模式"></a>4.2 特使  ( ambassador ) 模式</h4><p>我们观察到的下一个模式是特使模式。 特使容器代理与主容器之间的通信。例如，开发人员可能会将使用 memcache 协议的应用与 twemproxy 特使配对。该应用认为它只是与本地主机上的单个内存缓存进行通信，但实际上 twemproxy 正在将请求分片到其他位置的集群中分布式安装的多个内存缓存节点。这种容器模式在三个方面简化了程序员的生活：</p><ul><li>他们只需要以应用连接到本地主机上的单个服务器的方式来思考和编程</li><li>他们可以通过在本地机器上运行一个真正的内存缓存实例来独立测试应用，而不是特使。</li><li>他们可以将 twemproxy 特使与其他应用一起重用，这些应用甚至可以用不同的语言进行编码。</li></ul><p>特使之所以是可能的，因为同一台机器上的容器共享相同的本地主机网络接口。图 2 展示了这种模式的例子。</p><p><img src="/images/design-patterns-for-container-based-distributed-systems-cn/1668266707053.png" alt=""></p><h4 id="4-3-适配器模式"><a href="#4-3-适配器模式" class="headerlink" title="4.3 适配器模式"></a>4.3 适配器模式</h4><p>我们观察到的最后一个单节点模式是适配器模式。与向应用呈现简化的外部世界视图的特使模式相比，适配器向外部世界呈现简化、统一的应用视图。它们通过标准化跨多个容器的输出和接口来做到这一点。适配器模式的一个实际例子是，确保系统中所有容器具有相同监控接口的适配器。当今的应用使用多种方法导出其指标（例如 JMX、statsd 等）。但是，如果所有应用都呈现一致的监控接口，那么单个监控工具就更容易从一组异构应用中收集、聚合和呈现指标。在谷歌内部，我们通过编码约定实现了这一点，但这只有在您从头开始构建软件时才有可能。适配器模式使遗留和开源应用的异构世界，无需修改原始应用，就能够呈现统一的接口。主容器可以通过 localhost 或共享本地卷与适配器通信。如图 3 所示。请注意，虽然一些现有的监控解决方案能够与多种类型的后端进行通信，但它们在监控系统自身使用应用特定的代码，关注点分离 ( Separation of Concerns，SoC ) 是模糊的。</p><p><img src="/images/design-patterns-for-container-based-distributed-systems-cn/1668321605769.png" alt=""></p><h3 id="5-多节点应用模式"><a href="#5-多节点应用模式" class="headerlink" title="5 多节点应用模式"></a>5 多节点应用模式</h3><p>超越单台机器上的协作容器，模块化容器更容易构建协调一致的多节点、分布式应用。 接下来我们将描述其中的三种分布式系统模式。 与上一节中的模式一样，这些模式也需要系统支持 Pod 抽象。</p><h4 id="5-1-领导者-Leader-选举模式"><a href="#5-1-领导者-Leader-选举模式" class="headerlink" title="5.1 领导者 ( Leader ) 选举模式"></a>5.1 领导者 ( Leader ) 选举模式</h4><p>分布式系统中最常见的问题之一是领导者选举（例如 [20]）。虽然复制通常用于在一个组件的多个相同实例之间共享负载，但复制的另一个更复杂的用途是应用需要将一个副本从一组副本中区分为“领导者”。如果领导者失败，其他副本可以快速取代领导者。一个系统甚至可以并行运行多个领导者选举，例如：确定多个分片中每个分片的领导者。许多库可以执行领导者选举。它们通常很难正确理解和使用，此外，它们受到特定的实现编程语言的限制。将领导选举库链接到应用的替代方案是使用领导者选举容器。每个领导者选举容器都与需要领导者选举的应用实例共同调度，一组领导者选举容器，可以在它们之间执行选举，并且它们可以通过 localhost 向每个需要领导者选举的应用容器提供简化的 HTTP API（例如 becomeLeader、renewLeadership 等）。这些领导者选举容器可以由该复杂领域的专家构建一次，然后应用开发人员可以重复使用随后的简化接口，而不管他们选择什么实现语言。这代表了软件工程中最好的抽象和封装。</p><h4 id="5-2-工作队列模式"><a href="#5-2-工作队列模式" class="headerlink" title="5.2 工作队列模式"></a>5.2 工作队列模式</h4><p>尽管工作队列（如领导者选举一样）是一个经过充分研究的主题，许多框架都实现了它们，但它们也是可以从面向容器的体系结构中受益的分布式系统模式的例子。在以前的系统中，框架将程序限制在单一语言环境中（例如 Celery for Python [13]。译注：异步任务队列），或者工作和二进制文件的分发交由实现者处理（例如 Condor [21]。译注：作业调度系统）。容器实现 run() 和 mount() 接口的可能性，使得实现通用工作队列框架变得相当简单，该框架可以利用打包了任意处理代码的容器和任意数据，构建一个完整的工作队列系统。开发人员只需构建一个容器，该容器可以在文件系统上接收输入数据文件，并将其转换为输出文件；这个容器将成为工作队列的一个阶段。开发完整工作队列所涉及的所有其他工作都可以由通用工作队列框架处理，无论何时需要类似的系统都可以重用该框架。用户代码集成到此共享工作队列框架中的方式如图 4 所示。</p><p><img src="/images/design-patterns-for-container-based-distributed-systems-cn/1668325038278.png" alt=""></p><h4 id="5-3-分散-汇聚模式"><a href="#5-3-分散-汇聚模式" class="headerlink" title="5.3 分散/汇聚模式"></a>5.3 分散/汇聚模式</h4><p>我们着重突出的最后一个分布式系统模式是分散/汇聚。 在这样的系统中，外部客户端向 “根” 或 “父” 节点发送初始请求。 此根节点将请求分散到大量服务器以并行执行计算。 每个分片返回部分数据，根节点将这些数据汇聚到原始请求的单个响应中。 这种模式在搜索引擎中很常见。 开发这样一个分布式系统涉及大量样板代码：分发请求、收集响应、与客户端交互等。大部分代码都是非常通用的，同样，就像在面向对象编程中一样，可以通过这样一种方式重构，即可以提供单个实现，只要它们实现特定的接口，就可以与任意容器一起使用。 特别地，为了实现分散/汇聚系统，用户需要提供两个容器。 </p><ul><li>一是实现叶子节点计算的容器； 该容器执行部分计算并返回相应的结果。 </li><li>第二个容器是合并容器； 此容器获取所有叶容器的聚合输出，并将它们组装为单个响应。 </li></ul><p>通过提供实现这些相对简单的接口的容器，很容易看出用户如何实现任意深度的散布/汇聚系统（如果需要，除了根之外，还包括父级）。这样的系统如图 5 所示。</p><p><img src="/images/design-patterns-for-container-based-distributed-systems-cn/1668327726784.png" alt=""></p><h3 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6 相关工作"></a>6 相关工作</h3><p>面向服务的架构 (SOA) [16] 早于基于容器的分布式系统，并与其许多特征相通。 例如，两者都强调可重用的组件，这些组件具有通过网络进行通信的定义明确的接口。 另一方面，SOA 系统中的组件往往比我们描述的多容器模式粒度更大，耦合更松散。 此外，SOA 中的组件通常实现业务活动，而我们在这里关注的组件更类似于通用库，可以更轻松地构建分布式系统。 最近出现了术语 “微服务” 来描述我们在本文中讨论的组件类型。</p><p>网络组件的标准化管理接口的概念至少可以追溯到 SNMP [19]。 SNMP 主要侧重于管理硬件组件，尚未出现管理基于微服务/容器的系统的标准。 这并没有阻止众多容器管理系统的发展，包括 Aurora [7]、ECS [17]、Docker Swarm [18]、Kubernetes [6]、Marathon [8] 和 Nomad [11]。</p><p>我们在第 5 节中提到的所有分布式算法都有悠久的历史。 人们可以在 Github 中找到许多领导者选举实现，尽管它们似乎是作为库而不是独立组件构建的。 有许多流行的工作队列实现，包括 Celery [13] 和 Amazon SQS [14]。 分散-汇聚已被识别为一种企业集成模式 [12]。</p><h3 id="7-结论"><a href="#7-结论" class="headerlink" title="7 结论"></a>7 结论</h3><p>正如面向对象编程引出了面向对象的“设计模式”的出现和规范化一样，我们看到容器体系结构引出了基于容器的分布式系统的设计模式。在本文中，我们识别了我们看到的三种类型的模式：系统管理的单容器模式、紧密协作容器的单节点模式和分布式算法的多节点模式。在所有情况下，容器都提供了许多与面向对象系统中的对象相同的好处，例如可以很容易地在多个团队之间划分实现，并在新的上下文中重用组件。此外，它们还提供了一些分布式系统独有的好处，例如使组件能够独立升级、多种语言编写，以及使整个系统能够优雅地降级。就像几十年前面向对象编程一样，我们相信，容器模式集只会增长，并且在未来几年，通过实现分布式系统开发的标准化和规范化，它们将彻底改变分布式系统编程。</p><h3 id="8-参考文献"><a href="#8-参考文献" class="headerlink" title="8 参考文献"></a>8 参考文献</h3><p>[1] Docker Engine <a href="http://www.docker.com">http://www.docker.com</a><br>[2] rkt: a security-minded standards-based container engine <a href="https://coreos.com/rkt/">https://coreos.com/rkt/</a><br>[3] Erich Gamma, John Vlissides, Ralph Johnson, Richard Helm, Design Patterns: Elements of Reusable Object-Oriented Software, AddisonWesley, Massachusetts, 1994.<br>[4] Jeffrey Dean, Sanjay Ghemawat, MapReduce: Simplified Data Processing on Large Clusters, Sixth Symposium on Operating System Design and Implementation, San Francisco, CA 2004.<br>[5] Apache Hadoop, <a href="http://hadoop.apache.org">http://hadoop.apache.org</a><br>[6] Kubernetes, <a href="http://kubernetes.io">http://kubernetes.io</a><br>[7] Apache Aurora, <a href="https://aurora.apache.org">https://aurora.apache.org</a>.<br>[8] Marathon: A cluster-wide init and control system for services, <a href="https://mesosphere.github.io/marathon/">https://mesosphere.github.io/marathon/</a><br>[9] Managing the Activity Lifecycle, <a href="http://developer.android.com/training/basics/activitylifecycle/index.html">http://developer.android.com/training/basics/activitylifecycle/index.html</a><br>[10] Brendan Burns, The Distributed System ToolKit: Patterns for Composite Containers, <a href="http://blog.kubernetes.io/2015/06/the-distributedsystem-toolkit-patterns.html">http://blog.kubernetes.io/2015/06/the-distributedsystem-toolkit-patterns.html</a><br>[11] Nomad by Hashicorp, <a href="https://www.nomadproject.io/">https://www.nomadproject.io/</a><br>[12] Gregor Hohpe, Enterprise Integration Patterns, Addison-Wesley, Massachusetts, 2004.<br>[13] Celery: Distributed Task Queue, <a href="http://www.celeryproject.org/">http://www.celeryproject.org/</a><br>[14] Amazon Simple Queue Service, <a href="https://aws.amazon.com/sqs/">https://aws.amazon.com/sqs/</a><br>[15] <a href="https://www.kernel.org/doc/Documentation/cgroupv1/cgroups.txt">https://www.kernel.org/doc/Documentation/cgroupv1/cgroups.txt</a><br>[16] Service Oriented Architecture, <a href="https://en.wikipedia.org/wiki/Serviceoriented">https://en.wikipedia.org/wiki/Serviceoriented</a> architecture<br>[17] Amazon EC2 Container Service, <a href="https://aws.amazon.com/ecs/">https://aws.amazon.com/ecs/</a><br>[18] Docker Swarm <a href="https://docker.com/swarm">https://docker.com/swarm</a><br>[19] J. Case, M. Fedor, M. Schoffstall, J. Davin, A Simple Network Management Protocol (SNMP), <a href="https://www.ietf.org/rfc/rfc1157.txt">https://www.ietf.org/rfc/rfc1157.txt</a>, 1990.<br>[20] R. G. Gallager, P. A. Humblet, P. M. Spira, A distributed algorithm for minimum-weight spanning trees, ACM Transactions on Programming Languages and Systems, January, 1983.<br>[21] M.J. Litzkow, M. Livny, M. W. Mutka, Condor: a hunter of idle workstations, IEEE Distributed Computing Systems, 1988.<br>[22] <a href="https://linuxcontainers.org/">https://linuxcontainers.org/</a></p><p><em>来源：<a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45406.pdf">Design Patterns for Container-based Distributed Systems</a></em></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/11-13-2022/design-patterns-for-container-based-distributed-systems-cn.html">https://www.cyningsun.com/11-13-2022/design-patterns-for-container-based-distributed-systems-cn.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;译者序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文发表于 2016 年，作者为 Borg、Omega 和 Kubernetes 的主要开发： &lt;strong&gt;&lt;a href=&quot;https://www.linkedin.com/in/bre</summary>
      
    
    
    
    <category term="System Design" scheme="https://www.cyningsun.com/category/System-Design/"/>
    
    
    <category term="Design patterns" scheme="https://www.cyningsun.com/tag/Design-patterns/"/>
    
  </entry>
  
  <entry>
    <title>译｜Dependency Management</title>
    <link href="https://www.cyningsun.com/06-08-2022/dependency-management-cn.html"/>
    <id>https://www.cyningsun.com/06-08-2022/dependency-management-cn.html</id>
    <published>2022-06-07T16:00:00.000Z</published>
    <updated>2022-11-11T15:35:56.461Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>译者序</strong></p><p>本文为 Bazel 依赖管理的文章，介绍了大规模下依赖关系的复杂情况及其应对策略。从本文可以学到什么？</p><ol><li>了解构建系统依赖管理的基本情况</li><li>理解 Golang 内置的构建工具和后续的发展方向</li><li>版本如何影响公司内部基础架构升级</li></ol></blockquote><p>在浏览前面的页面时，有一个主题反复提及：管理自己的代码相当简单，但管理其依赖关系则困难得多。存在各种各样的依赖关系：有时依赖于某个任务（如“将版本标记为完成之前推送文档”）；有时依赖于某个制品（如“需要最新版本计算机视觉库才能构建代码）；有时，内部依赖于代码库的另一部分，并且有时外部依赖于其他团队（无论是组织内还是第三方）的代码或数据。但无论如何，“欲此先彼”的观念在构建系统的设计中反复出现，管理依赖关系或许是构建系统最基本的工作</p><h3 id="应对模块和依赖关系"><a href="#应对模块和依赖关系" class="headerlink" title="应对模块和依赖关系"></a>应对模块和依赖关系</h3><p>使用基于制品的构建系统（如Bazel）的项目被分解为一组模块，模块通过 <code>BUILD</code> 文件表示彼此之间的依赖关系。正确组织模块和依赖关系会对构建系统的性能以及维护工作量产生巨大影响。</p><h3 id="使用精细模块和-1：1：1-规则"><a href="#使用精细模块和-1：1：1-规则" class="headerlink" title="使用精细模块和 1：1：1 规则"></a>使用精细模块和 1：1：1 规则</h3><p>在组织基于工件的构建时，第一个问题是确定单个模块应该包含多少功能。在 Bazel 中，模块由描述说明可构建单元（如 java_library 或 go_binary）的目标表示。 一种极端情况下，整个项目可以包含在一个模块中，方法是将一个 BUILD 文件放在根目录下，并以递归方式将该项目的所有源文件合并在一起。另外一种极端情况下，几乎每个源文件都可以放到自己的模块中，实质上要求每个文件在 BUILD 文件中列出它所依赖的其他所有文件</p><p>大多数项目都处于极端情况之间，选择涉及性能和可维护性之间的权衡。整个项目使用一个模块意味着，除了从外部添加依赖项之外，再不需要更改 BUILD 文件，但构建系统必须始终一次性构建整个项目。这意味着它无法将各部分并行或分布式构建，也无法缓存已构建的部分。每个文件一个模块则相反：构建系统在构建的缓存和调度步骤方面具有最大的灵活性，但每当更改文件引用文件时，工程师需要花费更多精力来维护依赖项列表。</p><p>尽管确切的粒度因语言而异（甚至在语言内也是如此），但相比基于任务的构建系统中编写的典型的模块，Google 倾向于使用小得多的模块。Google 的典型生产二进制文件通常依赖于数万个目标，即使是中等规模的团队也可以在其代码库中拥有数百个目标。对于具有强大内置的打包概念的语言（如 Java），每个目录通常包含一个软件包、目标和 BUILD 文件（Pants，另一个基于 Bazel 的构建系统，称之为 1:1:1 规则）。打包概念较弱的语言，每个 BUILD 文件通常会定义多个目标。</p><p>较小的构建目标的好处在大规模时开始显现出来，因为它们可以加快分布式构建的速度，减少重建目标的频率。 测试入场后，优势变得更加引人注目，因为更细粒度的目标意味着构建系统可以更智能地运行可能受给定更改影响的有限测试子集。由于 Google 认为使用较小的目标具有系统方面的优势，因此我们通过投资自动管理 BUILD 文件的工具，以避免给开发人员带来负担，从而在减轻不利影响方面迈出了一大步。</p><p>其中一些工具，如 <code>buildizer</code> 和 <code>buildozer</code>，可以放在 <a href="https://github.com/bazelbuild/buildtools">buildtools</a> 目录中与 Bazel 一起使用</p><h3 id="最小化模块可见性"><a href="#最小化模块可见性" class="headerlink" title="最小化模块可见性"></a>最小化模块可见性</h3><p>Bazel 和其他构建系统允许每个目标指定可见性：一种指定哪些目标可以依赖于它的属性。目标可以是公共的，此时，工作区中的任何其他目标都可以引用它；私有的，此时，只允许同一个 BUILD 文件中引用它；或仅对明确定义的其他目标列表可见。可见性本质上与依赖相反：如果目标 A 想要依赖目标 B，则目标 B 必须使其自身对目标 A 可见。与大多数编程语言一样，通常最好尽可能降低可见性。一般来说，仅当目标代表 Google 的任何团队都可以广泛使用的库时，Google 团队才会公开。要求在使用他们代码之前与他们协调的团队，会维护一份允许的客户目标列表，作为其目标的可见范围。每个团队内部实现的目标将可见性仅限于团队拥有的目录，大多数BUILD 文件只有一个非私有的目标。</p><h3 id="管理依赖项"><a href="#管理依赖项" class="headerlink" title="管理依赖项"></a>管理依赖项</h3><p>模块需要能够相互引用。将代码库拆分成精细的模块的缺点是，需要管理模块之间的依赖关系（尽管工具可以帮助自动执行）。表达依赖关系通常最终成为 BUILD 文件中的大部分内容。</p><h4 id="内部依赖项"><a href="#内部依赖项" class="headerlink" title="内部依赖项"></a>内部依赖项</h4><p>在分解为精细模块的大型项目中，大多数依赖项可能是内部依赖项；即，在同一源代码库中定义和构建的另一个目标。内部依赖项与外部依赖项的不同之处在于，它们是从源代码构建的，而不是在运行构建时以预构建制品下载的。这也意味着内部依赖项没有“版本”概念，目标及其所有内部依赖项始终在存储库中的同一提交/修订时构建。关于内部依赖项，如何处理可传递依赖项（图 1）是一个应谨慎处理的问题。假设目标 A 依赖于目标 B，而目标 B 依赖于通用库目标 C。目标 A 是否能够使用目标 C 中定义的类？</p><p><img src="/images/dependency-management-cn/transitive-dependencies.png" alt="transitive-dependencies.png"><br>图 1. 可传递依赖项</p><p>就底层工具而言，这么做没有任何问题； B 和 C 都会在构建时链接到目标 A，因此 C 中定义的任何符号都是已知的。Bazel 多年来一直允许这种情况出现，但随着 Google 不断发展，我们看到了一些问题。假设 B 已重构，使其不再需要依赖于 C。如果 B 对 C 的依赖被移除，那么通过 B 的依赖关系使用 C 的 A 以及其他所有目标都会破坏。实际上，目标的依赖项会成为其公共合约的一部分，永远无法安全更改。这意味着，依赖关系会随着时间的推移而积累，Google 的构建速度会开始变慢。</p><p>Google 最终在 Bazel 中引入了“严格可传递依赖关系模式”，从而解决了此问题。在此模式下，Bazel 会检测目标是否试图直接引用符号，而不依赖于它；如果是的话，则失败，并显示错误以及一条可用于自动插入依赖项的 shell 命令。在 Google 的整个代码库中推广这一变化，并重构数百万个构建目标，以明确列出它们的依赖项，该项目花费了多年的努力，但非常值得。由于目标中不必要依赖项减少，现在构建要快得多。而且，工程师有权删除他们不需要的依赖项，而不用担心破坏依赖它们的目标。</p><p>与往常一样，强制执行严格的可传递依赖关系需要做出权衡。因为现在经常使用的库需要在许多位置显式列出，而不是被意外地拉取，使得构建文件更详细；而工程师需要花费更多精力在 BUILD 文件中添加依赖项。此后，我们开发了相关工具，可在不进行任何开发者干预的情况下，自动检测许多缺失的依赖项并将其添加到 BUILD 文件，从而减少此类繁重工作。但即使没有此类工具，我们也发现，在代码库扩大规模的情况下这样做非常值得：显式地将依赖项添加到构建文件是一次性的成本，但只要构建目标存在，处理隐式可传递依赖关系就会导致持续的问题。默认情况下，Bazel 会在 Java 代码中强制执行<a href="https://blog.bazel.build/2017/06/28/sjd-unused_deps.html">严格可传递依赖关系</a></p><h4 id="外部依赖项"><a href="#外部依赖项" class="headerlink" title="外部依赖项"></a>外部依赖项</h4><p>如果依赖项不是内部依赖项，它一定是外部依赖项。外部依赖项是指在构建系统之外构建和存储的制品。系统直接从制品库（通常通过互联网访问）导入依赖项，并按原样使用，而不是从源代码构建。外部依赖项与内部依赖项之间的最大差异之一是，外部依赖项有版本，并且版本独立于项目的源代码。</p><h4 id="自动-vs-手动-管理依赖项"><a href="#自动-vs-手动-管理依赖项" class="headerlink" title="自动 vs 手动 管理依赖项"></a>自动 vs 手动 管理依赖项</h4><p>构建系统可以手动或自动管理外部依赖项的版本。手动管理时，构建文件会明确列出要从制品库下载的版本，通常使用 1.1.4 等<a href="https://semver.org/">语义版本字符串</a>。自动管理时，源文件会指定可接受版本的范围，而构建系统始终会下载最新版本。例如，Gradle 将依赖项版本声明为“1.+”，以指定依赖项的主版本或补丁版本可以接受，前提是主版本为 1。</p><p>对小型项目来说，自动管理依赖项很方便，但它们通常是非一般规模的项目或由多个工程师处理的项目的灾难。自动管理依赖项的问题在于，无法控制版本更新。无法保证外部一方不会进行中断性的更新（即使他们声称使用语义化版本），因此，某一天工作过的构建版本可能会在第二天就被破坏，并且没有简单的方法来检测更改的内容或将其回滚到工作状态。即使构建不会中断，也可能出现无法跟踪的细微的行为或性能变化。</p><p>相比之下，手动管理的依赖项需要更新到源代码控制系统，可以轻松地找到和回滚这些依赖项，并且可以签出旧版代码库以使用旧版依赖项构建。Bazel 要求手动指定所有依赖项的版本。即使在中等规模下，手动版本管理的开销也非常值得，因为这样可以获得稳定性。</p><h4 id="单一版本规则"><a href="#单一版本规则" class="headerlink" title="单一版本规则"></a>单一版本规则</h4><p>库的不同版本通常由不同的制品表示，因此理论上讲，没有理由不能在构建系统中以不同的名称声明同一外部依赖项的不同版本。这样，每个目标就都可以选择要使用的依赖项版本。这会导致实践中遇到许多问题，因此 Google 对代码库中的所有第三方依赖项强制执行严格的<a href="https://opensource.google/docs/thirdparty/oneversion/">单一版本规则</a>。</p><p>允许多个版本的最大问题是钻石依赖性问题。假设目标 A 依赖于目标 B 以及外部库的 v1。如果后续重构目标 B，添加对同一外部库的 v2 的依赖项，则目标 A 会中断，因为它现在隐式依赖于同一库的两个不同版本。实际上，添加新的从目标到具有多个版本的任何第三方库的依赖关系的做法，从来都不是安全的，因为该目标的任何用户都可能已经依赖于不同的版本。遵循单一版本规则可以避免该冲突。如果目标添加对第三方库的依赖关系，现存所有依赖关系已经采用相同的版本，因此可以和谐共存。</p><h4 id="可传递外部依赖关系"><a href="#可传递外部依赖关系" class="headerlink" title="可传递外部依赖关系"></a>可传递外部依赖关系</h4><p>处理外部依赖项的可传递依赖关系特别困难。许多制品库（如：Maven、Central）允许制品指定仓库中特定版本的其他制品的依赖关系。默认情况下，Maven 或 Gradle 等构建工具通常以递归方式下载每个可传递依赖关系，意味着在项目中添加单个依赖项可能会导致总共下载数十个制品。</p><p>这样非常方便：添加一个新库的依赖项时，必须跟踪该库的每个传递依赖关系，并手动添加所有依赖关系，是一件非常痛苦的事。但也存在一个巨大的缺点：由于不同的库可以依赖于同一第三方库的不同版本，因此必然会违反单一版本规则，导致钻石依赖关系问题。如果目标依赖的两个外部库使用相同依赖项的不同版本，则无法确定具体会获取哪个库。也意味着，如果新版本开始拉取它的某些依赖项的冲突版本，则可能会导致整个代码库中看似不相关的故障。</p><p>因此，Bazel 不会自动下载传递依赖项。然而，并没有万能的办法，Bazel 的替代方案是，使用全局文件列出代码库的每个外部依赖项以及用于整个代码库的相应依赖项的显式版本。幸运的是，Bazel 提供的工具能够自动生成这样的文件，其中包含一组 Maven 制品的可传递依赖关系。可以运行该工具一次，以生成项目的初始 WORKSPACE 文件；然后，可以手动更新该文件，以调整每个依赖项的版本。</p><p>再次强调，这是一种方便性和扩展性之间的选择。小型项目可能本身无需担心管理可传递依赖关系，并且可能无需使用自动可传递依赖关系。随着组织和代码库的增长，冲突和意外结果变得越来越频繁，此策略变得越来越没有吸引力。在较大规模时，手动管理依赖项的成本远低于处理自动管理依赖项引起的问题的成本。</p><h4 id="使用外部依赖关系缓存构建结果"><a href="#使用外部依赖关系缓存构建结果" class="headerlink" title="使用外部依赖关系缓存构建结果"></a>使用外部依赖关系缓存构建结果</h4><p>外部依赖项通常由发布稳定版本的库（可能未提供源代码）的第三方提供。一些组织还会选择将自己的一些代码作为制品提供，以便其他代码可以作为第三方（而非内部依赖项）依赖它们。如果制品的构建速度很慢但下载速度很快，理论上，可加快构建速度。</p><p>但是，这种方法也带来了很多开销和复杂性：需要负责构建每个制品并将其上传到制品库，并且客户需要确保自身保持最新版本。调试也变得更加困难，因为系统的不同部分是从存储库中的不同点构建的，并且不再有源代码库树的一致视图。</p><p>如前所述，如需解决制品构建时间较长的问题，一种更好的方式是使用支持远程缓存的构建系统。此类构建系统会将每个构建生成的制品保存到工程师共享的位置，因此如果开发者依赖其他人最近构建的制品，构建系统会自动下载无需构建。这样做提供了直接依赖于工件做法的所有性能优势，同时仍然确保构建与从同一源构建一样。这是 Google 内部使用的策略，Bazel 支持配置使用远程缓存。</p><h4 id="外部依赖的安全性和可靠性"><a href="#外部依赖的安全性和可靠性" class="headerlink" title="外部依赖的安全性和可靠性"></a>外部依赖的安全性和可靠性</h4><p>依赖于第三方来源的制品本身存在风险。如果第三方源代码（例如：制品库）发生故障，则会有可用性风险，因为如果无法下载外部依赖项，整个构建可能会停止。还有一种安全风险：如果第三方系统遭到攻击者入侵，攻击者可以将引用的制品替换为他们自己的设计之一，从而将任意代码注入到您的 build 中。将依赖的任何制品镜像到受控的服务器，并阻止构建系统访问 Maven Central 等第三方制品库，可以解决这两个问题。需要权衡的是，镜像需要精力和资源维护，因此，是否使用它们通常取决于项目的规模。通过在源存储库中指定每个第三方制品的哈希值，也可以完全防止安全问题，而开销很小，如果制品被篡改，则会导致构建失败。另一种完全回避问题的替代方法是拷贝（vendor）项目的依赖项。当项目拷贝（vendor）其依赖项时，它会将这些依赖项和项目的源代码（源代码或二进制文件）签入源代码控制系统。这实际上意味着，项目的所有外部依赖项都会转换为内部依赖项。Google 在内部使用此方法，将整个 Google 中引用的每个第三方库签入 Google 源代码树根目录下的 third_party 目录。但是，这仅在 Google 有效，因为 Google 的源代码控制系统是为了处理超大单一代码库而专门构建的，因此拷贝可能不适合所有组织。</p><p><em>原文：</em> <a href="https://bazel.build/basics/dependencies">Dependency Management</a></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/06-08-2022/dependency-management-cn.html">https://www.cyningsun.com/06-08-2022/dependency-management-cn.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;译者序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文为 Bazel 依赖管理的文章，介绍了大规模下依赖关系的复杂情况及其应对策略。从本文可以学到什么？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;了解构建系统依赖管理的基本情况&lt;/li&gt;
&lt;li&gt;理解 Gol</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>如何快速定位现网 BUG</title>
    <link href="https://www.cyningsun.com/09-13-2021/how-to-locate-bug-in-production-env.html"/>
    <id>https://www.cyningsun.com/09-13-2021/how-to-locate-bug-in-production-env.html</id>
    <published>2021-09-12T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.289Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/how-to-locate-bug-in-production-env/bugfix.jpg" alt="bugfix.jpg"></p><p>“幸福的家庭都是相似的，不幸的家庭却各有各的不幸”，托尔斯泰的名言。在 BUG 定位这件事情上，其实也有类似的现象：”菜鸟们的紧张无措都是相似的，老鸟们的方法却各有各的不同”。</p><p>年年过大促，年年定位现网故障。果不其然，今年 9.9 大促再次踩坑。看到组内的新手们排查问题的手足无措，也就有了这篇文档。本文的目的不在于穷举所有排查问题的手段，而在于帮助新手们避雷。</p><h3 id="蜻蜓点水"><a href="#蜻蜓点水" class="headerlink" title="蜻蜓点水"></a>蜻蜓点水</h3><p>当遇到无法轻易复现，并且缺少有用的日志辅助缺陷排查的时候，新手们的一般会选择去看代码。然而，最关键的点来了，他们并不是在真正看代码，他们只是印证自己”脑海中记忆的代码” 跟代码库里的是一致的。最常见的一个结果，就是得到一个 “代码是这样的呀、没有问题呀” 的结论。看代码过程是轻浮的，是跳跃的。</p><p>然而，计算机执行的并不是你脑海中的代码，而是实实在在的代码。计算机是严谨的、会一丝不苟的，从调用入口开始，一行不漏的逐行执行完毕，然后返回结果。任何细微的差异都有可能执行的是路径完全不同，而 BUG 就是因为走了跟预期不一样的执行路径。</p><p>看代码需要一行一行的看，一层层调用的展开。无论是自己编写的代码，还是开源仓库的代码，还是服务框架的代码，任何一行代码都不应该被跳过。</p><p>脚踏实地，而不是蜻蜓点水。</p><h3 id="轻视数据"><a href="#轻视数据" class="headerlink" title="轻视数据"></a>轻视数据</h3><p>大型复杂的系统产生了繁多的数据。不同的团队成员看到数据（事实）之后，会加入自己对数据的判断（观点），呈现出二次加工之后的数据。最终可能得到是一份夹杂了观点和事实的数据。</p><blockquote><p>当你听到蹄子声响时，你可以说听到了马蹄声，但实际上也可能是斑马蹄的声音，虽然概率很低。</p></blockquote><p>同时，就会出现以下类型的数据误用：</p><ul><li>不对数据数据进行汇总、分析，基于片面的数据进行假设</li><li>基于不可靠的数据，导致错误的假设</li></ul><p>基于错误的、片面的数据，进行假设，最终大概率是徒劳而无功。</p><p>靠谱的使用数据的方式，应当是团队成员把相关的数据汇聚，根据业务架构形成 “马赛克调查墙”，基于 “马赛克调查墙” 确定方向，再进行假设。</p><h3 id="轻视逻辑"><a href="#轻视逻辑" class="headerlink" title="轻视逻辑"></a>轻视逻辑</h3><p>很多很多人一上来就开始猜答案，基于他们认定的答案来提问，这是特别坏的一个习惯，因为这样找问题几乎就只能凭运气了。</p><p>“分治”（Divide &amp; Conquer）是一种非常通用的解决方案。在一个多层系统中，整套系统需要多层组件共同协作完成。最好的办法通常是从系统的一端开始，逐个检查每一个组件，直到系统最底层。这样的策略非常适用于数据处理流水线。在大型系统中，逐个检查可能太慢了，可以采用对分法（bisection）将系统分为两部分，确认问题所在再重复进行。逐项排除、层层递进，才能系统的剥离出真相。</p><p>还有一个常见的逻辑误区“相关性 = 因果性”。然而，相关性并不代表因果性。比如:</p><blockquote><p>统计表明，游泳死亡人数越高，冰糕卖得越多，也就是游泳死亡人数和冰糕售出量之间呈正相关性，我们可以由此得出结论说吃冰糕就会增加游泳死亡风险吗？显然不可以！这两个事件显然都仅仅是夏天到了气温升高了所导致的，吃不吃冰糕跟游泳死亡风险根本没有任何因果关系。</p></blockquote><p>同理，跟 BUG 相关的异常数据，不代表数据的操作导致了 BUG。为了论证因果关系，需要更加严密的实证来说明。按照相关理论复现所有 BUG 表现的特性，且只表现这些特征。</p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/09-13-2021/how-to-locate-bug-in-production-env.html">https://www.cyningsun.com/09-13-2021/how-to-locate-bug-in-production-env.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/images/how-to-locate-bug-in-production-env/bugfix.jpg&quot; alt=&quot;bugfix.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;“幸福的家庭都是相似的，不幸的家庭却各有各的不幸”，托尔斯泰的名言。在 BUG 定位这件事情</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>译｜There Are No Reference Types in Go</title>
    <link href="https://www.cyningsun.com/08-23-2021/there-are-no-reference-types-in-go-cn.html"/>
    <id>https://www.cyningsun.com/08-23-2021/there-are-no-reference-types-in-go-cn.html</id>
    <published>2021-08-22T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.289Z</updated>
    
    <content type="html"><![CDATA[<p>有一天，我用谷歌搜索一个 Go 问题，谷歌将我引导到 <a href="https://golang.org/doc/faq">Go FAQ</a> 页面。问题解决后，我阅读了整个 FAQ。</p><p>这是一次很棒的阅读，我从文章中学到了很多。但我注意到一个问题， <a href="https://golang.org/doc/faq#references">为什么数组是值,而 map、slice 和 channel 是引用</a>？答复如下：</p><blockquote><p>此话题历史久远。在早期，map 和 channel 都是语法指针，不能声明和使用非指针实例。此外，我们在竭尽全力探索数组如何工作。最终，我们认为指针和值的严格分离使语言更难使用。将这些类型更改为对关联的共享数据结构的引用，就解决了这些问题。改变给语言增加了一些令人遗憾的复杂性，但却对可用性产生了很大的影响：Go 一经推出，就成为了一种更高效、更舒服的语言。</p></blockquote><p>令我惊讶的是，Go 官方文档仍在使用<a href="https://github.com/golang/go/commit/b34f0551387fcf043d65cd7d96a0214956578f94">“引用类型”的概念</a>，因为自 <a href="https://github.com/golang/go/commit/b34f0551387fcf043d65cd7d96a0214956578f94">2013 年 4 月 3 日以来，“引用类型”的概念已从 Go 规范中完全删除</a>。现在 Go 规范中有 10 个“引用”词，没有一个代表“引用类型”的概念。</p><p>另一个惊喜是这句话：</p><blockquote><p>…指针和值的严格分离使该语言更难使用。…</p></blockquote><p>此答复将指针和值视为两个不兼容的概念。但是，Go 规范将指针视为特殊值，指针被称为“指针值”。值只是类型的实例。显然，Go 规范中“指针”一词的定义很好。我认为如果使用“指针值和非指针值”会更好。</p><p>所以，我认为此答复给 <a href="https://www.reddit.com/r/golang/comments/4vg7ht/why_are_there_so_many_different_ways_to_pass_by/">Go 社区带来了很多困惑</a>。它与当前 Go 规范冲突，并且打破了概念的一致性。</p><p>谈回第一个惊喜，我认为称呼  map/slice/channel 值为引用值完全没有必要。不仅因为 “reference” 这个词在编程世界中被滥用了，还因为 map/slice/channel 值只是普通的正常值</p><p>以下是 map/slice/channel 类型的内部声明：</p><div class="table-container"><table><thead><tr><th>Type Family</th><th>Type Declaration</th></tr></thead><tbody><tr><td>map</td><td>struct {<br/> m *internalHashtable <br/>}</td></tr><tr><td>channel</td><td>struct {<br/>  c *internalChannel <br/>}</td></tr><tr><td>slice</td><td>struct {<br/> array *internalArray <br/> len   int <br/> cap   int<br/> }</td></tr></tbody></table></div><p>请注意，上面的声明可能不完全与官方或非官方的 Go 实现中的声明相同。Go 实现可以直接使用指针表示 map 和 channel 的值，但 Go 规范/编译器永远不会将它们视为指针。因此，你可以放心的将 map/slice/channel 类型视为上面声明的指针包装类型，而不会有任何问题。</p><p>从上面的声明，很容易得出结论：map/slice/channel 只是包含一个非导出指针字段的结构类型。将它们称为引用类型是完全没有必要的。</p><p>Map 和 slice 类型与一般结构类型确实有一个区别。与一般结构类型不同，对于 map 或 slice 类型 T，T{}  不是 T 的零值。但这不是将 map 或 slice 类型拆分为新的引用类型类别的好理由。</p><p>通过理解 Go 的以下两个规则：</p><ul><li>map/slice/channel 值只是普通的指针包装结构的值</li><li>所有赋值，包括参数传递等，都是浅值复制（指针指向的值不会被复制）</li></ul><p>Gopher 应该清楚地理解赋值中的 dest 和 source  map/slice/channel 值将共享被包装的指针所指向的同一底层数据。</p><p>概念是用来帮助程序员理解语言的机制，而不是混淆他们。值、指针值和非指针值的概念足以让 Gopher 理解 Go。</p><p>我希望 Go 文档不会破坏概念定义的一致性。</p><p><em>原文：</em><a href="https://www.tapirgames.com/blog/golang-has-no-reference-values">https://www.tapirgames.com/blog/golang-has-no-reference-values</a></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/08-23-2021/there-are-no-reference-types-in-go-cn.html">https://www.cyningsun.com/08-23-2021/there-are-no-reference-types-in-go-cn.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;有一天，我用谷歌搜索一个 Go 问题，谷歌将我引导到 &lt;a href=&quot;https://golang.org/doc/faq&quot;&gt;Go FAQ&lt;/a&gt; 页面。问题解决后，我阅读了整个 FAQ。&lt;/p&gt;
&lt;p&gt;这是一次很棒的阅读，我从文章中学到了很多。但我注意到一个问题， &lt;a</summary>
      
    
    
    
    <category term="Golang" scheme="https://www.cyningsun.com/category/Golang/"/>
    
    
    <category term="Pointer" scheme="https://www.cyningsun.com/tag/Pointer/"/>
    
  </entry>
  
  <entry>
    <title>Go 语言没有引用类型，指针也与众不同</title>
    <link href="https://www.cyningsun.com/08-16-2021/go-has-no-reference-and-safe-pointer.html"/>
    <id>https://www.cyningsun.com/08-16-2021/go-has-no-reference-and-safe-pointer.html</id>
    <published>2021-08-15T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.289Z</updated>
    
    <content type="html"><![CDATA[<p>面向对象编程强调数据和操作绑定，方法是有状态的，本身可能会修改数据。因此编程时确定方法是否会修改原始数据尤其关键。多数从其他语言转到 Go 语言的开发者，都会首先了解 Go 语言传递参数的时候到底是 “传值” 还是 “传引用”。如果第一门开发语言是 C 语言或者 C++ 的开发者，还会区分下什么时候 “传指针”。</p><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><h4 id="什么是内存？"><a href="#什么是内存？" class="headerlink" title="什么是内存？"></a>什么是内存？</h4><p>可以把内存想想为一系列单元格，一个个排列成一行，每个单元格都有一个唯一的编号。编号顺序递增，代表内存的位置，也即是内存地址。</p><p><img src="/images/go-has-no-reference-and-safe-pointer/pointer-memory.png" alt="pointer-memory.png"></p><p>每个单元格都可以存放一个值，可以通过编号读取和替换单元格内的先前写入的值。</p><h4 id="什么是变量？"><a href="#什么是变量？" class="headerlink" title="什么是变量？"></a>什么是变量？</h4><p>糟糕的是，如果直接使用编号编程，就需要开发者自己管理内存，也难以和其他程序同时运行，极大的增加了编写大型程序的难度。</p><p>为了解决这个问题，就需要引入“变量”的概念。变量只是编号的假名、标签或昵称。</p><p><img src="/images/go-has-no-reference-and-safe-pointer/pointer-memory-multiply.png" alt="pointer-memory-multiply.png"></p><pre><code class="hljs go"><span class="hljs-keyword">var</span> a = <span class="hljs-number">6</span><span class="hljs-keyword">var</span> b = a * <span class="hljs-number">3</span></code></pre><h4 id="什么是指针？"><a href="#什么是指针？" class="headerlink" title="什么是指针？"></a>什么是指针？</h4><p>而指针的值是另一个变量的编号。指针指向变量的内存地址，就像变量代表值的内存地址一样。</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;        a := <span class="hljs-number">200</span>        b := &amp;a        *b++        fmt.Println(a)&#125;</code></pre><p><img src="/images/go-has-no-reference-and-safe-pointer/pointer-memory-variable.png" alt="pointer-memory-variable.png"></p><h4 id="什么是引用？"><a href="#什么是引用？" class="headerlink" title="什么是引用？"></a>什么是引用？</h4><p>在 C++ 语言中，为现有变量声明别名，称为引用变量。如代码所示，a、b、c 三个变量均共享同一内存地址</p><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-type">int</span> a = <span class="hljs-number">10</span>;        <span class="hljs-type">int</span> &amp;b = a;        <span class="hljs-type">int</span> &amp;c = b;        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%p %p %p\n&quot;</span>, &amp;a, &amp;b, &amp;c); <span class="hljs-comment">// 0x7ffe114f0b14 0x7ffe114f0b14 0x7ffe114f0b14</span>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><h3 id="Go-语言没有引用类型"><a href="#Go-语言没有引用类型" class="headerlink" title="Go 语言没有引用类型"></a>Go 语言没有引用类型</h3><p>Go 程序可以创建指向统一内存地址的变量，但无法创建共享相同内存地址的两个变量。如代码所示，b 和 c 具有相同的值（a的地址）但是，b 和 c 的内存地址是唯一的。更新 b 的内容对 c 没有影响。</p><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;        <span class="hljs-keyword">var</span> a <span class="hljs-type">int</span>        <span class="hljs-keyword">var</span> b, c = &amp;a, &amp;a        fmt.Println(b, c)   <span class="hljs-comment">// 0x1040a124 0x1040a124</span>        fmt.Println(&amp;b, &amp;c) <span class="hljs-comment">// 0x1040c108 0x1040c110</span>&#125;</code></pre><p><a href="https://github.com/golang/go/commit/b34f0551387fcf043d65cd7d96a0214956578f94">2013年4月3日，“引用类型”的概念已从 Go 规范中完全删除</a>,现在 Go 规范中的“引用”，没有一个代表“引用类型”的概念。</p><h3 id="指针是类型吗？"><a href="#指针是类型吗？" class="headerlink" title="指针是类型吗？"></a>指针是类型吗？</h3><p>指针是类型吗？这个问题可能在 C 或 C++ 中会有比较大的分歧，但是在 Go 语言中十分明确，毫无疑问：<a href="https://golang.org/ref/spec#Pointer_types">是的</a>。</p><blockquote><p>A pointer type denotes the set of all pointers to variables of a given type, called the base type of the pointer. The value of an uninitialized pointer is nil.</p></blockquote><p>既然有类型，就有类型的实例：值，类型和值是截然不同的两个概念。显然，在 Go 语言中，当谈到指针时，包含 “指针类型” 和 “指针值”。</p><p>同时，为了避免指针引入的风险， Go 语言对指针做了不少的约束，如下：</p><ol><li>指针值不支持数学运算</li></ol><pre><code class="hljs go"><span class="hljs-keyword">var</span> p *<span class="hljs-type">int</span>p++</code></pre><p>你不能更改指针指向的位置，除非赋值另外一个地址给它。同时也就不支持 <a href="https://maryash.github.io/135/slides/7.2%20Arrays%20and%20Pointers.pdf">Array-Pointer Duality</a>。</p><ol><li>base type 不同的指针值，无法直接互相赋值</li></ol><pre><code class="hljs go"><span class="hljs-keyword">type</span> MyInt <span class="hljs-type">int64</span><span class="hljs-keyword">type</span> Ta    *<span class="hljs-type">int64</span><span class="hljs-keyword">type</span> Tb    *MyInt<span class="hljs-comment">// 4 nil pointers of different types.</span><span class="hljs-keyword">var</span> pa0 Ta<span class="hljs-keyword">var</span> pa1 *<span class="hljs-type">int64</span><span class="hljs-keyword">var</span> pb0 Tb<span class="hljs-keyword">var</span> pb1 *MyInt   <span class="hljs-comment">// None of the following 3 lines compile ok.</span><span class="hljs-comment">/*</span><span class="hljs-comment">_ = pa0 == pb0</span><span class="hljs-comment">_ = pa1 == pb1</span><span class="hljs-comment">_ = pa0 == Tb(nil)</span><span class="hljs-comment">*/</span></code></pre><ol><li>返回局部变量的指针是安全的</li></ol><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">f</span><span class="hljs-params">()</span></span> *<span class="hljs-type">int</span> &#123;   i := <span class="hljs-number">1</span>  <span class="hljs-keyword">return</span> &amp;i&#125;</code></pre><h3 id="指针总结"><a href="#指针总结" class="headerlink" title="指针总结"></a>指针总结</h3><p>使用过 C/C++ 语言的开发者，习惯使用的不安全的指针是 <code>unsafe.Pointer</code>，而非普通的指针。</p><pre><code class="hljs C++"><span class="hljs-type">int</span>* valFirst<span class="hljs-type">intptr_t</span> valSecond<span class="hljs-type">void</span>* valThird</code></pre><p>vs</p><pre><code class="hljs go"><span class="hljs-type">int</span>* valFirst<span class="hljs-keyword">type</span> intptr_t *<span class="hljs-type">int</span>intptr_t valSecondunsafe.Pointer valThird</code></pre><p>对比服用，效果更佳。</p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/08-16-2021/go-has-no-reference-and-safe-pointer.html">https://www.cyningsun.com/08-16-2021/go-has-no-reference-and-safe-pointer.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;面向对象编程强调数据和操作绑定，方法是有状态的，本身可能会修改数据。因此编程时确定方法是否会修改原始数据尤其关键。多数从其他语言转到 Go 语言的开发者，都会首先了解 Go 语言传递参数的时候到底是 “传值” 还是 “传引用”。如果第一门开发语言是 C 语言或者 C++ 的</summary>
      
    
    
    
    <category term="Golang" scheme="https://www.cyningsun.com/category/Golang/"/>
    
    
    <category term="Pointer" scheme="https://www.cyningsun.com/tag/Pointer/"/>
    
  </entry>
  
  <entry>
    <title>译｜What “accept interfaces, return structs” means in Go</title>
    <link href="https://www.cyningsun.com/08-08-2021/go-accept-interfaces-return-structs.html"/>
    <id>https://www.cyningsun.com/08-08-2021/go-accept-interfaces-return-structs.html</id>
    <published>2021-08-07T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.289Z</updated>
    
    <content type="html"><![CDATA[<p>“接受接口、返回结构” 的一般原则，我在前一篇文章中写到，也多次在代码评审时向同事介绍，但经常遇到“为什么”的疑问。特别是因为这不是一条硬性规定。该想法的关键在于保持灵活性的同时避免预先抽象，并理解何时改变它。</p><p><img src="/images/accept-interfaces-return-structs/gopher.png" alt="gopher.png"></p><h3 id="预先抽象使系统变得复杂"><a href="#预先抽象使系统变得复杂" class="headerlink" title="预先抽象使系统变得复杂"></a>预先抽象使系统变得复杂</h3><blockquote><p>计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决，当然，间接过多的问题除外 - David J. Wheeler</p></blockquote><p>软件工程师喜欢抽象。就我个人而言，从未见过编写代码比创建抽象更投入的同事。Go 中，接口抽象脱离了结构，该间接层甚至没有最低层次的嵌入复杂性。遵循软件设计 <a href="http://c2.com/xp/YouArentGonnaNeedIt.html">您不会用到它</a> 的哲学，在需要之前制造这种复杂性毫无意义。函数调用返回接口的一个常见原因是让用户专注于函数开放的 API。因为有隐式接口，Go 不需要这样做。结构的 public function iu 就是其 API。</p><blockquote><p>总是当 <strong>真正</strong> 需要时 [抽象]，不要当 <strong>预见</strong> 需要时 [抽象]。</p></blockquote><p>某些语言要求你预见未来需要的每个接口。隐式接口的一大优点是，它们允许事后进行优雅的抽象，而无需预先进行抽象。</p><h3 id="因人而异的“需要”"><a href="#因人而异的“需要”" class="headerlink" title="因人而异的“需要”"></a>因人而异的“需要”</h3><blockquote><p>当真正需要时</p></blockquote><p>如何定义何时需要抽象？对于返回类型，这很容易。你是编写该函数的人，因此您确切知道何时需要将返回值抽象。</p><p>对于函数输入，需求不在你的控制范围之内。你可能认为 database struct 就足够了，但用户可能需要用其他东西装饰它。就算不是不可能，预测每个人使用你的函数的状态也是很困难的。能够精确控制输出，但无法预测用户输入。相比对输出的抽象化，这种不平衡造成了对输入的抽象化更强烈的偏重。</p><h3 id="去除不必要的代码细节"><a href="#去除不必要的代码细节" class="headerlink" title="去除不必要的代码细节"></a>去除不必要的代码细节</h3><p><img src="/images/accept-interfaces-return-structs/recipes.png" alt="recipes.png"></p><p>简化的另一方面是去除不必要的细节。函数就像烹饪食谱：给定输入，就会得到一个蛋糕！没有食谱会列出不需要的配料。类似地，函数也不应该列出不需要的输入。你如何看以下函数？</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">addNumbers</span><span class="hljs-params">(a <span class="hljs-type">int</span>, b <span class="hljs-type">int</span>, s <span class="hljs-type">string</span>)</span></span> <span class="hljs-type">int</span> &#123;     <span class="hljs-keyword">return</span> a + b &#125;</code></pre><p>对于大多数程序员来说，很明显，参数 s 不恰当。当参数是结构时，却不太明显。</p><pre><code class="hljs go"><span class="hljs-keyword">type</span> Database <span class="hljs-keyword">struct</span>&#123; &#125; <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d *Database)</span></span> AddUser(s <span class="hljs-type">string</span>) &#123;...&#125; <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d *Database)</span></span> RemoveUser(s <span class="hljs-type">string</span>) &#123;...&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewUser</span><span class="hljs-params">(d *Database, firstName <span class="hljs-type">string</span>, lastName <span class="hljs-type">string</span>)</span></span> &#123;     d.AddUser(firstName + lastName) &#125;</code></pre><p>就像配料太多的食谱一样，NewUser 接收一个可以做太多事情的 Database 对象。它只需要 AddUser，但接收的参数还有 RemoveUser。使用接口创建的函数，可以只依赖于必需。</p><pre><code class="hljs go"><span class="hljs-keyword">type</span> DatabaseWriter <span class="hljs-keyword">interface</span> &#123;     AddUser(<span class="hljs-type">string</span>) &#125; <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewUser</span><span class="hljs-params">(d DatabaseWriter, firstName <span class="hljs-type">string</span>, lastName <span class="hljs-type">string</span>)</span></span> &#123;     d.AddUser(firstName + lastName) &#125;</code></pre><p>Dave Cheney 在描述 <a href="https://en.wikipedia.org/wiki/Interface_segregation_principle">接口隔离原则</a> 时 <a href="https://dave.cheney.net/2016/08/20/solid-go-design">写到了这一点</a>。他还描述了限制输入的其他优点，值得一读。让人理解这个想法的总目标是：</p><blockquote><p>结果同时是一个函数，它的要求是最具体的——它只需要一个可写的东西——并且它的函数是最通用的</p></blockquote><p>我只想补充一点，上面的函数 addNumber 显然不应该有参数字符串 s，函数 NewUser 理想情况下不需要可以删除用户的 database。</p><h3 id="总结原因并审查例外"><a href="#总结原因并审查例外" class="headerlink" title="总结原因并审查例外"></a>总结原因并审查例外</h3><p>主要原因如下：</p><ul><li>去除不需要的抽象</li><li>用户对函数输入需求是模糊的</li><li>简化函数输入</li></ul><p>以上原因还允许我们定义规则的例外情况。例如，如果函数需要返回多种类型，那么显然返回需要定义为接口。类似地，如果函数是私有的，那么函数输入便并不模糊，因为你可以控制它，所以倾向于非预先抽象。对于第三条规则，go 没有办法抽象出 struct 成员的值。因此，如果你的函数需要访问结构体成员（而不仅仅是结构体上的函数），那么您将被迫直接接受结构体。</p><p><em>原文：</em>  <a href="https://medium.com/@cep21/what-accept-interfaces-return-structs-means-in-go-2fe879e25ee8">What “accept interfaces, return structs” means in Go</a></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/08-08-2021/go-accept-interfaces-return-structs.html">https://www.cyningsun.com/08-08-2021/go-accept-interfaces-return-structs.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;“接受接口、返回结构” 的一般原则，我在前一篇文章中写到，也多次在代码评审时向同事介绍，但经常遇到“为什么”的疑问。特别是因为这不是一条硬性规定。该想法的关键在于保持灵活性的同时避免预先抽象，并理解何时改变它。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/accept</summary>
      
    
    
    
    <category term="Golang" scheme="https://www.cyningsun.com/category/Golang/"/>
    
    
    <category term="Interface" scheme="https://www.cyningsun.com/tag/Interface/"/>
    
  </entry>
  
  <entry>
    <title>如何用好 Go interface</title>
    <link href="https://www.cyningsun.com/08-02-2021/using-golang-interface-well.html"/>
    <id>https://www.cyningsun.com/08-02-2021/using-golang-interface-well.html</id>
    <published>2021-08-01T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.289Z</updated>
    
    <content type="html"><![CDATA[<p><code>interface</code> 是 Go 语言最精髓的特性之一，一直以来想写一篇关于 <code>interface</code> 的文章，但是一直没敢写。持续几年之久，还是斗胆总结下。</p><h3 id="Concrete-types"><a href="#Concrete-types" class="headerlink" title="Concrete types"></a>Concrete types</h3><p>struct 定义数据的内存布局。一些早期建议将方法包含在 struct 中，但是被放弃了。相反，方法如普通函数一样声明在类型之外。描述 (data) 和行为 (methods) 是独立且正交的。</p><p>一方面，方法只是一个带有 “receiver” 参数的函数。<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> Point <span class="hljs-keyword">struct</span> &#123; x, y float &#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p Point)</span></span> Abs() float &#123;    <span class="hljs-keyword">return</span> math.Sqrt(p.x*p.x + p.y*p.y)&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Abs</span><span class="hljs-params">(p Point)</span></span> float &#123;<span class="hljs-keyword">return</span> math.Sqrt(p.x*p.x + p.y*p.y)&#125;</code></pre><br><code>Abs</code> 编写为一个常规函数，功能没有变化。</p><blockquote><p>什么时候应该使用方法，什么时候应该使用函数呢？如果方法不依赖类型的状态，则应该将其定义为函数。</p></blockquote><p>另一方面，方法在定义其行为时，使用了类型的值时，与所附加的类型紧密关联。方法可以从对应的类型中获取值，如果有指针 “receiver”，还可以操纵其状态。</p><p>“类型” 有时候很有用，有时候又很讨厌。因为类型是对底层内存布局的一个抽象，会让代码关注于非业务逻辑上的东西，然而代码又需要在不同类型的数据间做处理。interface 就是其中一种泛型解决方案。<br><pre><code class="hljs go"><span class="hljs-comment">// Package sort provides primitives for sorting slices and user-defined collections.</span><span class="hljs-keyword">package</span> sort<span class="hljs-comment">// An implementation of Interface can be sorted by the routines in this package.</span><span class="hljs-comment">// The methods refer to elements of the underlying collection by integer index.</span><span class="hljs-keyword">type</span> Interface <span class="hljs-keyword">interface</span> &#123;<span class="hljs-comment">// Len is the number of elements in the collection.</span>Len() <span class="hljs-type">int</span><span class="hljs-comment">// Less reports whether the element with index i</span><span class="hljs-comment">// must sort before the element with index j.</span>Less(i, j <span class="hljs-type">int</span>) <span class="hljs-type">bool</span><span class="hljs-comment">// Swap swaps the elements with indexes i and j.</span>Swap(i, j <span class="hljs-type">int</span>)&#125;<span class="hljs-comment">// Sort sorts data.</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Sort</span><span class="hljs-params">(data Interface)</span></span> &#123;    ...&#125;</code></pre></p><h3 id="Abstract-types"><a href="#Abstract-types" class="headerlink" title="Abstract types"></a>Abstract types</h3><p>Go 的 interface 仅仅是函数的集合，也定义了行为。 interface 与类型之间没有显式的关系，类型也可以同时满足多个 interface 的要求。<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> Abser <span class="hljs-keyword">interface</span> &#123;    Abs() float &#125;  <span class="hljs-keyword">var</span> a Abser a = Point&#123;<span class="hljs-number">3</span>, <span class="hljs-number">4</span>&#125; <span class="hljs-built_in">print</span>(a.Abs()) a = Vector&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>&#125; <span class="hljs-built_in">print</span>(a.Abs())</code></pre><br>Point 和 Vector 满足 Abser 的要求同时，也符合 interface{} 的要求。不同的是，interface{} 没有任何行为（method）。</p><h3 id="When-amp-How"><a href="#When-amp-How" class="headerlink" title="When &amp; How"></a>When &amp; How</h3><p>道理我都懂，但是何时使用，如何使用 interface 呢？</p><p>答案是，当不需要关心实现细节的时候？</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">fn</span><span class="hljs-params">(Parameter)</span></span> Result</code></pre><p>当函数编写者希望隐藏实现细节时，应该把 Result 设定为 interface；当函数编写者希望提供扩展点的时候，应当把 Parameter 设定为 interface；</p><h4 id="隐藏实现细节"><a href="#隐藏实现细节" class="headerlink" title="隐藏实现细节"></a>隐藏实现细节</h4><p>以 CancelCtx 为例:<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> Context <span class="hljs-keyword">interface</span> &#123;Deadline() (deadline time.Time, ok <span class="hljs-type">bool</span>)Done() &lt;-<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;Err() <span class="hljs-type">error</span>Value(key <span class="hljs-keyword">interface</span>&#123;&#125;) <span class="hljs-keyword">interface</span>&#123;&#125;&#125;<span class="hljs-comment">// newCancelCtx returns an initialized cancelCtx.</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newCancelCtx</span><span class="hljs-params">(parent Context)</span></span> cancelCtx &#123;<span class="hljs-keyword">return</span> cancelCtx&#123;Context: parent&#125;&#125;<span class="hljs-keyword">type</span> cancelCtx <span class="hljs-keyword">struct</span> &#123;...&#125;</code></pre><br>newCancelCtx 返回值为 <code>cancelCtx</code>。注意到 cancelCtx 是没有导出的，意味着使用者只能使用 Context 的变量来接收 newCancelCtx 返回值，从而达到隐藏实现的目的。cancelCtx 是否还有其他方法，以及具体如何实现，使用者并无感知。</p><h4 id="提供扩展点"><a href="#提供扩展点" class="headerlink" title="提供扩展点"></a>提供扩展点</h4><p>当我们需要将文档持久化<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> Document <span class="hljs-keyword">struct</span> &#123;    ...&#125;<span class="hljs-comment">// Save writes the contents of the Document to the file f.</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d *Document)</span></span> Save(f *os.File) <span class="hljs-type">error</span></code></pre><br>假如实现如上，Save 方法将 *os.File 作为写入的目标。但是此实现存在一些问题：</p><ol><li>该实现排除了将数据写入网络位置的选项。假设网络存储成为需求，则此函数的签名必须更改，从而影响其所有调用者。</li><li>该实现很难测试。为了验证其操作，测试必须在写入文件后读取文件的内容。还必须确保 f 被写入到临时位置，并始终在之后删除。</li><li>*os.File 暴露了许多与 Save 无关的方法，比如读取目录和检查路径是否为符号链接。</li></ol><p>可以使用接口隔离原则重新定义该方法，优化实现为：<br><pre><code class="hljs go"><span class="hljs-comment">// Save writes the contents of d to the supplied ReadWriterCloser.</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d *Document)</span></span> Save(rwc io.ReadWriteCloser) <span class="hljs-type">error</span></code></pre></p><p>然而，此方法仍然违反单一职责原则，它同时负责读取和验证写入的内容。将此部分责任拆分走，继续优化为：<br><pre><code class="hljs go"><span class="hljs-comment">// Save writes the contents of d to the supplied WriteCloser.</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d *Document)</span></span> Save(wc io.WriteCloser) <span class="hljs-type">error</span></code></pre><br>然而，wc 会在什么情况下关闭。可能 Save 将无条件调用 Close，或者在成功的情况下调用 Close，以上都不是一个好的选择。因此再次优化<br><pre><code class="hljs go"><span class="hljs-comment">// WriteTo writes the contents of d to the supplied Writer.</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d *Document)</span></span> WriteTo(w io.Writer) <span class="hljs-type">error</span></code></pre></p><p>接口声明了调用方需要的行为，而不是类型将提供的行为。行为的提供方具有高度的扩展空间，例如：装饰器模式扩展该行为。<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> LogWriter <span class="hljs-keyword">struct</span> &#123;    w  io.Writer&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *LogWriter)</span></span>Write(p []<span class="hljs-type">byte</span>) (n <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>) &#123;    fmt.Printf(<span class="hljs-string">&quot;write len:%v&quot;</span>, <span class="hljs-built_in">len</span>(p))    <span class="hljs-keyword">return</span> l.w.Write(r)&#125;</code></pre></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>关于 interface，很喜欢以下两句箴言：</p><blockquote><p> Program to an ‘interface’, not an ‘implementation’ —— GoF<br> Be conservative in what you do, be liberal in what you accept from others —— Robustness Principle</p></blockquote><p>而不是</p><blockquote><p>Return concrete types, receive interfaces as parameter<br>（由 cancelCtx 的例子可知，如果其类型是导出的 CancelCtx，返回 concrete types 与以上箴言是有出入的）</p></blockquote><p>高级语言赋予了开发者高级的能力，让开发者不要关注具体值、类型，集中精力去处理业务逻辑（行为，method），interface 提供的就是这种能力。除了 interface，其他问题处理也是基于类似的思路：</p><blockquote><p><a href="/09-09-2019/dont-just-check-errors-handle-them-gracefully-cn.html">Don’t just check errors, handle them gracefully</a><br>基于行为处理错误，而不是基于值或类型</p></blockquote><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/08-02-2021/using-golang-interface-well.html">https://www.cyningsun.com/08-02-2021/using-golang-interface-well.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;code&gt;interface&lt;/code&gt; 是 Go 语言最精髓的特性之一，一直以来想写一篇关于 &lt;code&gt;interface&lt;/code&gt; 的文章，但是一直没敢写。持续几年之久，还是斗胆总结下。&lt;/p&gt;
&lt;h3 id=&quot;Concrete-types&quot;&gt;&lt;a href=</summary>
      
    
    
    
    <category term="Golang" scheme="https://www.cyningsun.com/category/Golang/"/>
    
    
    <category term="Interface" scheme="https://www.cyningsun.com/tag/Interface/"/>
    
  </entry>
  
  <entry>
    <title>一个优雅的 LRU 缓存实现</title>
    <link href="https://www.cyningsun.com/07-26-2021/go-a-graceful-lru-implement.html"/>
    <id>https://www.cyningsun.com/07-26-2021/go-a-graceful-lru-implement.html</id>
    <published>2021-07-25T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.289Z</updated>
    
    <content type="html"><![CDATA[<p>Golang 的各种组件很灵活也很强大，但对于初级入门的使用者来说，要用好着实不易。最近，在开发一个可以拿来即用的 golang 库。第一个组件选择了缓存，主要是因为这个组件非常的关键，但也非常不容易实现好。</p><h3 id="第一步：定义-Cache-接口"><a href="#第一步：定义-Cache-接口" class="headerlink" title="第一步：定义 Cache 接口"></a>第一步：定义 Cache 接口</h3><p>设计一个高扩展的缓存包，就需要利用 <a href="/08-03-2019/solid-go-design-cn.html">里氏替换原则（Liskov Substitution Principle）</a>，做好抽象，将缓存定义为接口<br><pre><code class="hljs ada"><span class="hljs-keyword">type</span> <span class="hljs-type">Cache </span><span class="hljs-keyword">interface</span> &#123;    ...&#125;</code></pre></p><h3 id="第二步：组织包结构"><a href="#第二步：组织包结构" class="headerlink" title="第二步：组织包结构"></a>第二步：组织包结构</h3><p>然后，实现一个具体的 LRU 缓存，那么此时首先要组织好包结构，如下：<br><pre><code class="hljs bash">|-cache| |-lru| | |-lru.go| | |-segment.go| | |-options.go| | |-expvar.go|-cache.go</code></pre></p><p><a href="/03-03-2021/packages-as-layers-not-groups-cn.html">利用包划分层次</a>，将接口放在根包下，作为所有子包的通用语言：<br><pre><code class="hljs ada">// cache.go<span class="hljs-keyword">package</span> <span class="hljs-title">edge</span><span class="hljs-keyword">type</span> <span class="hljs-type">Cache </span><span class="hljs-keyword">interface</span> &#123;    ...&#125;</code></pre></p><h3 id="第三步：实现-LRU-缓存"><a href="#第三步：实现-LRU-缓存" class="headerlink" title="第三步：实现 LRU 缓存"></a>第三步：实现 LRU 缓存</h3><ol><li>为了防止锁竞争导致的性能低下，此处使用分段加锁的方式降低锁粒度以提高缓存性能</li><li>同时将 <code>segment</code>、<code>newSegment</code>、<code>cache</code> 以小写命名，避免对外暴露实现细节</li><li>使用 <a href="/07-19-2021/go-higher-order-function.html"><code>Higher-order function</code></a>，实现可扩展的配置参数</li><li>使用 <code>expvar</code> 暴露缓存的状态</li></ol><pre><code class="hljs go"><span class="hljs-comment">// lru.go</span><span class="hljs-keyword">package</span> lru<span class="hljs-keyword">type</span> cache <span class="hljs-keyword">struct</span> &#123;    ...&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">New</span><span class="hljs-params">(opts ...Opt)</span></span> (*cache, <span class="hljs-type">error</span>) &#123;    ...&#125;<span class="hljs-comment">// segment.go</span><span class="hljs-keyword">package</span> lru<span class="hljs-keyword">type</span> segment <span class="hljs-keyword">struct</span> &#123;    ...&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newSegment</span><span class="hljs-params">(c <span class="hljs-type">int</span>)</span></span> *segment &#123;    ...&#125;<span class="hljs-comment">// options.go</span><span class="hljs-keyword">type</span> options <span class="hljs-keyword">struct</span> &#123;    ...&#125;<span class="hljs-keyword">type</span> Opt <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(*options)</span></span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithConcurrency</span><span class="hljs-params">(c <span class="hljs-type">int</span>)</span></span> Opt &#123;<span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(o *options)</span></span> &#123;o.concurrency = c&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithCapacity</span><span class="hljs-params">(c <span class="hljs-type">int</span>)</span></span> Opt &#123;<span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(o *options)</span></span> &#123;o.capacity = c&#125;&#125;<span class="hljs-comment">// expvar.go</span><span class="hljs-keyword">var</span> m = <span class="hljs-keyword">struct</span> &#123;Get    *expvar.IntSet    *expvar.IntDelete *expvar.IntExists *expvar.IntHit    *expvar.IntEvict  *expvar.Int&#125;&#123;Get:    expvar.NewInt(<span class="hljs-string">&quot;cache.lru.get&quot;</span>),Set:    expvar.NewInt(<span class="hljs-string">&quot;cache.lru.set&quot;</span>),Delete: expvar.NewInt(<span class="hljs-string">&quot;cache.lru.delete&quot;</span>),Exists: expvar.NewInt(<span class="hljs-string">&quot;cache.lru.exists&quot;</span>),Hit:    expvar.NewInt(<span class="hljs-string">&quot;cache.lru.hit&quot;</span>),Evict:  expvar.NewInt(<span class="hljs-string">&quot;cache.lru.evict&quot;</span>),&#125;</code></pre><h3 id="第四步：结束了么？"><a href="#第四步：结束了么？" class="headerlink" title="第四步：结束了么？"></a>第四步：结束了么？</h3><p>当然没有，从以上可以看到，以下几点：</p><ol><li>options 可以做到多种实现共用，更应该放在 cache 文件夹下。</li><li>在使用时，lru.New() 赋值给 Cache 接口略微不自然</li><li>segment.go 和 expvar.go 未对使用者开放但文件却对外暴露</li><li>segment 可能后续会用来实现其他缓存算法，也不适合放在 lru 包下</li></ol><p>基于以上原因，再次调整包结构如下：<br><pre><code class="hljs bash">|-cache| |-options.go| |-lru.go|-cache.go|-internal| |-cache| | |-lru| | | |-expvar.go| | | |-segment.go</code></pre></p><p>同时，调整 LRU 缓存的接口为：<br><pre><code class="hljs go"><span class="hljs-comment">// cache.go</span><span class="hljs-keyword">package</span> cache<span class="hljs-keyword">type</span> cache <span class="hljs-keyword">struct</span> &#123;    ...&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewLRU</span><span class="hljs-params">(opts ...Opt)</span></span> (*cache, <span class="hljs-type">error</span>) &#123;    ...&#125;</code></pre></p><p>是不是自然了很多，使用示例：<br><pre><code class="hljs go"><span class="hljs-keyword">var</span> c edge.Cache = cache.NewLRU()</code></pre></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>学以致用，此 LRU 的实现应用了很多之前的知识。追求优秀代码的路是没有尽头的，下课。</p><p>源代码：<a href="https://github.com/cyningsun/edge">github.com/cyningsun/edge</a></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/07-26-2021/go-a-graceful-lru-implement.html">https://www.cyningsun.com/07-26-2021/go-a-graceful-lru-implement.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Golang 的各种组件很灵活也很强大，但对于初级入门的使用者来说，要用好着实不易。最近，在开发一个可以拿来即用的 golang 库。第一个组件选择了缓存，主要是因为这个组件非常的关键，但也非常不容易实现好。&lt;/p&gt;
&lt;h3 id=&quot;第一步：定义-Cache-接口&quot;&gt;&lt;a </summary>
      
    
    
    
    <category term="Golang" scheme="https://www.cyningsun.com/category/Golang/"/>
    
    
    <category term="Programming style" scheme="https://www.cyningsun.com/tag/Programming-style/"/>
    
  </entry>
  
  <entry>
    <title>Go 函数式编程：Higher-order function</title>
    <link href="https://www.cyningsun.com/07-19-2021/go-higher-order-function.html"/>
    <id>https://www.cyningsun.com/07-19-2021/go-higher-order-function.html</id>
    <published>2021-07-18T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.289Z</updated>
    
    <content type="html"><![CDATA[<p>在请求处理过程中，应用程序会接受和处理请求，然后返回响应结果。在该过程中，还存在一些通用的功能，例如：鉴权、监控、链路追踪。众多 RPC 框架会提供称之为 Middleware 或者 Interceptor 等概念，以可插拔的方式来支持上述谈到的众多功能。以 gRPC 为例，工作原理如图：</p><p><img src="/images/go-higher-order-function/grpc-interceptors.png" alt="grpc-interceptors.png"></p><p>其服务端的接口如下所示：<br><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">UnaryServerInterceptor</span><span class="hljs-params">(ctx context.Context, req <span class="hljs-keyword">interface</span>&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler)</span></span> (<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>)<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">StreamServerInterceptor</span> <span class="hljs-params">(srv <span class="hljs-keyword">interface</span>&#123;&#125;, stream grpc.ServerStream, info *grpc.StreamServerInfo, handler grpc.StreamHandler)</span></span> <span class="hljs-type">error</span></code></pre></p><p>可以看到，接口明确定义了输入参数，输出结果。如果我们要自己实现一个组件，需要支持使用者传入特定的配置，有没有什么办法可以做到呢？</p><p>答案是肯定的。</p><h3 id="Higher-order-function"><a href="#Higher-order-function" class="headerlink" title="Higher-order function"></a>Higher-order function</h3><p>在了解具体的解决方案之前，需要先了解一个概念叫<code>Higher-order function（高阶函数）</code></p><p>高阶函数是指至少支持以下特定之一的函数：</p><ol><li>将一个或多个函数作为参数（即过程参数），</li><li>返回函数作为其结果</li></ol><p>第二点，正是需要的特性。以限流的 interceptor 为例，支持传入自定义的限流器。此时就需要定义一个以限流器为参数的高阶函数，然后返回的函数是框架需要的 Interceptor，并在 Interceptor 函数内使用传入的限流器判断是否需要限流。按照接口限流的 Interceptor 具体实现为：<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> Limiter <span class="hljs-keyword">interface</span> &#123;Limit(key <span class="hljs-type">string</span>) <span class="hljs-type">bool</span>&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">UnaryServerInterceptor</span><span class="hljs-params">(limiter Limiter)</span></span> grpc.UnaryServerInterceptor &#123;<span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context, req <span class="hljs-keyword">interface</span>&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler)</span></span> (<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>) &#123;<span class="hljs-keyword">if</span> limiter.Limit(info.FullMethod) &#123;<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, status.Errorf(codes.ResourceExhausted, <span class="hljs-string">&quot;%s is rejected by grpc_ratelimit middleware, please retry later.&quot;</span>, info.FullMethod)&#125;<span class="hljs-keyword">return</span> handler(ctx, req)&#125;&#125;...</code></pre></p><p>目前传入的参数是固定的，可以这么来实现。更进一步，如果使用比较复杂，除了当前已经确定的参数，可以预期以后会增加更多的参数。也就要求当前设计的接口需要有很好的扩展性。还有办法么？</p><p>答案同样是肯定的。</p><h3 id="Functional-Options"><a href="#Functional-Options" class="headerlink" title="Functional Options"></a>Functional Options</h3><p>没有意外，利用的就是高阶函数的第一点，该编程模式有一个特定的名称：Functional Options。</p><p>首先为传入的参数定义结构体<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> options <span class="hljs-keyword">struct</span> &#123;    byMethod  <span class="hljs-type">bool</span>    byUser    <span class="hljs-type">bool</span>    byClientIP <span class="hljs-type">bool</span>&#125;</code></pre></p><p>其次，再定义一个函数类型：<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> Option <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(*Options)</span></span></code></pre></p><p>再次，定义修改配置的一组函数<br><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ByMethod</span><span class="hljs-params">(m <span class="hljs-type">bool</span>)</span></span> Option &#123;    <span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(o *options)</span></span> &#123;        o.byMethod = m    &#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ByUser</span><span class="hljs-params">(u <span class="hljs-type">bool</span>)</span></span> Option &#123;    <span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(o *options)</span></span> &#123;        o.byUser = u    &#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ByClientIP</span><span class="hljs-params">(c <span class="hljs-type">bool</span>)</span></span> Option &#123;    <span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(o *options)</span></span> &#123;        o.byClientIP = c    &#125;&#125;</code></pre></p><p>最后，修改提供的 Interceptor 为：<br><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">UnaryServerInterceptor</span><span class="hljs-params">(limiter Limiter, opts ...Option)</span></span> grpc.UnaryServerInterceptor &#123;<span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context, req <span class="hljs-keyword">interface</span>&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler)</span></span> (<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>) &#123;        <span class="hljs-keyword">default</span> := options &#123;            byMethod: <span class="hljs-literal">true</span>,            byUser: <span class="hljs-literal">false</span>,            byClientIP: <span class="hljs-literal">false</span>,        &#125;        <span class="hljs-keyword">for</span> _, opt := <span class="hljs-keyword">range</span> opts &#123;            opt(&amp;<span class="hljs-keyword">default</span>)        &#125;        ...<span class="hljs-keyword">return</span> handler(ctx, req)&#125;&#125;</code></pre></p><p>如是，你就拥有了一个具有扩展性、支持自定义参数的 Interceptor。</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>做个总结，谈个观点：</p><ol><li>高阶函数，并不是属于哪一个特定的编程语言。其他语言如C++，同样支持类似的特性。</li><li>作为架构师需要了解实现细节么，答案是需要。否则，在特定环境下，拿什么来支撑设计所谓的扩展性呢。</li></ol><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/07-19-2021/go-higher-order-function.html">https://www.cyningsun.com/07-19-2021/go-higher-order-function.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在请求处理过程中，应用程序会接受和处理请求，然后返回响应结果。在该过程中，还存在一些通用的功能，例如：鉴权、监控、链路追踪。众多 RPC 框架会提供称之为 Middleware 或者 Interceptor 等概念，以可插拔的方式来支持上述谈到的众多功能。以 gRPC 为例</summary>
      
    
    
    
    <category term="Golang" scheme="https://www.cyningsun.com/category/Golang/"/>
    
    
    <category term="Functional programming" scheme="https://www.cyningsun.com/tag/Functional-programming/"/>
    
  </entry>
  
  <entry>
    <title>译｜Eventually Consistent</title>
    <link href="https://www.cyningsun.com/06-26-2021/eventually-consistent-cn.html"/>
    <id>https://www.cyningsun.com/06-26-2021/eventually-consistent-cn.html</id>
    <published>2021-06-25T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.289Z</updated>
    
    <content type="html"><![CDATA[<p>一年前，我写过一致性模型的文章的<a href="http://www.allthingsdistributed.com/2007/12/eventually_consistent.html">第一个版本</a>。因为当时写的很匆忙，而且这个主题非常重要，值得更缜密的对待，所以我并不是很满意。ACM Queue 为将其发布到自己觉得杂志上，所以请我仔细推敲。我得以借此机会改进这篇文章。本文就是最新的版本。</p><h3 id="最终一致性-在全球范围内构建可靠的分布式系统需要在一致性和可用性之间进行权衡。"><a href="#最终一致性-在全球范围内构建可靠的分布式系统需要在一致性和可用性之间进行权衡。" class="headerlink" title="最终一致性 - 在全球范围内构建可靠的分布式系统需要在一致性和可用性之间进行权衡。"></a>最终一致性 - 在全球范围内构建可靠的分布式系统需要在一致性和可用性之间进行权衡。</h3><p>亚马逊云计算的基础是诸如 S3（Simple Storage Service）、SimpleDB、EC2（Elastic Compute Cloud）等基础设施，为构建互联网规模级别计算平台和种类繁多的应用提供了资源。这些基础设施服务的要求非常严格，需要在安全性、可扩展性、可用性、性能和成本效益方面获得高分，与此同时还要持续为全球数以百万计的客户提供服务。</p><p>在这些服务幕后，是全球范围内运行的大规模分布式系统。这种规模带来了额外的挑战。因为当系统处理数以万亿计的请求时，通常情况下发生概率较低的的事件会必然发生，需要在系统设计和架构中预先考虑。鉴于这些系统遍及全球范围，我们通常使用复制技术来保证一致性的性能和高可用性。尽管复制使我们更接近目标，却不能以完全透明的方式实现这些目标。在许多情况下，这些服务的客户将面临服务内部使用复制技术的后果。</p><p>其中一种表现方式是提供的数据一致性的类型，特别是底层分布式系统为数据复制提供最终一致性模型时。在亚马逊设计这些大规模系统时，使用了一套与大规模数据复制相关的指导原则和抽象方法，并专注于高可用性和数据一致性之间的平衡。在本文中，我介绍了一些相关的背景知识，包含了我们交付需要在全球范围内运行的可靠分布式系统的方法。本文的<a href="http://www.allthingsdistributed.com/2007/12/eventually_consistent.html">早期版本</a>于 2007 年 12 月在 All Things Distributed 博客上发表，在读者的帮助下得到了极大的改进。</p><h3 id="历史视角"><a href="#历史视角" class="headerlink" title="历史视角"></a>历史视角</h3><p>在理想世界里，只有一种一致性模型：当更新发生时，所有观察者都能看到那个更新。该模型第一次出现难以实现的情况是在70年代末的数据库系统中。关于该主题最好的“时期作品”是 <a href="http://acmqueue.com/modules.php?name=Content&amp;pa=showpage&amp;pid=233">Bruce Lindsay 等人的</a>”分布式数据库笔记”。 它阐述了数据库复制的基础性原则，并讨论了许多处理实现一致性的技术。其中许多技术都试图实现分发透明性——即对系统用户来说，似乎只有一个系统而不是多个协作系统。在此期间，许多系统采取的做法是倾向于让整个系统失败，而非破坏其透明度。</p><p>在90年代中期，随着大型互联网系统的兴起，这些做法被重新审视。当时的人们开始考虑可用性可能是这些系统最重要的属性的想法，但他们正在为拿什么权衡而苦苦挣扎。加州大学伯克利分校系统教授、当时的 Inktomi 负责人 <a href="http://www.cs.berkeley.edu/~brewer/">Eric Brewer</a> 在 2000 年 PODC（分布式计算原理）会议上的<a href="http://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf">主题演讲</a>中将不同的权衡结合在一起。他提出了 CAP 定理，该定理指出共享数据系统的三个属性——数据一致性、系统可用性和对网络分区的容忍度——在任何给定时间只能实现两个。更正式的认定可以在 <a href="http://portal.acm.org/citation.cfm?doid=564585.564601">Seth Gilbert 和 Nancy Lynch</a> 2002 年的一篇论文中找到。</p><p>一个不容忍网络分区的系统可以实现数据的一致性和可用性，通常通过使用事务协议来实现。要实现这一点，客户端和存储系统必须是同一环境的一部分；在某些情况下，它们作为一个整体失败，因此，客户端无法观察到分区。一个重要的观察结果是，在较大的分布式系统中，网络分区是给定的；因此，一致性和可用性无法同时实现。这意味着对于要删除的内容有两种选择：放宽一致性将允许系统在可分区条件下保持高可用性，而将一致性作为优先级意味着在某些条件下系统将不可用。</p><p>两种选项都要求客户端开发者了解系统提供的内容。如果系统强调一致性，开发者需要处理系统可能不可用的事实，例如：写入。如果因为系统不可用写操作失败，那么开发者不得不处理如何处置要写入的数据。如果系统强调可用性，那么总能接受写操作，但是在某些情况下，读操作不会反映最近完成的写入的结果。然后，开发人员必须决定客户端是否需要始终访问绝对最新的更新。大量的应用程序可以处理稍微陈旧的数据，并且在此模型下可以很好地提供服务。</p><p>原则上，<a href="http://en.wikipedia.org/wiki/ACID">ACID</a> 属性（原子性、一致性、隔离性、持久性）中定义的事务系统的一致性属性是一种不同的一致性保证。在 ACID 中，一致性是指当事务完成时，数据库处于一致状态的保证；例如，当从一个账户向另一个账户转账时，两个账户中持有的总金额不应改变。在基于 ACID 的系统中，这种一致性通常是编写事务的开发人员的责任，但可以由数据库管理完整性约束来辅助。</p><h3 id="一致性-——-客户端和服务器"><a href="#一致性-——-客户端和服务器" class="headerlink" title="一致性 —— 客户端和服务器"></a>一致性 —— 客户端和服务器</h3><p>有两种看待一致性的方法。一种是从开发人员/客户的角度来看：他们如何观察数据更新。第二种方式来自服务器端：更新如何流经系统以及系统可以为更新提供什么保证。</p><h4 id="客户端一致性"><a href="#客户端一致性" class="headerlink" title="客户端一致性"></a>客户端一致性</h4><p>客户端具有以下组件：</p><ul><li><p><strong>一个存储系统。</strong> 目前我们将其视为一个黑匣子，但人们应该假设在它幕后是大规模和高度分布式的，并且构建它是为了保证持久性和可用性。</p></li><li><p><strong>进程A。</strong> 这是一个对存储系统进行写入和读取的进程。</p></li><li><p><strong>进程B和C。</strong> 这两个进程独立于进程A，对存储系统进行读写操作。它们是真正的进程还是同一进程中的线程无关紧要；重要的是它们是独立的，共享信息需要通信。</p></li></ul><p>客户端一致性与观察者（在本例中为进程 A、B 或 C）如何以及何时查看对存储系统中的数据对象所做的更新有关。在以下说明不同类型一致性的示例中，进程 A 对数据对象进行了更新：</p><ul><li><p><strong>强一致性（Strong consistency）。</strong> 更新完成后，任何后续访问（通过 A、B 或 C）都将返回更新后的值。</p></li><li><p><strong>弱一致性（Weak consistency）。</strong> 系统不保证后续访问将返回更新后的值。在返回值之前需要满足许多条件。更新和保证任何观察者总是看到更新值之间的时间段被称为不一致窗口。</p></li><li><p><strong>最终一致性（Eventual consistency）。</strong> 弱一致性的一种特殊形式；存储系统保证如果没有对对象进行新的更新，最终所有访问都将返回最后更新的值。如果没有发生故障，则可以根据通信延迟、系统负载以及复制方案中涉及的副本数量等因素确定不一致窗口的最大大小。最流行的实现最终一致性的系统是 DNS（域名系统）。名称的更新根据配置的模式并结合时间控制的缓存进行分发；最终，所有客户端都会看到更新。</p></li></ul><p>最终一致性模型有许多需要考虑的重要变种：</p><ul><li><p><strong>因果一致性（Causal consistency）。</strong> 如果进程 A 通知进程 B 已更新数据项，则进程 B 的后续访问将返回更新后的值，并且保证写入会取代较早的写入。与进程 A 没有因果关系的进程 C 的访问遵循正常的最终一致性规则。</p></li><li><p><strong>读写一致性（Read-your-writes consistency）。</strong> 这是一种重要的模型，其中进程 A 在更新数据项后，始终访问更新的值并且永远不会看到旧值。这是因果一致性模型的一个特例。</p></li><li><p><strong>会话一致性（Session consistency）.</strong> 这是前一模型的实用版本，其中进程在会话上下文中访问存储系统。只要会话存在，系统就保证读写一致性。如果会话由于某种故障场景而终止，则需要创建新会话，并且保证会话之间不会重叠。</p></li><li><p><strong>单调读一致性（Monotonic read consistency）.</strong> 如果进程看到了对象的特定值，则任何后续访问都将永远不会返回任何先前的值。</p></li><li><p><strong>单调写一致性（Monotonic write consistency）.</strong> 在这种情况下，系统保证通过同一进程串行化写入。不保证这种一致性级别的系统是出了名的难以编程。</p></li></ul><p>上述特性可以组合。例如，可以将单调读与会话一致性相结合。 从实践的角度来看，这两个特性（单调读取和读取你的写入）在最终一致性系统中是最可取的，但并非总是必需的。开发者使用这两个特性可以更加简单的构建应用程序，同时允许存储系统放宽一致性并提供高可用性。</p><p>正如您从这些变种中看到的那样，可能存在多种不同的情况。是否可以处理后果取决于特定的应用程序。</p><p>最终一致性并不是极致分布式系统的某些深奥特性。许多提供主备可靠性的现代 RDBMS（关系数据库管理系统）以同步和异步模式实现复制技术。在同步模式下，副本更新是事务的一部分。在异步模式下，更新延迟到达备份，通常是通过日志传送。在后一种模式下，如果主服务器在日志发送之前发生故障，从提升为主的副本中读取，将出现旧的、不一致的值。同样为了支持更好的可扩展读取性能，RDBMS 已经开始提供从备份读取的能力，这是提供最终一致性保证的经典案例，其中不一致窗口取决于日志传送的周期。</p><h4 id="服务器端一致性"><a href="#服务器端一致性" class="headerlink" title="服务器端一致性"></a>服务器端一致性</h4><p>在服务器端，我们需要更深入地了解更新如何流经系统，以了解是什么使得系统的开发人员可以感受到不同的模式。在开始之前，让我们先建立一些定义：</p><p>N = 存储数据副本的节点数<br>W = 更新完成前需要确认收到更新的副本数<br>R = 通过读取操作访问数据对象时联系的副本数</p><p>如果 W + R &gt; N，那么写集和读集始终存在重叠，可以保证强一致性。在实现同步复制技术的主备 RDBMS 场景中：N=2、W=2、R=1，无论客户端从哪个副本读取，总能得到一致的结果。在启用了从备份读取的异步复制中，N=2、W=1、R=1。这种情况下 R + W = N，无法保证一致性。</p><p>这些基本仲裁协议（quorum protocols）配置存在的问题是，当系统由于故障而无法写入 W 节点时，写入操作必须失败，这标志着系统不可用。当 N = 3 和 W = 3 且只有两个节点可用时，系统不得不使写入失败。</p><p>在高性能和高可用性的分布式存储系统中，副本的数量通常大于 2。仅关注容错的系统通常使用 N = 3（W = 2、R = 2）的配置。需要提供非常高的读取负载服务的系统，通常会复制超出容错所需的数据；N 可以是数十甚至数百节点，R 配置为 1，这样单次读取就能返回结果。关注一致性的系统设置为 W = N 以应对更新，这可能会降低写入成功的概率。对于关注容错但不关注一致性的系统，常见配置是以 W = 1 运行，以获得最小的更新持久性，然后依靠延迟（传播）技术来更新其他副本。</p><p>如何配置 N、W 和 R 取决于具体情况以及需要优化的性能路径。在 R = 1 和 N = W 中，我们针对读取情况进行了优化，在 W = 1 和 R = N 中，我们针对快速写入进行了优化。当然，在后一种情况下，出现故障时无法保证持久性，如果 W &lt; (N + 1) / 2，当写集不重叠时，存在冲突写入的可能性。</p><p>当 W+R &lt;= N 时出现弱/最终一致性，这意味着读写集有可能不会重叠。如果这是一个经过深思熟虑的配置，而不是基于失败案例，那么将 R 设置为 1 以外的任何值几乎没有意义。这发生在两种非常常见的情况下：第一种是前面提到的用于读扩展的大规模复制；第二种是数据访问更复杂的地方。在简单的键值模型中，比较版本以确定写入系统的最新值很容易，但在返回对象集的系统中，确定正确的最新集更困难。在大多数写入集小于副本集的系统中，有一种机制以延迟方式将更新应用于副本集中的其余节点。在所有副本都被更新之前的时间段是前面讨论的不一致窗口。如果 W+R &lt;= N，则系统容易从尚未收到更新的节点读取数据。</p><p>读写一致性、会话一致性和单调一致性能否实现，通常取决于客户端对与执行分布式协议服务器的“粘性”。如果每次都是同一台服务器，那么就比较容易保证读写和单调读写。同一台服务器使得管理负载平衡和容错稍微困难一些，却是一个简单的解决方案。使用具有粘性的会话易于理解，并提供客户可以推理的暴露级别。</p><p>有时客户端实现读写和单调读取。通过在写入时添加版本，客户端会丢弃对上次看到的版本之前版本的读取。</p><p>当系统中的某些节点无法连接到其他节点，但客户端组可以访问这两个节点集合时，就会发生分区。如果您使用经典的多数仲裁方法，则在另一个分区变得不可用时，具有复制集的 W 个节点的分区可以继续进行更新。读取集也是如此。假设这两个集合重叠，根据定义，少数集合将变得不可用。分区不经常发生，但它们确实发生在数据中心之间以及数据中心内部。</p><p>在某些应用程序中，任何分区的不可用都是不可接受的，重要的是可以让访问该分区的客户端继续运行。在这种情况下，双方分配一组新的存储节点来接收数据，并在分区愈合时执行合并操作。例如，在亚马逊内部，购物车使用一种永远写入的系统；在分区的情况下，即使原始购物车位于其他分区上，客户也可以继续将商品放入购物车。一旦分区恢复，购物车应用程序将协助存储系统合并购物车。</p><h3 id="亚马逊-Dynamo"><a href="#亚马逊-Dynamo" class="headerlink" title="亚马逊 Dynamo"></a>亚马逊 Dynamo</h3><p>亚马逊的 <a href="http://www.allthingsdistributed.com/2007/10/amazons_dynamo.html">Dynamo</a> 就是这样一个系统，将所有这些特性都置于应用程序体系结构的显式控制之下。它是一个键值存储系统，跟 AWS（Amazon’s Web Service）一样，在亚马逊电子商务平台的服务内部广泛使用。Dynamo 的设计目标之一是允许应用程序的所有者、创建 Dynamo 存储系统实例者，在一致性、持久性、可用性和性能之间进行权衡，而 Dynamo 存储系统通常跨越多个数据中心。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在大规模可靠的分布式系统中，有两个必须容忍数据不一致的原因：在高并发条件下改善读写性能；以及处理大多数模型会导致部分系统不可用的分区情况，即使节点已启动并正在运行。</p><p>不一致性是否可接受取决于客户端应用程序。在所有情况下，开发人员都需要意识到，一致性保证是由存储系统提供的，在开发应用程序时需要加以考虑。最终一致性模型有许多实际的改进，例如会话一致性和单调读，它们给开发人员提供了更好的工具。很多时候，应用程序能够毫无问题地处理存储系统的最终一致性保证。一个特别流行的例子是一个网站，在这个网站中我们可以有用户感知一致性的概念。在这种情况下，不一致窗口需要小于客户加载下一个页面的预期时间。使得在预期下一次读取之前，将更新传播到整个系统。</p><p>本文的目标是提高对工程系统复杂性的认识，这些系统需要在全球范围内运行，并且需要仔细调优，以确保它们能够提供应用程序所需的持久性、可用性和性能。系统设计者拥有的工具之一就是一致性窗口的长度，在此期间，系统的客户端可能会接触到大规模系统工程的实相。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li>Brewer, E. A. 2000. <a href="http://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf">Towards robust distributed systems (abstract)</a>. In <em>Proceedings of the 19th Annual ACM Symposium on Principles of Distributed Computing</em> (July 16-19, Portland, Oregon): 7</li><li><a href="http://acmqueue.com/modules.php?name=Content&amp;pa=showpage&amp;pid=233">A Conversation with Bruce Lindsay.</a> 2004. ACM Queue 2(8): 22-33.</li><li>DeCandia, G., Hastorun, D., Jampani, M., Kakulapati, G., Lakshman, A., Pilchin, A., Sivasubramanian, S., Vosshall, P., Vogels, W. 2007. <a href="http://www.allthingsdistributed.com/2007/10/amazons_dynamo.html">Dynamo: Amazon’s highly available key-value store</a>. In Proceedings of the 21st ACM <em>Symposium on Operating Systems Principles</em> (Stevenson, Washington, October).</li><li>Gilbert , S., Lynch, N. 2002. <a href="http://portal.acm.org/citation.cfm?doid=564585.564601">Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant Web services</a>. ACM SIGACT News 33(2).</li><li>Lindsay, B. G., Selinger, P. G., et al. 1980. Notes on distributed databases. In <em>Distributed Data Bases, ed. I</em>. W. Draffan and F. Poole, 247-284. Cambridge: Cambridge University Press. Also available as IBM Research Report RJ2517, San Jose, California (July 1979).</li></ol><p>原文链接：<a href="http://www.allthingsdistributed.com/2008/12/eventually_consistent.html">http://www.allthingsdistributed.com/2008/12/eventually_consistent.html</a></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/06-26-2021/eventually-consistent-cn.html">https://www.cyningsun.com/06-26-2021/eventually-consistent-cn.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;一年前，我写过一致性模型的文章的&lt;a href=&quot;http://www.allthingsdistributed.com/2007/12/eventually_consistent.html&quot;&gt;第一个版本&lt;/a&gt;。因为当时写的很匆忙，而且这个主题非常重要，值得更缜密的对待，</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>内存管理 - 物理内存</title>
    <link href="https://www.cyningsun.com/06-15-2021/memory-management-physical-memory.html"/>
    <id>https://www.cyningsun.com/06-15-2021/memory-management-physical-memory.html</id>
    <published>2021-06-14T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.288Z</updated>
    
    <content type="html"><![CDATA[<p>本篇从我自己的角度来写对物理内存管理的理解。由于 Linux 引入了虚拟内存的概念，应用程序对物理内存的访问都是由内核模块来接管的，因此带着以下问题，逐步揭开相关的细节：</p><ol><li>内核是使用什么地址访问物理内存的？</li><li>物理内存为何需要分区？</li><li>伙伴系统和 SLAB 系统 有何区别？</li></ol><h3 id="页框管理"><a href="#页框管理" class="headerlink" title="页框管理"></a>页框管理</h3><p>想要管理内存，首先要知道有哪些内存，并且把内存状态记录下来。物理内存默认以 4k 分割为一个个的单元，每个单元被称为页框（page frame）。内核使用 <code>struct page</code> 数组跟踪内存中每个页框的当前状态。数组的每个元素对应于物理内存中的一个页框，数组定义如下：</p><pre><code class="hljs c"><span class="hljs-comment">// `struct page` 定义在 `linux/mm_types.h`</span><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">page</span> *<span class="hljs-title">mem_map</span>;</span></code></pre><p>例如，mem_map[0] 包含内存中第一个页框的信息</p><blockquote><p>名词说明：</p><ul><li>页框: 存储数据的内存块</li><li>页：存放在页框内的数据块</li></ul></blockquote><p>如此，内核就通过页框数组把所有的内存使用索引了起来，并且知道每个页的情况，例如：是否空闲、拥有者是谁。</p><h3 id="为什么分区？"><a href="#为什么分区？" class="headerlink" title="为什么分区？"></a>为什么分区？</h3><p>然而对于内核来说仅有分页是不够的，内核也没办法 <strong>完全</strong> 直接访问内存，是什么原因呢？</p><p>具体还是要从内存分配过程聊起来。进程申请内存的时候，会调用 malloc() 和 mmap() 等内存分配函数，最终会发起系统调用陷入内核态进行内存分配。但是，内存分配过程分配的只是虚拟地址空间，并没有给虚拟内存分配对应的物理内存。当进程访问没有建立映射关系的虚拟内存时，将触发一个缺页中断。当一个进程发生缺页中断的时候，进程会再次陷入内核态，查找/分配一个页框，建立映射关系（虚拟地址到物理地址）</p><p>可以看到进程在分配内的时候两次进入内核态，然而两次却完全不同。要理解这一点首先要熟悉两个概念 “进程上下文” vs “中断上下文”</p><p>在 Linux 实现中，处理器在执行过程中总是处于以下三种状态：<br>（1）内核态，运行于进程上下文，内核代表进程运行于内核空间。<br>（2）内核态，运行于中断上下文，内核代表硬件运行于内核空间。<br>（3）用户态，运行于用户空间。</p><p><img src="/images/memory-management-physical-memory/contexts.png" alt="contexts.png"></p><p>内核的地址空间不仅仅要支持硬件访问，同时还需要映射到进程的虚拟地址空间，成为进程上下文的一部分。</p><blockquote><p>当然，单独从实现来看，对于（1）、（2）两种情况，内核的上下文如果完完全全从进程上下文独立开也是可行的，甚至更为简单。但是从性能来看，当前的方案才是更优的。详情参考：<a href="https://www.sciencedirect.com/topics/computer-science/kernel-address-space">《User Space on Top of Kernel Space Versus Separated Address Spaces》</a></p></blockquote><h3 id="分区地址映射"><a href="#分区地址映射" class="headerlink" title="分区地址映射"></a>分区地址映射</h3><p>32位系统中，内核模块的地址空间只有1G。但是，内核又要访问所有的 4G 内存。但内核访问物理内存与进程访问虚拟内存不同，虚实映射既消耗空间也消耗性能（详见：<a href="/12-02-2020/memory-management-summary.html#地址映射">地址映射</a>），且在内核场景下，内存移动与内存换出的需求并不高，也没有多进程隔离的需求（详见：<a href="https://www.cyningsun.com/12-02-2020/memory-management-summary.html#%E5%86%85%E5%AD%98%E5%85%B1%E4%BA%AB">内存共享</a>），映射的收益不大。</p><p><img src="/images/memory-management-physical-memory/zones.png" alt="zones.png"></p><p>因此，内核把页框分组，划分为不同的区（ZONE）。内核空间的前 896MB（不仅是内核代码，还有它的数据）被“直接”映射到物理内存。虚拟内核空间的最后 128MB 部分被映射到物理“高内存”（&gt; 896MB）的一些部分。物理内存的直接映射允许物理页面分配器的直接访问获得的页面，而无需任何映射操作。获取物理页的虚拟地址所需的唯一操作是添加固定偏移量。</p><p>通过以上方式，既实现 4G 内存的访问，也保证了内核访问的性能。最终，物理内存的页框就被组织成了以下的形式<br><img src="/images/memory-management-physical-memory/physical-memory.png" alt="physical-memory.png"></p><p>从内核地址空间虚实转换的视角来看，如下：<br><img src="/images/memory-management-physical-memory/kernel-address-space.png" alt="kernel-address-space.png"></p><h3 id="内存分配器"><a href="#内存分配器" class="headerlink" title="内存分配器"></a>内存分配器</h3><p>对于空闲内存的分配管理是交给内存分配器进行的。内核中有两种内存分配器，即伙伴系统分配器 和 SLAB 分配器。前者是页框分配器，后者是对象分配器。</p><p>伙伴系统的引入为内核提供了一种用于分配一组连续的页而建立的一种高效的分配策略。避免因频繁地申请和释放不同大小的连续页框，导致在已分配页框的内存块中分散了许多小块的空闲页框，而其他需要分配连续页框的请求无法得到满足。</p><p>SLAB 工作是针对一些经常分配并释放的对象，如进程描述符等内核中常见的小对象。如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内碎片，而且处理速度也太慢。而 SLAB 分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符)，每当要申请这样一个对象，就从一个 SLAB 列表中分配同样大小的内存，而当要释放时，将其重新保存在该列表中。</p><p>伙伴系统解决了内存外部碎片问题，而 SLAB 解决了内存的内部碎片问题。所谓外部碎片是指由于频繁地申请和释放页框而导致的某些小的连续页框，而内部碎片就是指被分配出去但是不能被利用的内存。</p><p><img src="/images/memory-management-physical-memory/memory-allocator.png" alt="memory-allocator.png"></p><p>两个系统的细节暂时按下，后续详聊。</p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/06-15-2021/memory-management-physical-memory.html">https://www.cyningsun.com/06-15-2021/memory-management-physical-memory.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本篇从我自己的角度来写对物理内存管理的理解。由于 Linux 引入了虚拟内存的概念，应用程序对物理内存的访问都是由内核模块来接管的，因此带着以下问题，逐步揭开相关的细节：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;内核是使用什么地址访问物理内存的？&lt;/li&gt;
&lt;li&gt;物理内存为何需要分区？</summary>
      
    
    
    
    <category term="Linux" scheme="https://www.cyningsun.com/category/Linux/"/>
    
    
    <category term="内存管理" scheme="https://www.cyningsun.com/tag/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 设计与查询规范</title>
    <link href="https://www.cyningsun.com/06-06-2021/mysql-design-guide.html"/>
    <id>https://www.cyningsun.com/06-06-2021/mysql-design-guide.html</id>
    <published>2021-06-05T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.288Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>想象一下自己是一名伐木工人，手里有林场里最好的斧子，因此你是工作效率最高的。突然有一天场里来了个推销的，他把一种新的砍树工具——链锯——给夸到了天上去。你也买了一把，不过你不懂得怎么用。你估摸着按照自己原来擅长的砍树方法，把链锯大力地挥向树干……</p><p>MySQL 这个工具也是一样，设计规范就是的一个很好的工具说明。即统一了命名风格，又可以让新人快速上手。</p><p>本文的主要内容可以在网上找到类似的版本，但是在一些细节点又略微不同。基于多年 MySQL 使用经验，基于应用与 MySQL 的通盘考虑（视 MySQL 为低配版本的：Bigtable + KV），才有了这些细节上的调整。</p><h3 id="命名"><a href="#命名" class="headerlink" title="命名"></a>命名</h3><p>避免使用 MySQL 关键词 作为 db / table / field / index 名称</p><ul><li>DB<ul><li>使用项目名作为前缀，“_db” 作为后缀；分库添加后缀8位宽度的数字，数字从0开始</li><li>风格：由下划线分割的小写英文字母组成</li><li>DB 名称总长度小于 42 个字符</li></ul></li><li>Table<ul><li>“_db” 作为后缀；分表添加后缀8位宽度的数字，数字从0开始</li><li>风格：由下划线分割的小写英文字母组成</li><li>表名称总长度小于 48 个字符</li></ul></li><li>Field<ul><li>主键统一定义为：<code>id</code> BIGINT UNSIGNED NOT NULL</li><li>指向其他表主键的字段以 “_id” 后缀结尾</li><li>风格：由下划线分割的小写英文字母组成</li></ul></li><li>Index<ul><li>使用 “idx_” 作为前缀；索引字段名字、顺序组合为名称</li><li>风格：由下划线分割的小写英文字母组成</li></ul></li><li>Comment<ul><li>纯英文单词注释所有字段</li></ul></li></ul><h3 id="DB"><a href="#DB" class="headerlink" title="DB"></a>DB</h3><ul><li>使用 Innodb 存储引擎<blockquote><p>Innodb 支持事务，支持行级锁，更好的恢复性，高并发下性能更好</p></blockquote></li><li>使用 utf8mb4_unicode_ci 编码<blockquote><p>兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效</p></blockquote></li></ul><h3 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h3><ul><li><p>使用 utf8mb4_unicode_ci 编码</p></li><li><p>每张表必须显式定义主键</p><blockquote><ol><li>数据的存储顺序和主键的顺序是相同的</li><li>不要使用更新频繁的列作为主键，不要使用 UUID、MD5、HASH、字符串等无法保证数据的顺序增长的字段作为主键</li></ol></blockquote></li><li><p>尽量控制单表数据量的大小，建议控制在 1000万 以内</p><blockquote><ol><li>该量级数据量查询性能较好</li><li>可以用历史数据归档，分库分表等手段来控制单表数据量</li></ol></blockquote></li><li><p>宽表尽量拆分为索引表和内容表以提高查询性能</p><blockquote><ol><li>MySQL 限制每个表最多存储 4096 列，并且每一行数据的大小不能超过 65535 字节 减少磁盘 IO，保证热数据的内存缓存命中率</li><li>表越宽，装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的 IO，更有效的利用缓存，避免读入无用的冷数据</li></ol></blockquote></li><li><p>谨慎使用 JOIN</p><blockquote><ol><li>应用层缓存效率更高，可以在多种查询场景复用缓存</li><li>在应用层做关联，可以更容易对数据库进行拆分，更容易做到高性能和可扩展</li><li>查询效率提升。使用 ID 查询，可以让 MySQL 按照主键索引顺序查询，相比关联要更稳定高效</li></ol></blockquote></li><li><p>谨慎使用 MySQL 分区表</p><blockquote><p>分区表在物理上表现为多个文件，在逻辑上表现为一个表 谨慎选择分区键，跨分区查询效率可能更低 建议采用物理分表的方式管理大数据</p></blockquote></li><li><p>不要使用外键</p><blockquote><ol><li>MySQL 外键实现比较简单粗糙，性能不好</li><li>MySQL 作为后端存储，不在 MySQL 上放置任何计算逻辑</li><li>如果依赖于在 MySQL 服务器上运行的计算逻辑，进行数据库/表分片将非常困难</li></ol></blockquote></li></ul><h3 id="Field"><a href="#Field" class="headerlink" title="Field"></a>Field</h3><ul><li>优先选择符合存储需要的最小的数据类型<blockquote><p>列的字段越大，索引时所需要的空间越大，磁盘单页存储的索引节点数越少，遍历时 IO 次数就越多， 索引性能也就越差</p><p>方法：<br>1）将字符串转换成数字类型存储，如：将IP地址转换成整形数据（inet_aton / inet_ntoa）<br>2）对于非负型的数据（如自增ID、整型IP）来说，要优先使用无符号整型来存储</p></blockquote></li><li>存储相同数据的列名和列类型必须一致<blockquote><p>如果查询时关联列类型不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低</p></blockquote></li><li><p>尽可能把所有列定义为 NOT NULL</p><blockquote><ul><li>NULL 占用额外的空间来保存</li><li>NULL 需要特殊处理，可能会导致应用程序异常</li><li>NULL MySQL 索引统计和值比较更复杂</li></ul></blockquote></li><li><p>避免使用 ENUM 类型</p><blockquote><ul><li>修改 ENUM 值需要使用 ALTER 语句</li><li>ENUM 类型的 ORDER BY 操作效率低，需要额外操作</li><li>禁止使用数值作为 ENUM 的枚举值</li></ul></blockquote></li><li><p>禁止在数据库中存储长文本、图片，文件等大数据</p><blockquote><p>MySQL 内存临时表不支持 TEXT、BLOB 大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行</p><p>而且对于这种数据，MySQL 还是要进行二次查询，会使 SQL 性能变得很差，但是不是说一定不能使用这样的数据类型</p></blockquote></li><li><p>禁止建立预留字段</p><blockquote><ul><li>预留字段的命名很难做到见名识义</li><li>预留字段无法确认存储的数据类型，所以无法选择合适的类型</li><li>对预留字段类型的修改，会对表进行锁定</li></ul></blockquote></li></ul><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ul><li>限制每张表上的索引数量，建议单张表索引不超过5个<blockquote><p>MySQL 优化器优化查询时，会根据统计信息，对候选索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能</p></blockquote></li></ul><h3 id="Stored-Programs"><a href="#Stored-Programs" class="headerlink" title="Stored Programs"></a>Stored Programs</h3><ul><li>禁止使用 mysql 视图，存储过程，触发器，自定义函数</li></ul><h3 id="Queries"><a href="#Queries" class="headerlink" title="Queries"></a>Queries</h3><ul><li>禁止直连生产环境，手工删除和修改生产数据</li><li>禁止使用 SELECT * 必须使用 SELECT &lt;字段列表&gt; 查询<blockquote><p>可减少表结构变更对应用程序的影响</p></blockquote></li><li>禁止使用不含字段列表的INSERT语句<blockquote><p>正确：INSERT INTO tbl(c1,c2,c3) VALUES (a,b,c);<br>错误：INSERT INTO VALUES (a,b,c);</p></blockquote></li><li>WHERE从句中禁止对列进行函数转换和计算<blockquote><p>对列进行函数转换或计算时会导致无法使用索引。</p><p>正确：WHERE create_time &gt;= 20190101 AND create_time &lt; 20190102<br>错误：WHERE DATE(create_time)=20190101</p></blockquote></li><li>不会有重复值时使用 UNION ALL 而不是 UNION<blockquote><p>UNION 将结果集的所有数据放到临时表后再去重<br>UNION ALL 不会再对结果集进行去重</p></blockquote></li></ul><p>参考链接：<br><a href="https://www.cnblogs.com/huchong/p/10219318.html">https://www.cnblogs.com/huchong/p/10219318.html</a></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/06-06-2021/mysql-design-guide.html">https://www.cyningsun.com/06-06-2021/mysql-design-guide.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;想象一下自己是一名伐木工人，手里有林场里最好的斧子，因此你是工作效率最高的。突然有一天场里来了个推销的，他把一种新的砍树工具——链锯——给夸</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.cyningsun.com/category/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="Guide" scheme="https://www.cyningsun.com/tag/Guide/"/>
    
  </entry>
  
  <entry>
    <title>译｜High-Performance Server Architecture</title>
    <link href="https://www.cyningsun.com/06-02-2021/high-performance-server-architecture-cn.html"/>
    <id>https://www.cyningsun.com/06-02-2021/high-performance-server-architecture-cn.html</id>
    <published>2021-06-01T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.288Z</updated>
    
    <content type="html"><![CDATA[<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>本文的目的是分享我多年来关于如何开发某种应用程序的一些想法，对于这种应用程序，术语“服务”只是一个无力的近似称呼。更准确地说，将写的与一大类程序有关，这些程序每秒处理大量离散的消息或请求。网络服务通常最适合此定义，但从某种意义上讲，实际上并非所有的程序都是服务。但是，由于“高性能请求处理程序”是很糟糕的标题，为简单起见，倒不如叫“服务”万事大吉。</p><p>尽管单个程序中多任务处理现在很普遍，但我不会写此类“轻度并行”应用程序。您用来阅读本文的浏览器可能会并行执行某些操作，但是如此低的并行度真的不会带来多少有趣的挑战。当请求处理的基础结构本身是整体性能的瓶颈时，就会出现有趣的挑战，因此改进基础结构实际上会提高性能。对于运行在具有千兆位内存的千兆赫处理器上的浏览器，通过 DSL 线路同时进行六路下载，基础结构成为瓶颈并不常见。此文关注的重点不是用吸管抿水的应用程序，而是从消防水管喝水的应用程序。在硬件功能的边缘，如何做才是真正重要的。</p><p>有些人不可避免地会对我的一些意见和建议持怀疑态度，或者认为他们有更好的方法。挺好，我不是想成为上帝的代言人；我发现这些方法对我来说很有用，不仅是它们对性能的影响，而且它们对以后调试或扩展代码的难度也有影响。效果因人而异。如果还有其他方法对您更好，那太好了，但是请注意，我在这里建议的几乎所有方法都曾作为其他方法的替代品而存在，而我曾经尝试过，只是其结果让人厌恶或恐惧。你最喜欢的想法可能会在其中某个故事中占据显著位置，如果让我现在就讲述出来，无辜的读者可能会无聊至死。您不想伤害他们，对吗？</p><p>本文的其余部分将围绕我称之为“性能糟糕的四骑士”展开：</p><blockquote><p>译者注：天启四骑士，战争、瘟疫、饥荒和死亡。</p></blockquote><ol><li>数据拷贝</li><li>上下文切换</li><li>内存分配</li><li>锁竞争</li></ol><p>最后还将有一个总括的章节，但这些是最大的性能杀手。如果您能够处理大多数请求而无需数据拷贝，无需上下文切换，无需经过内存分配器并且无需竞争锁，那么即使有一些次要问题，您也会拥有一个性能良好的服务。</p><h3 id="数据拷贝"><a href="#数据拷贝" class="headerlink" title="数据拷贝"></a>数据拷贝</h3><p>这可能是一个很短的章节，原因很简单：大多数人已经吸取了这个教训。人人都知道数据拷贝不好。很明显，对吧？实际上，显而易见可能是您在计算机职业生涯的很早就知道，仅仅是因为有人在几十年前就开始使用这个词了。我知道我的情况就是如此，但我离题了。如今，每门学校课程和每个非正式的指南都涵盖了它。甚至营销人员也发现“零拷贝”是一个很好的热门词汇。</p><p>尽管事后看来副本很糟糕，但似乎仍然有些让人错过的细微差别。其中最重要的是，数据拷贝经常是隐藏和伪装起来的。您真的知道您调用的驱动程序或库中的代码是否会进行数据拷贝吗？可能超出您的想象。猜猜PC上的“编程 I/O”是指什么。哈希函数是伪装、非隐藏副本的一个示例，该函数具有副本的所有内存访问开销，并且还涉及更多的计算。一旦指出散列实际上是“拷贝升级版”，显然应该避免使用散列，但我知道至少有一群才华横溢的人，他们必须用艰难的方式来解决这个问题。如果您真的想摆脱数据拷贝，不管是因为它真的会影响性能，还是因为你想把“零拷贝操作”写入黑客会议幻灯片里，您将需要跟踪许多真正属于数据拷贝但并未广而告之的内容。</p><p>避免数据拷贝行之有效的方法是使用间接寻址，并传递缓冲区描述符（或缓冲区描述符链），而不是仅仅使用缓冲区指针。每个描述符通常由以下内容组成：</p><ul><li>整个缓冲区的指针和长度。</li><li>缓冲区的实际填充部分的指针和长度，或偏移量和长度。</li><li>指向列表中其他缓冲区描述符的前后指针。</li><li>引用计数。</li></ul><p>现在，代码只需将适当的缓冲区描述符的引用计数加一，而不用拷贝一段数据以确保它留在内存中。在某些情况下，这种做法可以非常好地工作，包括典型的网络协议栈的运行方式，但也可能成为一个真正令人头痛的问题。一般来说，很容易在链的开始或结尾添加缓冲区，添加对整个缓冲区的引用以及释放整个链。在中间添加，逐块释放或引用部分缓冲区愈加困难。尝试拆分或合并缓冲区简直让人发疯。</p><p>不过，我实际上并不建议所有情况都使用这种方法。为什么不？因为每次要查看头字段时都必须遍历描述符链，这将成为极大的痛苦。确实有比数据拷贝更糟糕的事情。我发现最好的方法是识别程序中的大对象，例如数据块，确保这些大对象按上述方法单独进行分配，这样就不必拷贝它们，也不必过多地操心其他事情。</p><p>这就引出了我关于数据拷贝的最后一点：不要过分规避。我已经看到太多的代码通过做更糟糕的事情来避免数据拷贝，例如强制执行上下文切换或中断大型 I/O 请求。数据拷贝代价很高，当您寻找避免冗余操作的地方时，它是您应首先考虑的问题之一，但是收益递减。对代码进行梳理，然后将其复杂度提高一倍，仅仅是为了去掉最后几份数据副本，通常是在浪费本可以更好利用在其他地方的时间。</p><h3 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h3><p>尽管每个人都认为数据拷贝很糟糕，但我却常常为这么多人完全忽略上下文切换对性能的影响而感到惊讶。根据我的经验，在高负载下，上下文切换实际上比数据副本要落后更多的“崩溃”。系统从一个线程到另一个线程所花费的时间，开始多于它在线程内实际执行有用工作所花费的时间。令人惊奇的是，在某种程度上，导致过度上下文切换的原因是显而易见的。上下文切换的第一大原因是活跃线程数多于处理器数。随着活跃线程与处理器的比率增加，上下文切换的数量也会增加——运气好的话会呈线性关系，但通常呈指数关系。这个非常简单的事实解释了为什么每个连接一个线程的多线程设计的伸缩性非常差。对于可伸缩系统来说，唯一可行的选择是限制活动线程的数量，使其（通常）小于或等于处理器的数量。这种方法的一种流行变体是永远只使用一个线程。尽管这种方法确实避免了上下文抖动，也避免了加锁，它也无法实现超过一个处理器的总吞吐量。因此，除非该程序无论如何都是非 CPU 密集型的（通常是网络I/O密集型的），否则它仍然不受重视。</p><p>“线程有度”的程序要做的第一件事就是弄清楚如何让一个线程同时处理多个连接。这通常意味着前端使用 select/poll、asynchronous I/O、信号或完成端口，后端是事件驱动的结构。哪种前端 API 最好，许多“宗教战争”已经打过，而且还在继续。Dan Kegel 的 <a href="http://www.kegel.com/c10k.html">C10K论文</a><br>是该领域很好的资料。就个人而言，我认为所有 select/poll 和 signal 形式都是丑陋的，因此偏爱 AIO 或完成端口，但实际上并不重要。除了 select()，其他都可以很好地工作，处理程序前端最外层不需要做太多的工作。</p><p>多线程事件驱动服务最简单概念模型是在其中心处有一个队列。一个或多个 “listener” 线程读取请求并将其放入队列，一个或多个 “worker” 线程将其从中移除并处理。从概念上讲，这是一个很好的模型，但是人们通常经常以这种方式实现他们的代码。为什么这样做是错的呢？因为上下文切换的第二大原因是将工作从一个线程转移到另一个线程。有些人甚至要求由原始（译者注：listener）线程发送请求的响应，使错误更严重 —— 导致每个请求需要两次上下文切换而非一次。使用“对称的”方法非常重要，在这种方法中，给定线程可以在不更改上下文的情况下，从 “listener” 成为 “worker”，再成为 “listener”。</p><p>通常，即使将来的一瞬间，也不可能知道有多少个线程处于活跃状态。毕竟，请求可能随时出现在任何连接上，也可能专用于各种维护任务的“后台”线程在那一刻唤醒。如果您不知道有多少线程处于活跃状态，该如何限制有多少活跃线程？以我的经验，最有效也是最简单的方法之一：使用老式的计数信号量，每个线程在执行“实际工作”时都必须持有该信号量。如果已经达到线程限制，则每个 listen 模式线程可能会在唤醒时可能会产生一个额外的上下文切换，然后阻塞在信号量上，但是一旦所有 listen 模式线程都以这种方式阻塞，它们就不会继续争用资源，直到一个现有线程“退出”，因此系统影响可以忽略不计。更重要的是，这种方法处理维护线程比大多数替代方法更优雅（大部分时间处于睡眠状态，因此不计入活跃线程数）。</p><p>一旦将请求处理分为两个阶段（listener 和 worker），并使用多个线程为这些阶段提供服务，就很自然地将处理进一步分为两个以上的阶段。在最简单的形式下，处理一个请求就变成了在一个方向上依次调用各个阶段，然后又在另一个方向上进行调用（对于应答）的问题。但是，事情会变得更加复杂。一个阶段可能代表 “fork”出来两条处理路径的两个互不相同的阶段，或者本身可能会在不调用其他阶段的情况下生成应答（例如，缓存的值）。因此，每个阶段都必须能够指定请求“下一步应该做什么”。由阶段的派发函数的返回值表示，有三种可能：</p><ul><li>该请求需要传递到另一个阶段（返回值中包含指示阶段的ID或指针）。</li><li>请求已完成（特殊的“请求处理完毕”返回值）</li><li>请求被阻塞（特殊的“请求阻塞”返回值）。与前面的情况相同，只是请求没有被释放，稍后将由另一个线程继续执行。</li></ul><p>请注意，在本模型中，请求的排队是在阶段内，而非阶段之间。避免了将请求不断放在后继阶段的队列中，然后立即调用该后继阶段，再次使请求出队的常见愚蠢做法。我称之为没事找事的队列、锁定活动。</p><p>将一个复杂的任务分成多个较小的通信部分的想法似乎很熟悉，那是因为它实际上已经很久远了。我的方法源于 1978 年 C.A.R. Hoare 提出的“<a href="http://www.afm.sbu.ac.uk/csp/">Communicating Sequential Processes</a>”概念，该概念又基于 Per Brinch Hansen 和 Matthew Conway 的思想，这些思想可以追溯到 1963 年 —— 我出生之前！但是，当 Hoare 创造术语 CSP 时，他的意思是抽象数学意义上的“进程”，并且 CSP 进程不必与同名的操作系统实体相关。在我看来，通过单 OS 线程内部类线程的协程以实现 CSP 的常见方法给用户带来了并发的所有麻烦，却又没有任何可伸缩性。</p><p>同一时期，Matt Welsh 的 <a href="http://www.cs.berkeley.edu/~mdw/proj/seda/">SEDA</a> 是一个朝着更明智的方向发展的阶段执行理念的例子。实际上，SEDA 是“正确完成服务架构”的一个很好的例子，它的一些特定的特征值得评论（尤其是那些与我上面概述的特征不同的地方）。</p><ol><li>SEDA 的“批处理”倾向于强调一次处理多个请求，而我的方法倾向于强调一次处理单个请求的多个阶段。</li><li>在我看来，SEDA 的一个显著缺陷是，它为每个阶段分配了一个单独的线程池，只在后台重新分配各个阶段的线程以响应负载。因此，上面提到的引起上下文切换的“1”和“2”原因仍然存在。</li><li>在学术研究项目的背景下，用 Java 实现 SEDA 可能说得通。但是，在现实世界中，这种选择可谓不恰当的。</li></ol><h3 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h3><p>分配和释放内存是许多应用程序中最常见的操作之一。因此，人们已经开发出许多巧妙的技巧来使通用存储器分配器更有效。然而，再聪明也弥补不了这样一个事实：在许多情况下，这种分配器的通用性不可避免地使它们的效率远远低于其他分配器。因此，关于如何完全避免使用系统内存分配器，我有三点建议。</p><p>建议一：简单的预分配。我们都知道，静态分配器如果导致程序功能受限，是非常不好的，但是还有许多其他形式的预分配可能会非常有益。通常，原因归结为这样一个事实：即使在此过程中“浪费”了一些内存，通过系统内存分配器的一次访问也要好于几次。因此，如果可以断言同时使用不超过N项，则在程序启动时进行预分配可能是一个有效的选择。即使不是这种情况，也可以在一开始就预先分配请求处理程序可能需要的所有内容，而不是根据需要分配每个内容。除了通过系统分配器在一次行程中连续分配多项的可能性之外，也通常大大简化了错误恢复代码。如果内存非常紧张，那么预分配可能不是一种选择，但在除最极端的情况外的所有情况下，结果通常都是净收益。</p><p>建议二：对经常分配和释放的对象使用 lookaside 列表。基本思想是将最近释放的对象放到列表中，而不是真正释放，希望如果很快再次使用，则只需将其从列表中移除，而不用从系统内存中分配。另一个好处是， lookaside 列表的存取转换的实现通常可以跳过复杂的对象初始化/终结。</p><p>通常不希望 lookaside 列表无限制地增长，即使程序处于空闲状态也从不释放任何内容。因此，通常有必要执行某种定期的 “sweeper” 任务以释放不活跃的对象，但是如果清理程序引入了不适当的加锁复杂性或竞争，则也不可取。因此，一个好的折衷方案是，lookaside 列表实际上由单独加锁的 “old” 列表和 “new” 列表组成的系统。优先从新列表开始分配，然后从旧列表开始分配，并且仅在万不得已的情况下才从系统中分配；对象总是被释放到新列表中。清理线程的操作如下：</p><ol><li>锁定两个列表。</li><li>保存旧列表的表头。</li><li>通过表头赋值，将（以前）新列表变为旧列表。</li><li>解锁。</li><li>在空闲时将保存的旧列表中的所有对象都释放掉。</li></ol><p>此类系统中的对象只有在至少一个但不超过两个完整的清除程序间隔不需要时才真正释放。最重要的是，清除程序在执行大部分工作时没有持有任何与常规线程竞争的锁。理论上，相同的方法可以推广到两级以上，但我还没有发现如此做有用。</p><p>使用 lookaside 列表的一个担心是列表指针可能会增加对象的大小。根据我的经验，使用 lookaside 列表的大多数对象都已经包含了列表指针，所以考虑此点没有实际意义。但是，即使指针只用于 lookaside 列表，但避免使用系统内存分配器（和对象初始化）方面所节省的开销，将远远弥补额外增加的内存。</p><p>建议三：实际上与尚未讨论到的加锁有关，但我仍然要加进来。即使使用 lookaside 列表，锁竞争通常也是分配内存的最大成本。一种解决方案是维护多个私有的 lookaside 列表，这样就绝对不可能争用任何一个列表。例如，每个线程可以有一个单独的 lookaside 列表。出于高速缓存 cache-warmth 的考虑，每个处理器一个列表更好，但是仅在线程无法被抢占的情况下才有效。如有必要，私有 lookaside 列表甚至可以与共享列表相结合，以创建具有极低分配开销的系统。</p><h3 id="锁竞争"><a href="#锁竞争" class="headerlink" title="锁竞争"></a>锁竞争</h3><p>众所周知，高效的加锁方案很难设计，因此我称之为 “Scylla” 和 “Charybdis”，取自《奥德赛》中的怪物。Scylla 是过于简单和/或粗粒度的锁，是可以或应该并行的串行化的活动，这些活动可以或应该并行进行，从而牺牲了性能和可伸缩性。Charybdis 是过于复杂或细粒度的锁，加锁的空间和加锁的操作时间会再次降低性能。靠近 Scylla 的陷阱是代表死锁和活锁的状态。靠近 Charybdis 的陷阱是代表竞态条件。两者之间，有一个狭窄的渠道代表既高效又正确的加锁……或者在哪？由于锁定往往与程序逻辑紧密相关，因此，如果不从根本上改变程序的工作方式，通常就不可能设计出良好的锁定方案。这就是为什么人们讨厌锁，并试图将不可伸缩的单线程实现合理化的原因。</p><p>几乎每个加锁方案都是从“围绕所有事物的一个大锁”开始，并且茫然地希望性能不会太糟。当希望破灭时（几乎总是这样），大锁被分解成小锁，然后继续祈祷，然后重复整个过程，大概直到性能足够为止。但是，通常每次迭代都会增加 20-50％ 的复杂性和锁开销，以减少 5-10％ 的锁竞争。幸运的是，最终结果性能仍然会有些许提高，但实际下降的情况也并不少见。设计师只能挠头了，“我把锁粒度做得更细，就像教科书上说的那样”，他想，“那为什么性能会变得更差呢？”</p><p>我认为情况变得更糟，因为上述方法从根本上讲是错误的。把“解决方案空间”想象成一座山脉，高点代表好的解决方案，低点代表差的解决方案。问题是，“大锁”的起点几乎总是被各种山谷，马鞍山，小山峰、死胡同与高峰隔开。这是一个经典的爬山问题。想从一个起点爬到更高的山峰，只迈出一小步，从不走下坡路，几乎是行不通的。我们需要的是一种完全不同的接近顶峰的方式。</p><p>您要做的第一件事是形成程序加锁的脑中地图。该地图有两个轴：</p><ul><li>纵轴表示代码。如果您使用的是非分支阶段的阶段体系结构，则可能已经有了一个显示划分的图表，就像每个人都在使用的 OSI 模型网络协议栈那样。</li><li>横轴表示数据。在每个阶段中，应将每个请求分配给一个数据集，该数据集使用的资源应该独立于其他任何资源。</li></ul><p>现在有了一个网格，其中每个单元格表示特定处理阶段中的特定数据集。最重要的是以下规则：两个请求不应处于争用状态，除非它们位于相同的数据集和相同的处理阶段。如果你能做到这一点，你已经成功了一半。</p><p>一旦定义了网格，就可以绘制程序的每种加锁类型，下一个目标是确保所得的点尽可能沿两个轴均匀分布。不幸的是，这部分是非常特定于应用的。你必须像钻石切割师一样思考，利用你对程序执行的知识来寻找阶段和数据集之间的自然“解理纹”。它们有时从一开始就很明显，有时很难找到，但回想起来似乎更明显。将代码分为多个阶段是一个复杂的程序设计问题，因此我能提供的内容不多，但以下是一些关于如何定义数据集的建议：</p><ul><li>如果有某种与请求相关联的块号或哈希或事务ID，那么最好将该值除以数据集的数量。</li><li>有时，最好动态地将请求分配给数据集，根据哪个数据集拥有最多的可用资源，而不是请求的某些内在属性。把它想象成现代CPU中的多个整数单元；它们对离散请求流经系统略知一二。</li><li>确保每个阶段的数据集分配不同通常是有用的，这样可以保证在一个阶段竞争的请求在另一阶段不会再次竞争。</li></ul><p>如果您已经将“加锁域”进行了垂直和水平划分，并确保加锁活动均匀地分布在生成的单元格中，则可以确定加锁状态良好。不过，还有一步。您还记得我几段内容之前嘲笑的“小步走”方法吗？它仍然有它的作用，因为现在你处于一个好的起点而不是一个糟糕的起点。用比喻的话来说，你可能已经爬上了这座山脉最高峰之一的斜坡，但你可能还没有到达山顶。现在是时候收集竞争的统计信息了，看看您需要做些什么来改进，以不同的方式拆分阶段和数据集，然后收集更多的统计信息，直到满意为止。如果你做了这些，你一定能从山顶看到美丽的景色。</p><h3 id="其他内容"><a href="#其他内容" class="headerlink" title="其他内容"></a>其他内容</h3><p>正如我所承诺的，我已经讨论了服务设计中四个最大的性能问题。不过，特定的服务仍然有其他重要的问题需要解决。主要是要了解平台/环境：</p><ul><li>存储子系统如何处理较大和较小的请求？顺序还是随机？read-ahead 和 write-behind 的能力如何？</li><li>使用的网络协议的效率如何？是否可以设置参数或标志以获得更好的性能？是否有诸如TCP_CORK，MSG_PUSH 或 Nagle-toggling 技巧之类的工具可用于避免发送微小消息？</li><li>系统是否支持分散/集中 I/O（例如readv / writev）？使用这些可以提高性能，也可以减轻使用缓冲链的痛苦。</li><li>页大小是多少？缓存行大小是多少？在边界上内容对齐是否值得？相对于其他操作，系统调用或上下文切换的成本多高？</li><li>reader/writer 加锁原语是否处于饥饿？因何饥饿？事件有“惊群效应”的问题吗？睡眠/唤醒是否有一种恶劣的（但非常常见的）行为，即当 X 唤醒 Y 时，即使 X 还有事情要做，上下文也会立即切换到 Y？</li></ul><p>我相信我能想出更多这样的问题。相信你也可以。在任何特定情况下，针对任何一个问题做点什么都不值得，但通常至少值得考虑一下。如果您不知道答案 — 其中许多答案在系统文档中找不到 — 请找出答案。编写一个测试程序或微观基准，从经验上寻找答案；无论如何，编写这样的代码本身就是一种有用的技能。如果您要编写在多个平台上运行的代码，那么其中许多问题都与您应该将功能抽象到每个平台库中的点相关，这样您就可以在支持特定功能的平台上实现性能提升。</p><p>“知道答案”理论也适用于你自己的代码。找出代码中重要的高级操作是什么，并在不同的条件下对它们进行计时。这与传统的概要性能剖析不太一样；这是衡量 <em>设计</em> 元素，而不是实际的实现。低级优化通常是搞砸设计的人最后的选择。</p><p><em>原文：</em> <a href="https://pl.atyp.us/content/tech/servers.html">High-Performance Server Architecture</a></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/06-02-2021/high-performance-server-architecture-cn.html">https://www.cyningsun.com/06-02-2021/high-performance-server-architecture-cn.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h3&gt;&lt;p&gt;本文的目的是分享我多年来关于如何开发某种应用程序的一些想法，对于这种应用程序，术语“服务”只是一个无力的近似称呼。更准确地说，将写的与一大类</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Golang channel 的本质</title>
    <link href="https://www.cyningsun.com/05-15-2021/channels-orchestrate-mutexes-serialize.html"/>
    <id>https://www.cyningsun.com/05-15-2021/channels-orchestrate-mutexes-serialize.html</id>
    <published>2021-05-14T16:00:00.000Z</published>
    <updated>2022-05-09T11:08:55.288Z</updated>
    
    <content type="html"><![CDATA[<p>channel 是 Go 语言独有的一个特性，相比 goroutine 更加抽象，也更加难以理解。毕竟后者可以类比线程、进程。<a href="https://www.jtolio.com/2016/03/go-channels-are-bad-and-you-should-feel-bad/">《Go channels are bad and you should feel bad》</a> 提及在使用 channel 和 mutex 时的困惑。其中提到过一个简单的程序，可以保存一场游戏的各个选手中的最高分。作者分别使用 <code>channel</code> 和 <code>mutex</code> 来实现该功能。</p><h3 id="channel-版"><a href="#channel-版" class="headerlink" title="channel 版"></a>channel 版</h3><p>首先定义 <code>Game</code> 结构体：<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> Game <span class="hljs-keyword">struct</span> &#123;  bestScore <span class="hljs-type">int</span>  scores    <span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>&#125;</code></pre></p><p>bestScore 不会使用 mutex 保护，而是使用一个独立的 goroutine 从 channel 接收数据，然后更新其状态。<br><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(g *Game)</span></span> run() &#123;  <span class="hljs-keyword">for</span> score := <span class="hljs-keyword">range</span> g.scores &#123;    <span class="hljs-keyword">if</span> g.bestScore &lt; score &#123;      g.bestScore = score    &#125;  &#125;&#125;</code></pre></p><p>然后定义构造函数来开始一场游戏<br><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewGame</span><span class="hljs-params">()</span></span> (g *Game) &#123;  g = &amp;Game&#123;    bestScore: <span class="hljs-number">0</span>,    scores:    <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>),  &#125;  <span class="hljs-keyword">go</span> g.run()  <span class="hljs-keyword">return</span> g&#125;</code></pre></p><p>紧接着，定义 <code>Player</code> 接口返回该选手的分数，同时返回 error 用以表示 选手放弃比赛等异常情况。<br><pre><code class="hljs go"><span class="hljs-keyword">type</span> Player <span class="hljs-keyword">interface</span> &#123;  NextScore() (score <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>)&#125;</code></pre></p><p>游戏通过 channel 接收所有选手的分数<br><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(g *Game)</span></span> HandlePlayer(p Player) <span class="hljs-type">error</span> &#123;  <span class="hljs-keyword">for</span> &#123;    score, err := p.NextScore()    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;      <span class="hljs-keyword">return</span> err    &#125;    g.scores &lt;- score  &#125;&#125;</code></pre></p><p>最终，<code>Game</code> 得以实现线程安全的记录选手的最高分，一切都很完美。</p><p>该实现大为成功，游戏服务同时创建了很多的游戏。不久，你发现有选手偶尔会停止游戏，很多游戏也不再有选手玩了，但是却没有什么机制停止游戏循环。你正被废弃的  <code>(*Game).run</code> goroutine 压垮。</p><h3 id="mutex-版"><a href="#mutex-版" class="headerlink" title="mutex 版"></a>mutex 版</h3><p>然而，请注意使用 mutex 的解决方案的简单性，它甚至不存在以上问题：</p><pre><code class="hljs go"><span class="hljs-keyword">type</span> Game <span class="hljs-keyword">struct</span> &#123;  mtx sync.Mutex  bestScore <span class="hljs-type">int</span>&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewGame</span><span class="hljs-params">()</span></span> *Game &#123;  <span class="hljs-keyword">return</span> &amp;Game&#123;&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(g *Game)</span></span> HandlePlayer(p Player) <span class="hljs-type">error</span> &#123;  <span class="hljs-keyword">for</span> &#123;    score, err := p.NextScore()    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;      <span class="hljs-keyword">return</span> err    &#125;    g.mtx.Lock()    <span class="hljs-keyword">if</span> g.bestScore &lt; score &#123;      g.bestScore = score    &#125;    g.mtx.Unlock()  &#125;&#125;</code></pre><h3 id="channel-用以编排，mutex-用以串行"><a href="#channel-用以编排，mutex-用以串行" class="headerlink" title="channel 用以编排，mutex 用以串行"></a>channel 用以编排，mutex 用以串行</h3><p>如果是你来实现，你更愿意使用 <code>channel</code> 还是 <code>mutex</code> ？<br>按照目前提供的信息，毫无疑问，我会选择后者。</p><p>那 channel 和 mutex 有什么区别呢？在什么场景下该使用 channel ？</p><p>其实 <code>Rob Pike</code> 在 <a href="https://go-proverbs.github.io/">Go Proverbs</a> 中总结为：</p><blockquote><p>Channels orchestrate; mutexes serialize.</p></blockquote><p>翻译就是</p><blockquote><p>channel 用以编排，mutex 用以串行</p></blockquote><p>此句话很简单，但也很抽象。究竟该怎样理解呢？</p><h4 id="channel-vs-mutex"><a href="#channel-vs-mutex" class="headerlink" title="channel vs mutex"></a>channel vs mutex</h4><p><code>Rob Pike</code> 在讲述《Concurrency is not Parallelism》中开篇，即提到：</p><ol><li>世界万物是并行的，但是当前的编程语言却是面向对象的</li><li>Golang 希望通过 <code>goroutine</code>（并发执行）、<code>channel</code>（同步和数据传递）、<code>select</code>（多路并发控制）来实现并行</li></ol><p>在之前的文章中，我提到过</p><blockquote><p>对于其他语言的使用者，对于他们而言，程序中的流程控制一般意味着：</p><blockquote><ul><li>if/else</li><li>for loop</li></ul></blockquote><p>在 Go 中，类似的理解仅仅对了一小半。因为 channel 和 select 才是流程控制的重点。<br>channel 提供了强大能力，帮助数据从一个 goroutine 流转到另一个 goroutine。也意味着，channel 对程序的 <strong>数据流</strong> 和 <strong>控制流</strong> 同时存在影响。</p></blockquote><p><code>channel</code> 只是 Go 语言并行化工具集的一部分，其同时肩负了 <strong>数据流</strong> 和 <strong>控制流</strong> 的职责，它是程序结构的组织者。对比来看，<code>mutex</code> 则只关注数据，保障数据串行访问</p><h4 id="编排"><a href="#编排" class="headerlink" title="编排"></a>编排</h4><p>再谈 channel 的编排，可以看下 《Go Concurrency Patterns》中搜索举例：<br><pre><code class="hljs go"><span class="hljs-comment">/*</span><span class="hljs-comment">Example: Google Search 3.0</span><span class="hljs-comment">Given a query, return a page of search results (and some ads).</span><span class="hljs-comment">Send the query to web search, image search, YouTube, Maps, News, etc. then mix the results.</span><span class="hljs-comment">*/</span>c := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> Result)<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123; c &lt;- First(query, Web1, Web2) &#125; ()<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123; c &lt;- First(query, Image1, Image2) &#125; ()<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123; c &lt;- First(query, Video1, Video2) &#125; ()timeout := time.After(<span class="hljs-number">80</span> * time.Millisecond)<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">3</span>; i++ &#123;    <span class="hljs-keyword">select</span> &#123;    <span class="hljs-keyword">case</span> result := &lt;-c:        results = <span class="hljs-built_in">append</span>(results, result)    <span class="hljs-keyword">case</span> &lt;-timeout:        fmt.Println(<span class="hljs-string">&quot;timed out&quot;</span>)        <span class="hljs-keyword">return</span>    &#125;&#125;</code></pre></p><p>无论程序执行在几个核心的机器上，程序的并行结构都没有任何变化，如下：</p><p><img src="/images/channels-orchestrate-mutexes-serialize/orchestrate.png" alt="orchestrate.png"></p><p>讲到程序结构的编排，可以跟服务编排的 Kubernetes 类比。 如果说 goroutine 是 K8S 的容器，channel 就是 K8S 的网络（如，overlay）。Kubernetes 使用户能够以任何规模部署和扩展其微服务应用程序，Golang 使程序能够在任何数量 CPU 的机器上执行和和扩展进行充分的并行。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>就像《Concurrency is not Parallelism》说明的那样，目前 channel很大程度的被误用或滥用了。了解清楚 channel 的本质，才能使用正确的工具做对的事。</p><blockquote><p>Goroutines and channels are big ideas. They’re tools for program construction.<br>But sometimes all you need is a reference counter.<br>Go has “sync” and “sync/atomic” packages that provide mutexes, condition variables, etc. They provide tools for smaller problems.<br>Often, these things will work together to solve a bigger problem.<br>Always use the right tool for the job.</p></blockquote><p><em>本文涉及源代码</em> ：<a href="https://github.com/cyningsun/go-test/tree/master/20210509-go-channel-vs-mutex">go-test: 《go-channel-vs-mutex》</a></p><p><strong>本文作者</strong>： cyningsun<br /><strong>本文地址</strong>： <a href="https://www.cyningsun.com/05-15-2021/channels-orchestrate-mutexes-serialize.html">https://www.cyningsun.com/05-15-2021/channels-orchestrate-mutexes-serialize.html</a> <br /><strong>版权声明</strong>：本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;channel 是 Go 语言独有的一个特性，相比 goroutine 更加抽象，也更加难以理解。毕竟后者可以类比线程、进程。&lt;a href=&quot;https://www.jtolio.com/2016/03/go-channels-are-bad-and-you-should</summary>
      
    
    
    
    <category term="Golang" scheme="https://www.cyningsun.com/category/Golang/"/>
    
    
    <category term="Channel" scheme="https://www.cyningsun.com/tag/Channel/"/>
    
  </entry>
  
</feed>
