<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="sogou_site_verification" content="MQ6oTycfG3"/>
<meta name="google-site-verification" content="hqIFVwBa7rWx4VpI_8SjaGCBNRD664DCU_Sulcvdit8" />
<meta name="360-site-verification" content="329fb6aa8e262eb052b215fce0617f04" />
<meta name="bytedance-verification-code" content="UEpFiB9TrD8NdRaxRndn" />
<meta name="shenma-site-verification" content="0651eae61e001b3f7a26821e537c7ad0_1600871722">

<title>译｜Monitoring and Tuning the Linux Networking Stack: Sending Data</title>
<meta property="og:site_name" content="有疑说">
<meta property="article:publisher" content="https://www.cyningsun.com" />
<meta property="article:author" content="https://www.cyningsun.com" />
<meta property="article:published_time" content="2023-04-25 00:00:00 +0800"/>

<meta property="article:modified_time" content="2025-08-03 00:00:00 +0800"/>

<meta property="og:url" content="/04-25-2023/monitoring-and-tuning-the-linux-networking-stack-sent-cn.html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta itemprop="description" name="description" content="TL;DR本文解释了 Linux 内核的计算机如何发送数据包，以及当数据包从用户程序流向网络硬件时，如何监控和调优网络栈的每个组件。 本文是之前的文章 监控和调优 Linux 网络栈：接收数据 的姊妹篇。 如果不阅读内核的源代码，不深入了解到底发生了什么，就不可能调优或监控 Linux 网络栈。 希望本文能给想做这方面工作的人提供参考。 关于监控和调优 Li">

<meta name="keywords" content="Linux 协议栈，监控，调优，发送">


<link rel="stylesheet" href="/css/bootstrap.css">


<link rel="stylesheet" href="/css/hc.css">

<link rel="shortcut icon" href="/img/favicon.ico">
<style>
    html{ background:#eee; }
    pre{white-space:pre-wrap;}

    em{ text-transform:lowercase; color:#1abc9c; }
    :-moz-any(h1, h2, h3, h4, h5, h5) em{ text-transform: capitalize; }
    em:hover{ color:inherit; }

    #article{ padding:10% 10% 1% 10%; position:relative;   background:#fff;}
    #tagline{ color:#999; font-size:1em; margin:-2em 0 2em; padding-bottom:2em; border-bottom:3px double #eee; }
    #table{ margin-bottom:2em; color:#888; }

    a,code {
      word-break:break-all;
    }

    @media only screen and (max-width: 640px) {
      table{ word-break:break-all;word-wrap:break-word;font-size:12px; }
      .typo table th, .typo table td, .typo-table th, .typo-table td .typo table caption {
        padding: 0.5em;
      }
      #fork{ display:none; }
    }

    ol.toc::before {
      content: '目录';
      font-size: 1.3em;
      border-left: 5px solid #999;
      padding: 2px 5px 2px 15px;
    }
    ol.toc {
        background: #fff;
        overflow: hidden;
        border: 1px solid #efefef;
        color: #999;
        margin-left: 0;
        margin-bottom: 10px;
    }

    ol.toc li {
      padding: 2px 5px 2px 20px;
    }

    ol.toc ol {
      list-style: circle;
      padding: 0px 0px 0px 0px;
      margin-bottom: 0px;
    }

    ol.related::before {
      content: '相关文章';
      font-size: 1.3em;
      border-left: 5px solid #999;
      padding: 2px 5px 2px 15px;
    }
    ol.related {
        background: #fff; 
        overflow: hidden;
        color: #999;
        margin-top: 40px;
        margin-left: 0;
        margin-bottom: 10px;
    }

    ol.related li {
      padding: 2px 5px 2px 20px;
    }
    .official-account-wrapper {
      width: 200px;
      margin-left: 0px;
      padding: 70px 5px 10px 20px;
    }
    .official-account-wrapper img {
      width: 150px;
      height: 150px;
      border-width:2px;
      border-color:#999;
    }
</style>

<link rel="stylesheet" href="/css/iconfont.css">


<link rel="stylesheet" href="/css/syntax.css">

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?fedff94a2e83a6e2a4d203129a3272e8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>    
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-156665333-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'UA-156665333-1');
</script>
  <meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/feed.xml" title="有疑说" type="application/atom+xml">
</head>
  <body>
    <div id = "wrapper">
    <div class="nav-toggle"><i class="fa fa-bars fa-2x"></i> Herring Cove </div>
<div class="navbar navbar-default" role="navigation">
    <div class="container">
        <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </button>
        <p class="navbar-brand">有疑说 </p>
        </div>
        <div class="navbar-collapse collapse">
        <ul class="nav navbar-nav">
          <li><a href="/subjects">主题</a></li>
          <li><a href="/archives">归档</a></li>
          <li><a href="/links">链接</a></li>
          <li><a href="/about">关于</a></li>
        </ul>
        </div><!--/.nav-collapse -->
    </div>
</div>

<!-- Sidebar -->
<div id="sidebar-wrapper">
  <ul class="sidebar-nav">
    <li class="sidebar-brand"><a href="/"><div class="brand">有疑说 </div></a><div>博学、慎思、明辨、笃行</div></li>
    <hr />
          <li><a href="/subjects">主题</a></li>
          <li><a href="/archives">归档</a></li>
          <li><a href="/links">链接</a></li>
          <li><a href="/about">关于</a></li>
    <hr />
    <div id="social-wrapper">
      <li> <a href="http://weibo.com/CyningSun"  target="_blank"><i class="iconfont icon-weibo"></i> @Weibo</a></li>
      <li> <a href="mailto:cyningsun@gmail.com" ><i class="iconfont icon-gmail"></i> Gmail</a> </li>
      <li> <a href="https://www.douban.com/people/cyningscut" target="_blank"><i class="iconfont icon-douban"></i> Douban</a></li>
      <li> <a href="https://github.com/cyningsun" target="_blank"><i class="iconfont icon-github"></i> Github</a> </li>
      <li><a href="/feed.xml" target="_blank"><i class="iconfont icon-rss"></i> RSS</a></li>
    </div>
    <div class="official-account-wrapper" align="center">
      <img src="/img/official-account-qrcode.jpg" alt="official-account-qrcode"/>
      <div>关注公众号</div>
      </div>
  </ul>
</div>
      <div class="container">
        <div id="article"  class="typo">
    <h1>译｜Monitoring and Tuning the Linux Networking Stack: Sending Data</h1><br/>
    
    <div class="timestamp-info" style="font-family: 'PingFang SC', Verdana, 'Helvetica Neue', 'Microsoft Yahei', 'Hiragino Sans GB', 'Microsoft Sans Serif', 'WenQuanYi Micro Hei', sans-serif; font-weight: 100; font-size: 14px; color: #666; margin-bottom: 10px; padding: 5px; text-align: center;">
        First Published: 2023-04-25
         | 
        Last Revised: 2025-08-03
    </div>
    
    <h2 id="tagline" class="serif"></h2>
    <div class="post">
        
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#TL-DR"><span class="toc-text">TL;DR</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E7%9B%91%E6%8E%A7%E5%92%8C%E8%B0%83%E4%BC%98-Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%9A%84%E4%B8%80%E8%88%AC%E6%80%A7%E5%BB%BA%E8%AE%AE"><span class="toc-text">关于监控和调优 Linux 网络栈的一般性建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%A7%88"><span class="toc-text">概览</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%A6%E7%BB%86%E6%8E%A2%E8%AE%A8"><span class="toc-text">详细探讨</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8F%E8%AE%AE%E6%97%8F%E6%B3%A8%E5%86%8C"><span class="toc-text">协议族注册</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A5%97%E6%8E%A5%E5%AD%97%E5%8F%91%E9%80%81%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE"><span class="toc-text">套接字发送网络数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#sock-sendmsg%E3%80%81-sock-sendmsg-%E5%92%8C-sock-sendmsg-nosec"><span class="toc-text">sock_sendmsg、__sock_sendmsg 和 __sock_sendmsg_nosec</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#inet-sendmsg"><span class="toc-text">inet_sendmsg</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#UDP-%E5%8D%8F%E8%AE%AE%E5%B1%82"><span class="toc-text">UDP 协议层</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#udp-sendmsg"><span class="toc-text">udp_sendmsg</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#UDP-corking"><span class="toc-text">UDP corking</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96-UDP-%E7%9B%AE%E6%A0%87%E5%9C%B0%E5%9D%80%E5%92%8C%E7%AB%AF%E5%8F%A3"><span class="toc-text">获取 UDP 目标地址和端口</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A5%97%E6%8E%A5%E5%AD%97%E4%BC%A0%E8%BE%93%E7%B0%BF%E8%AE%B0%E5%92%8C%E6%97%B6%E9%97%B4%E6%88%B3"><span class="toc-text">套接字传输簿记和时间戳</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#sendmsg-%E5%8F%91%E9%80%81%E8%BE%85%E5%8A%A9%E6%B6%88%E6%81%AF"><span class="toc-text">sendmsg 发送辅助消息</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89-IP-%E9%80%89%E9%A1%B9"><span class="toc-text">设置自定义 IP 选项</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%84%E6%92%AD%E8%BF%98%E6%98%AF%E5%8D%95%E6%92%AD%EF%BC%9F"><span class="toc-text">组播还是单播？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B7%AF%E7%94%B1"><span class="toc-text">路由</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-MSG-CONFIRM-%E9%98%BB%E6%AD%A2-ARP-%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88"><span class="toc-text">使用 MSG_CONFIRM 阻止 ARP 缓存失效</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#uncorked-UDP-%E5%A5%97%E6%8E%A5%E5%AD%97%E7%9A%84%E5%BF%AB%E9%80%9F%E8%B7%AF%E5%BE%84%EF%BC%9A%E5%87%86%E5%A4%87%E4%BC%A0%E8%BE%93%E6%95%B0%E6%8D%AE"><span class="toc-text">uncorked UDP 套接字的快速路径：准备传输数据</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#ip-make-skb"><span class="toc-text">ip_make_skb</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%BC%A0%E8%BE%93%E6%95%B0%E6%8D%AE%EF%BC%81"><span class="toc-text">传输数据！</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#corked-UDP-%E5%A5%97%E6%8E%A5%E5%AD%97%E7%9A%84%E6%85%A2%E9%80%9F%E8%B7%AF%E5%BE%84%EF%BC%9A%E6%B2%A1%E6%9C%89%E9%A2%84%E5%85%88%E5%AD%98%E5%9C%A8%E7%9A%84-corked-%E6%95%B0%E6%8D%AE"><span class="toc-text">corked UDP 套接字的慢速路径：没有预先存在的 corked 数据</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#ip-append-data"><span class="toc-text">ip_append_data</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#ip-append-data-1"><span class="toc-text">__ip_append_data</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%88%B7%E6%96%B0-corked-%E5%A5%97%E6%8E%A5%E5%AD%97"><span class="toc-text">刷新 corked 套接字</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%94%99%E8%AF%AF%E7%BB%9F%E8%AE%A1"><span class="toc-text">错误统计</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#udp-send-skb"><span class="toc-text">udp_send_skb</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E6%8E%A7%EF%BC%9AUDP-%E5%8D%8F%E8%AE%AE%E5%B1%82%E7%BB%9F%E8%AE%A1%E4%BF%A1%E6%81%AF"><span class="toc-text">监控：UDP 协议层统计信息</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#proc-net-snmp"><span class="toc-text">&#x2F;proc&#x2F;net&#x2F;snmp</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#proc-net-udp"><span class="toc-text">&#x2F;proc&#x2F;net&#x2F;udp</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E4%BC%98%EF%BC%9A%E5%A5%97%E6%8E%A5%E5%AD%97%E5%8F%91%E9%80%81%E9%98%9F%E5%88%97%E5%86%85%E5%AD%98"><span class="toc-text">调优：套接字发送队列内存</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#IP-%E5%8D%8F%E8%AE%AE%E5%B1%82"><span class="toc-text">IP 协议层</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ip-send-skb"><span class="toc-text">ip_send_skb</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ip-local-out-%E5%92%8C-ip-local-out"><span class="toc-text">ip_local_out 和 __ip_local_out</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#netfilter-%E5%92%8C-nf-hook"><span class="toc-text">netfilter 和 nf_hook</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E7%BC%93%E5%AD%98"><span class="toc-text">目标缓存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ip-output"><span class="toc-text">ip_output</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ip-finish-output"><span class="toc-text">ip_finish_output</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B7%AF%E5%BE%84-MTU-%E5%8F%91%E7%8E%B0"><span class="toc-text">路径 MTU 发现</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ip-finish-output2"><span class="toc-text">ip_finish_output2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dst-neigh-output"><span class="toc-text">dst_neigh_output</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#neigh-hh-output"><span class="toc-text">neigh_hh_output</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#n-gt-output"><span class="toc-text">n-&gt;output</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#neigh-resolve-output"><span class="toc-text">neigh_resolve_output</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E6%8E%A7%EF%BC%9AIP-%E5%8D%8F%E8%AE%AE%E5%B1%82"><span class="toc-text">监控：IP 协议层</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#proc-net-snmp-1"><span class="toc-text">&#x2F;proc&#x2F;net&#x2F;snmp</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#proc-net-netstat"><span class="toc-text">&#x2F;proc&#x2F;net&#x2F;netstat</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E5%AD%90%E7%B3%BB%E7%BB%9F"><span class="toc-text">Linux 网络设备子系统</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Linux-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6"><span class="toc-text">Linux 流量控制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dev-queue-xmit-%E5%92%8C-dev-queue-xmit"><span class="toc-text">dev_queue_xmit 和 __dev_queue_xmit</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#netdev-pick-tx"><span class="toc-text">netdev_pick_tx</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#netdev-pick-tx-1"><span class="toc-text">__netdev_pick_tx</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Transmit-Packet-Steering-XPS"><span class="toc-text">Transmit Packet Steering(XPS)</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#skb-tx-hash"><span class="toc-text">skb_tx_hash</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%81%A2%E5%A4%8D-dev-queue-xmit"><span class="toc-text">恢复 __dev_queue_xmit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dev-xmit-skb"><span class="toc-text">__dev_xmit_skb</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E4%BC%98%EF%BC%9ATransmit-Packet-Steering-XPS"><span class="toc-text">调优：Transmit Packet Steering(XPS)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%92%E9%98%9F%E8%A7%84%E5%88%99%EF%BC%81"><span class="toc-text">排队规则！</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#qdisc-run-begin-%E5%92%8C-qdisc-run-end"><span class="toc-text">qdisc_run_begin 和 qdisc_run_end</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#qdisc-run"><span class="toc-text">__qdisc_run</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#qdisc-restart"><span class="toc-text">qdisc_restart</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#dequeue-skb"><span class="toc-text">dequeue_skb</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#sch-direct-xmit"><span class="toc-text">sch_direct_xmit</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#handle-dev-cpu-collision"><span class="toc-text">handle_dev_cpu_collision</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#dev-requeue-skb"><span class="toc-text">dev_requeue_skb</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8F%90%E9%86%92%EF%BC%8C-qdisc-run-%E4%B8%AD%E7%9A%84-while-%E5%BE%AA%E7%8E%AF"><span class="toc-text">提醒， __qdisc_run 中的 while 循环</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#netif-schedule"><span class="toc-text">__netif_schedule</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#net-tx-action"><span class="toc-text">net_tx_action</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#net-tx-action-%E5%AE%8C%E6%88%90%E9%98%9F%E5%88%97"><span class="toc-text">net_tx_action 完成队列</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#net-tx-action-%E8%BE%93%E5%87%BA%E9%98%9F%E5%88%97"><span class="toc-text">net_tx_action 输出队列</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E5%90%8E%EF%BC%8C%E6%88%91%E4%BB%AC%E6%9D%A5%E7%9C%8B%E7%9C%8B%E6%88%91%E4%BB%AC%E7%9A%84%E6%9C%8B%E5%8F%8B-dev-hard-start-xmit"><span class="toc-text">最后，我们来看看我们的朋友 dev_hard_start_xmit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E6%8E%A7-qdiscs"><span class="toc-text">监控 qdiscs</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-tc-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7"><span class="toc-text">使用 tc 命令行工具</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E4%BC%98-qdiscs"><span class="toc-text">调优 qdiscs</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A2%9E%E5%8A%A0-qdisc-run"><span class="toc-text">增加 __qdisc_run</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A2%9E%E5%8A%A0%E4%BC%A0%E8%BE%93%E9%98%9F%E5%88%97%E9%95%BF%E5%BA%A6"><span class="toc-text">增加传输队列长度</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F"><span class="toc-text">网络设备驱动程序</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A9%B1%E5%8A%A8%E6%93%8D%E4%BD%9C%E6%B3%A8%E5%86%8C"><span class="toc-text">驱动操作注册</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-ndo-start-xmit-%E4%BC%A0%E8%BE%93%E6%95%B0%E6%8D%AE"><span class="toc-text">使用 ndo_start_xmit 传输数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#igb-tx-map"><span class="toc-text">igb_tx_map</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E9%98%9F%E5%88%97%E9%99%90%E5%88%B6%EF%BC%88DQL%EF%BC%89"><span class="toc-text">动态队列限制（DQL）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%A0%E8%BE%93%E5%AE%8C%E6%88%90"><span class="toc-text">传输完成</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BC%A0%E8%BE%93%E5%AE%8C%E6%88%90-IRQ"><span class="toc-text">传输完成 IRQ</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#igb-poll"><span class="toc-text">igb_poll</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#igb-clean-tx-irq"><span class="toc-text">igb_clean_tx_irq</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#igb-poll-%E8%BF%94%E5%9B%9E%E5%80%BC"><span class="toc-text">igb_poll 返回值</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E6%8E%A7%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87"><span class="toc-text">监控网络设备</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-ethtool-S"><span class="toc-text">使用 ethtool -S</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-sysfs"><span class="toc-text">使用 sysfs</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-proc-net-dev"><span class="toc-text">使用 &#x2F;proc&#x2F;net&#x2F;dev</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E6%8E%A7%E5%8A%A8%E6%80%81%E9%98%9F%E5%88%97%E9%99%90%E5%88%B6"><span class="toc-text">监控动态队列限制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E4%BC%98%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87"><span class="toc-text">调优网络设备</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5%E6%AD%A3%E5%9C%A8%E4%BD%BF%E7%94%A8%E7%9A%84%E4%BC%A0%E8%BE%93%E9%98%9F%E5%88%97%E6%95%B0"><span class="toc-text">检查正在使用的传输队列数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B0%83%E6%95%B4%E4%BD%BF%E7%94%A8%E7%9A%84%E4%BC%A0%E8%BE%93%E9%98%9F%E5%88%97%E6%95%B0"><span class="toc-text">调整使用的传输队列数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B0%83%E6%95%B4%E4%BC%A0%E8%BE%93%E9%98%9F%E5%88%97%E7%9A%84%E5%A4%A7%E5%B0%8F"><span class="toc-text">调整传输队列的大小</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9D%9F"><span class="toc-text">结束</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96"><span class="toc-text">其他</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%8F%E5%B0%91-ARP-%E6%B5%81%E9%87%8F%EF%BC%88MSG-CONFIRM%EF%BC%89"><span class="toc-text">减少 ARP 流量（MSG_CONFIRM）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#UDP-Corking"><span class="toc-text">UDP Corking</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E6%88%B3"><span class="toc-text">时间戳</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-text">结论</span></a></li></ol>
 
        <h2 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h2><p>本文解释了 Linux 内核的计算机如何发送数据包，以及当数据包从用户程序流向网络硬件时，如何监控和调优网络栈的每个组件。</p>
<p>本文是之前的文章 <a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/">监控和调优 Linux 网络栈：接收数据</a> 的姊妹篇。</p>
<p>如果不阅读内核的源代码，不深入了解到底发生了什么，就不可能调优或监控 Linux 网络栈。</p>
<p>希望本文能给想做这方面工作的人提供参考。</p>
<h2 id="关于监控和调优-Linux-网络栈的一般性建议"><a href="#关于监控和调优-Linux-网络栈的一般性建议" class="headerlink" title="关于监控和调优 Linux 网络栈的一般性建议"></a>关于监控和调优 Linux 网络栈的一般性建议</h2><p>正如在上一篇文章中提到的，Linux 网络栈是复杂的，没有一刀切的监控或调优解决方案。 如果您真的想调优网络栈，您别无选择，只能投入大量的时间、精力和金钱来了解网络系统的各个部分是如何交互的。</p>
<p>本文中提供的许多示例设置仅用于说明目的，并不是对某个配置或默认设置的推荐或反对。 在调整任何设置之前，您应该围绕您需要监控的内容制定一个参考框架，以注意到有意义的变化。</p>
<p>网络连接到计算机时调整网络设置是危险的；你很容易地把自己锁在外面，或者完全关闭你的网络。 不要在生产机器上调整这些设置；相反，如果可能的话，在新机器上进行调整，再投入生产中。</p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>作为参考，您可能需要手边有一份设备数据手册。 这篇文章将研究由 <code>igb</code> 设备驱动程序控制的 Intel I350 以太网控制器。 您可以找到该数据手册（警告：大型 PDF）<a target="_blank" rel="noopener" href="http://www.intel.com/content/dam/www/public/us/en/documents/datasheets/ethernet-controller-i350-datasheet.pdf">供您参考</a>。</p>
<p>网络数据从用户程序到网络设备的流程概览：</p>
<ol>
<li>使用系统调用（如<code>sendto</code>、<code>sendmsg</code>等）写入数据。</li>
<li>数据通过套接字子系统传递到套接字协议族的系统（本例是 <code>AF_INET</code>）。</li>
<li>协议族通过协议层传递数据，协议层（在许多情况下）将数据转成数据包。</li>
<li>数据通过路由层，沿途填充目标和邻居缓存（如果是冷缓存）。 如果需要查找以太网地址，会生成 ARP 流量。</li>
<li>在通过协议层之后，数据包到达设备无关层。</li>
<li>使用 XPS（如果启用）或哈希函数选择输出队列。</li>
<li>调用设备驱动程序的发送函数。</li>
<li>然后，数据被传递到输出设备附属的排队规则（qdisc）。</li>
<li>如果可以，qdisc 将直接传输数据；或将其排队，等待 <code>NET_TX</code> 软中断期间发送。</li>
<li>最后，数据从 qdisc 传递给驱动程序。</li>
<li>驱动程序创建所需的 DMA 映射，以便设备可以从 RAM 读取数据。</li>
<li>驱动器向设备发送信号，表示数据准备就绪。</li>
<li>设备从 RAM 读取数据并传输。</li>
<li>传输完成后，设备发出硬中断信号，表示传输完成。</li>
<li>驱动程序注册的传输完成硬中断处理程序运行。 对于许多设备，此处理程序只是生成  <code>NET_RX</code>  软中断，触发 NAPI 轮询循环开始运行。</li>
<li>软中断触发轮询函数运行，并调用驱动程序以解除 DMA 映射、释放数据包。</li>
</ol>
<p>接下来各节会详细介绍以上整个流程。</p>
<p>下面探讨的协议层是 IP 和 UDP 协议层。 本文介绍的许多信息也可作为其他协议层的参考。</p>
<h2 id="详细探讨"><a href="#详细探讨" class="headerlink" title="详细探讨"></a>详细探讨</h2><p>与<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/">姊妹篇类似</a>，本文将探讨 Linux 3.13.0 版本内核，贯穿全文提供了 GitHub 代码链接和代码片段。</p>
<p>从如何在内核中注册协议族、套接字子系统如何使用协议族开始探讨，然后探讨协议族接收数据。</p>
<h3 id="协议族注册"><a href="#协议族注册" class="headerlink" title="协议族注册"></a>协议族注册</h3><p>当用户程序中运行这样一段代码来创建 UDP 套接字时，会发生什么？</p>
<pre><code class="hljs c++">sock = <span class="hljs-built_in">socket</span>(AF_INET, SOCK_DGRAM, IPPROTO_UDP)</code></pre>

<p>简而言之，Linux 内核查找 UDP 协议栈导出的一组函数，它们处理包括发送和接收网络数据在内的许多事情。 要准确理解其工作原理，必须深入 <code>AF_INET</code> 地址族代码。</p>
<p>Linux 内核在内核初始化的早期执行 <code>inet_init</code> 函数。 此函数注册 <code>AF_INET</code> 协议族、协议族中的各种协议栈（TCP、UDP、ICMP 和 RAW），并调用初始化程序使协议栈准备好处理网络数据。 您可以在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/af_inet.c#L1678-L1804">.&#x2F;net&#x2F;ipv4&#x2F;af_inet.c</a> 中找到 <code>inet_init</code> 的代码。</p>
<p><code>AF_INET</code> 协议族导出了一个具有 <code>create</code> 函数的结构。 当用户程序创建套接字时，内核会调用此函数：</p>
<pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_proto_family</span> inet_family_ops = &#123;
        .family = PF_INET,
        .create = inet_create,
        .owner  = THIS_MODULE,
&#125;;</code></pre>

<p><code>inet_create</code> 函数接受传递给套接字系统调用的参数，搜索已注册的协议，以找到链接到套接字的一组操作。 看一看：</p>
<pre><code class="hljs c++">        <span class="hljs-comment">/* Look for the requested type/protocol pair. */</span>
lookup_protocol:
        err = -ESOCKTNOSUPPORT;
        <span class="hljs-built_in">rcu_read_lock</span>();
        <span class="hljs-built_in">list_for_each_entry_rcu</span>(answer, &amp;inetsw[sock-&gt;type], list) &#123;

                err = <span class="hljs-number">0</span>;
                <span class="hljs-comment">/* Check the non-wild match. */</span>
                <span class="hljs-keyword">if</span> (protocol == answer-&gt;protocol) &#123;
                        <span class="hljs-keyword">if</span> (protocol != IPPROTO_IP)
                                <span class="hljs-keyword">break</span>;
                &#125; <span class="hljs-keyword">else</span> &#123;
                        <span class="hljs-comment">/* Check for the two wild cases. */</span>
                        <span class="hljs-keyword">if</span> (IPPROTO_IP == protocol) &#123;
                                protocol = answer-&gt;protocol;
                                <span class="hljs-keyword">break</span>;
                        &#125;
                        <span class="hljs-keyword">if</span> (IPPROTO_IP == answer-&gt;protocol)
                                <span class="hljs-keyword">break</span>;
                &#125;
                err = -EPROTONOSUPPORT;
        &#125;</code></pre>

<p>稍后，复制 <code>answer</code> 的 <code>ops</code> 字段到套接字结构中，<code>answer</code> 持有协议栈相关的引用：</p>
<pre><code class="hljs c++">sock-&gt;ops = answer-&gt;ops;</code></pre>

<p>可以在 <code>af_inet.c</code> 中找到所有协议栈的结构定义。 让我们看一下<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/af_inet.c#L998-L1020">TCP 和 UDP 协议结构</a>：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* Upon startup we insert all the elements in inetsw_array[] into</span>
<span class="hljs-comment"> * the linked list inetsw.</span>
<span class="hljs-comment"> */</span>
<span class="hljs-type">static</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">inet_protosw</span> inetsw_array[] =
&#123;
        &#123;
                .type =       SOCK_STREAM,
                .protocol =   IPPROTO_TCP,
                .prot =       &amp;tcp_prot,
                .ops =        &amp;inet_stream_ops,
                .no_check =   <span class="hljs-number">0</span>,
                .flags =      INET_PROTOSW_PERMANENT |
                              INET_PROTOSW_ICSK,
        &#125;,

        &#123;
                .type =       SOCK_DGRAM,
                .protocol =   IPPROTO_UDP,
                .prot =       &amp;udp_prot,
                .ops =        &amp;inet_dgram_ops,
                .no_check =   UDP_CSUM_DEFAULT,
                .flags =      INET_PROTOSW_PERMANENT,
       &#125;,

			<span class="hljs-comment">/* .... more protocols ... */</span></code></pre>

<p>在 <code>IPPROTO_UDP</code> 的情况下，<code>ops</code> 结构关联包含各种功能的<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/af_inet.c#L935-L960">函数</a>，包括发送和接收数据：</p>
<pre><code class="hljs c++"><span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">proto_ops</span> inet_dgram_ops = &#123;
  .family		   = PF_INET,
  .owner		   = THIS_MODULE,

  <span class="hljs-comment">/* ... */</span>

  .sendmsg	   = inet_sendmsg,
  .recvmsg	   = inet_recvmsg,

  <span class="hljs-comment">/* ... */</span>
&#125;;
<span class="hljs-built_in">EXPORT_SYMBOL</span>(inet_dgram_ops);</code></pre>

<p>协议相关的结构 <code>prot</code> 包含函数指针，指向 UDP 协议栈所有内部函数。UDP 协议中，此结构被称为 <code>udp_prot</code>，并由 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/udp.c#L2171-L2203">.&#x2F;net&#x2F;ipv4&#x2F;udp.c</a> 导出：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">proto</span> udp_prot = &#123;
  .name		   = <span class="hljs-string">&quot;UDP&quot;</span>,
  .owner		   = THIS_MODULE,

  <span class="hljs-comment">/* ... */</span>

  .sendmsg	   = udp_sendmsg,
  .recvmsg	   = udp_recvmsg,

  <span class="hljs-comment">/* ... */</span>
&#125;;
<span class="hljs-built_in">EXPORT_SYMBOL</span>(udp_prot);</code></pre>

<p>现在，转向一段发送 UDP 数据的用户程序，看内核是如何调用 <code>udp_sendmsg</code>  的！</p>
<h3 id="套接字发送网络数据"><a href="#套接字发送网络数据" class="headerlink" title="套接字发送网络数据"></a>套接字发送网络数据</h3><p>用户程序想要发送 UDP 网络数据，因此它使用 <code>sendto</code> 系统调用，可能像这样：</p>
<pre><code class="hljs c++">ret = <span class="hljs-built_in">sendto</span>(socket, buffer, buflen, <span class="hljs-number">0</span>, &amp;dest, <span class="hljs-built_in">sizeof</span>(dest));</code></pre>

<p>此系统调用经过<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/the-definitive-guide-to-linux-system-calls/">Linux 系统调用</a>层，并落在<code>./net/socket.c</code> 中的<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/socket.c#L1756-L1803">这个函数</a>：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/*</span>
<span class="hljs-comment"> *      Send a datagram to a given address. We move the address into kernel</span>
<span class="hljs-comment"> *      space and check the user space data area is readable before invoking</span>
<span class="hljs-comment"> *      the protocol.</span>
<span class="hljs-comment"> */</span>

<span class="hljs-built_in">SYSCALL_DEFINE6</span>(sendto, <span class="hljs-type">int</span>, fd, <span class="hljs-type">void</span> __user *, buff, <span class="hljs-type">size_t</span>, len,
                <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>, flags, <span class="hljs-keyword">struct</span> sockaddr __user *, addr,
                <span class="hljs-type">int</span>, addr_len)
&#123;
	<span class="hljs-comment">/*  ... code ... */</span>

	err = <span class="hljs-built_in">sock_sendmsg</span>(sock, &amp;msg, len);

	<span class="hljs-comment">/* ... code  ... */</span>
&#125;</code></pre>

<p><code>SYSCALL_DEFINE6</code> 宏展开<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/linux/syscalls.h#L170-L198">为一堆宏</a>，这些宏反过来使用 6 个参数，建立基础结构来创建系统调用（因此是 <code>DEFINE6</code>）。 这样做的一个结果是，内核的系统调用函数名都有 <code>sys_</code> 前缀。</p>
<p><code>sendto</code> 的系统调用代码，组织数据为较低层能够处理的格式之后，调用 <code>sock_sendmsg</code>。 特别是，它将传递给 <code>sendto</code> 的目标地址构造一个结构，让我们来看一下：</p>
<pre><code class="hljs c++">iov.iov_base = buff;
iov.iov_len = len;
msg.msg_name = <span class="hljs-literal">NULL</span>;
msg.msg_iov = &amp;iov;
msg.msg_iovlen = <span class="hljs-number">1</span>;
msg.msg_control = <span class="hljs-literal">NULL</span>;
msg.msg_controllen = <span class="hljs-number">0</span>;
msg.msg_namelen = <span class="hljs-number">0</span>;
<span class="hljs-keyword">if</span> (addr) &#123;
        err = <span class="hljs-built_in">move_addr_to_kernel</span>(addr, addr_len, &amp;address);
        <span class="hljs-keyword">if</span> (err &lt; <span class="hljs-number">0</span>)
                <span class="hljs-keyword">goto</span> out_put;
        msg.msg_name = (<span class="hljs-keyword">struct</span> sockaddr *)&amp;address;
        msg.msg_namelen = addr_len;
&#125;</code></pre>

<p>此段代码复制用户程序传入的 <code>addr</code> 到内核数据结构 <code>address</code> 中，然后以 <code>msg_name</code> 嵌入到 <code>struct msghdr</code> 结构中。 类似于 userland 程序不调用 <code>sendto</code>，而是直接调用 <code>sendmsg</code> 时所做的操作。内核提供此变化，是因为 <code>sendto</code> 和 <code>sendmsg</code> 都调用到 <code>sock_sendmsg</code>。</p>
<h4 id="sock-sendmsg、-sock-sendmsg-和-sock-sendmsg-nosec"><a href="#sock-sendmsg、-sock-sendmsg-和-sock-sendmsg-nosec" class="headerlink" title="sock_sendmsg、__sock_sendmsg 和 __sock_sendmsg_nosec"></a><code>sock_sendmsg</code>、<code>__sock_sendmsg</code> 和 <code>__sock_sendmsg_nosec</code></h4><p>在调用 <code>__sock_sendmsg</code> 之前，<code>sock_sendmsg</code> 会执行一些错误检查，而 <code>__sock_sendmsg</code> 在调用 <code>__sock_sendmsg_nosec</code> 之前也会进行自己的错误检查。<code>__sock_sendmsg_nosec</code> 传递数据到更深层的套接字子系统中。</p>
<pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> __sock_sendmsg_nosec(<span class="hljs-keyword">struct</span> kiocb *iocb, <span class="hljs-keyword">struct</span> socket *sock,
                                       <span class="hljs-keyword">struct</span> msghdr *msg, <span class="hljs-type">size_t</span> size)
&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sock_iocb</span> *si =  ....

				<span class="hljs-comment">/* other code ... */</span>

        <span class="hljs-keyword">return</span> sock-&gt;ops-&gt;<span class="hljs-built_in">sendmsg</span>(iocb, sock, msg, size);
&#125;</code></pre>

<p>如前一节解释套接字创建时所述，注册到此套接字 <code>ops</code> 结构的 <code>sendmsg</code> 函数是<code>inet_sendmsg</code>。</p>
<h4 id="inet-sendmsg"><a href="#inet-sendmsg" class="headerlink" title="inet_sendmsg"></a><code>inet_sendmsg</code></h4><p>从名字不难猜到，这是 <code>AF_INET</code> 协议族提供的一个通用函数。 此函数首先调用<code>sock_rps_record_flow</code> 记录最后一个处理流的 CPU；<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#receive-packet-steering-rps">接收数据包转向</a>会使用该信息。 接下来，查找并调用套接字的内部协议操作结构的 <code>sendmsg</code> 函数：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">inet_sendmsg</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> kiocb *iocb, <span class="hljs-keyword">struct</span> socket *sock, <span class="hljs-keyword">struct</span> msghdr *msg,</span></span>
<span class="hljs-params"><span class="hljs-function">                 <span class="hljs-type">size_t</span> size)</span></span>
<span class="hljs-function"></span>&#123;
  <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sock</span> *sk = sock-&gt;sk;

  <span class="hljs-built_in">sock_rps_record_flow</span>(sk);

  <span class="hljs-comment">/* We may need to bind the socket. */</span>
  <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">inet_sk</span>(sk)-&gt;inet_num &amp;&amp; !sk-&gt;sk_prot-&gt;no_autobind &amp;&amp;
      <span class="hljs-built_in">inet_autobind</span>(sk))
          <span class="hljs-keyword">return</span> -EAGAIN;

  <span class="hljs-keyword">return</span> sk-&gt;sk_prot-&gt;<span class="hljs-built_in">sendmsg</span>(iocb, sk, msg, size);
&#125;
<span class="hljs-built_in">EXPORT_SYMBOL</span>(inet_sendmsg);</code></pre>

<p>在处理 UDP 时，<code>sk-&gt;sk_prot-&gt;sendmsg</code> 指向 UDP 协议层 <code>udp_sendmsg</code>。 <code>udp_sendmsg</code> 是前面看到的 <code>udp_prot</code> 结构导出的。此函数调用<strong>从通用 <code>AF_INET</code> 协议族过渡到 UDP 协议栈</strong>。</p>
<h3 id="UDP-协议层"><a href="#UDP-协议层" class="headerlink" title="UDP 协议层"></a>UDP 协议层</h3><h4 id="udp-sendmsg"><a href="#udp-sendmsg" class="headerlink" title="udp_sendmsg"></a><code>udp_sendmsg</code></h4><p><code>udp_sendmsg</code> 函数位于 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/udp.c#L845-L1088">.&#x2F;net&#x2F;ipv4&#x2F;udp.c</a>。 整个函数相当长，因此我们将探讨其中的一些部分。 如果你想完整地阅读它，请点击前面的链接。</p>
<h5 id="UDP-corking"><a href="#UDP-corking" class="headerlink" title="UDP corking"></a>UDP corking</h5><p>在变量声明和一些基本的错误检查之后，<code>udp_sendmsg</code> 要做的第一件事就是检查套接字是否“corked”。 UDP corking 是一项特性，允许用户程序请求内核累积多次 <code>send</code> 调用的数据到单个数据报中发送。 在用户程序中有两种方法可启用此选项：</p>
<ol>
<li>使用 <code>setsockopt</code> 系统调用，传递 <code>UDP_CORK</code> 套接字选项。</li>
<li>调用 <code>send</code>、<code>sendto</code> 或 <code>sendmsg</code> 时，传递带有 <code>MSG_MORE</code> 的 <code>flags</code> 。</li>
</ol>
<p>以上选项分别记录在 <a target="_blank" rel="noopener" href="http://man7.org/linux/man-pages/man7/udp.7.html">UDP 手册页</a> 和 <a target="_blank" rel="noopener" href="http://man7.org/linux/man-pages/man2/send.2.html">send &#x2F; sendto &#x2F; sendmsg 手册页</a> 。</p>
<p><code>udp_sendmsg</code> 检查 <code>up-&gt;pending</code> 以确定套接字当前是否被 corked。如果是，则直接追加数据。 稍后将看到如何追加数据。</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">udp_sendmsg</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> kiocb *iocb, <span class="hljs-keyword">struct</span> sock *sk, <span class="hljs-keyword">struct</span> msghdr *msg,</span></span>
<span class="hljs-params"><span class="hljs-function">                <span class="hljs-type">size_t</span> len)</span></span>
<span class="hljs-function"></span>&#123;

	<span class="hljs-comment">/* variables and error checking ... */</span>

  fl4 = &amp;inet-&gt;cork.fl.u.ip4;
  <span class="hljs-keyword">if</span> (up-&gt;pending) &#123;
          <span class="hljs-comment">/*</span>
<span class="hljs-comment">           * There are pending frames.</span>
<span class="hljs-comment">           * The socket lock must be held while it&#x27;s corked.</span>
<span class="hljs-comment">           */</span>
          <span class="hljs-built_in">lock_sock</span>(sk);
          <span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(up-&gt;pending)) &#123;
                  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(up-&gt;pending != AF_INET)) &#123;
                          <span class="hljs-built_in">release_sock</span>(sk);
                          <span class="hljs-keyword">return</span> -EINVAL;
                  &#125;
                  <span class="hljs-keyword">goto</span> do_append_data;
          &#125;
          <span class="hljs-built_in">release_sock</span>(sk);
  &#125;</code></pre>

<h5 id="获取-UDP-目标地址和端口"><a href="#获取-UDP-目标地址和端口" class="headerlink" title="获取 UDP 目标地址和端口"></a>获取 UDP 目标地址和端口</h5><p>接下来，从两个可能的来源之一确定目标地址和端口：</p>
<ol>
<li>套接字本身存储的目标地址，因为套接字在某个时间点已连接。</li>
<li>辅助结构传入的地址，正如在 <code>sendto</code> 的内核代码中看到的那样。</li>
</ol>
<p>内核处理逻辑如下：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/*</span>
<span class="hljs-comment"> *      Get and verify the address.</span>
<span class="hljs-comment"> */</span>
<span class="hljs-keyword">if</span> (msg-&gt;msg_name) &#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sockaddr_in</span> *usin = (<span class="hljs-keyword">struct</span> sockaddr_in *)msg-&gt;msg_name;
        <span class="hljs-keyword">if</span> (msg-&gt;msg_namelen &lt; <span class="hljs-built_in">sizeof</span>(*usin))
                <span class="hljs-keyword">return</span> -EINVAL;
        <span class="hljs-keyword">if</span> (usin-&gt;sin_family != AF_INET) &#123;
                <span class="hljs-keyword">if</span> (usin-&gt;sin_family != AF_UNSPEC)
                        <span class="hljs-keyword">return</span> -EAFNOSUPPORT;
        &#125;

        daddr = usin-&gt;sin_addr.s_addr;
        dport = usin-&gt;sin_port;
        <span class="hljs-keyword">if</span> (dport == <span class="hljs-number">0</span>)
                <span class="hljs-keyword">return</span> -EINVAL;
&#125; <span class="hljs-keyword">else</span> &#123;
        <span class="hljs-keyword">if</span> (sk-&gt;sk_state != TCP_ESTABLISHED)
                <span class="hljs-keyword">return</span> -EDESTADDRREQ;
        daddr = inet-&gt;inet_daddr;
        dport = inet-&gt;inet_dport;
        <span class="hljs-comment">/* Open fast path for connected socket.</span>
<span class="hljs-comment">           Route will not be used, if at least one option is set.</span>
<span class="hljs-comment">         */</span>
        connected = <span class="hljs-number">1</span>;
&#125;</code></pre>

<p>是的，UDP 协议层使用 <code>TCP_ESTABLISHED</code>！ 不管怎样，套接字状态都使用 TCP 状态描述。</p>
<p>回想一下前面看到的，当用户程序调用 <code>sendto</code> 时，内核是如何代表用户组装一个 <code>struct msghdr</code> 结构。 上面的代码显示了内核解析该数据设置 <code>daddr</code> 和 <code>dport</code>。</p>
<p>当内核函数访问 <code>udp_sendmsg</code> 函数时，内核函数没有构造 <code>struct msghdr</code> 结构，则从套接字本身获取目标地址和端口，并标记套接字为“已连接”。</p>
<p>两种情况下，都设置 <code>daddr</code> 和 <code>dport</code> 为目标地址和端口。</p>
<h5 id="套接字传输簿记和时间戳"><a href="#套接字传输簿记和时间戳" class="headerlink" title="套接字传输簿记和时间戳"></a>套接字传输簿记和时间戳</h5><p>接下来，获取并存储套接字上设置的源地址、设备索引和时间戳选项（如<code>SOCK_TIMESTAMPING_TX_HARDWARE</code>、<code>SOCK_TIMESTAMPING_TX_SOFTWARE</code>、<code>SOCK_WIFI_STATUS</code>）：</p>
<pre><code class="hljs c++">ipc.addr = inet-&gt;inet_saddr;

ipc.oif = sk-&gt;sk_bound_dev_if;

<span class="hljs-built_in">sock_tx_timestamp</span>(sk, &amp;ipc.tx_flags);</code></pre>

<h5 id="sendmsg-发送辅助消息"><a href="#sendmsg-发送辅助消息" class="headerlink" title="sendmsg 发送辅助消息"></a><code>sendmsg</code> 发送辅助消息</h5><p>除了发送或接收数据包之外，<code>sendmsg</code> 和 <code>recvmsg</code> 系统调用还允许用户设置或请求辅助数据。 用户程序可以创建一个嵌入了请求的 <code>struct msghdr</code>，来使用这些辅助数据。许多辅助数据类型都记录在 <a target="_blank" rel="noopener" href="http://man7.org/linux/man-pages/man7/ip.7.html">IP 手册页</a> 中。</p>
<p>辅助数据的一个常见例子是 <code>IP_PKTINFO</code>。 在 <code>sendmsg</code> 的情况下，此数据类型允许程序设置 <code>struct in_pktinfo</code>，以便发送数据时使用。 通过在结构 <code>struct in_pktinfo</code> 中填充字段，程序可以指定要在数据包上使用的源地址。 如果程序是侦听多个 IP 地址的服务器程序，这是一个有用的选项。 在这种情况下，服务器程序可能希望使用与客户端连接服务器的 IP 地址来回复客户端。<code>IP_PKTINFO</code> 恰好适合这种情况。</p>
<p>类似地，当用户程序向 <code>sendmsg</code> 传递数据时， <code>IP_TTL</code> 和 <code>IP_TOS</code> 辅助消息允许用户在每个数据包的级别设置 IP 数据包的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Time_to_live#IP_packets">TTL</a> 和 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Type_of_service">TOS</a> 值。如果需要，也可以通过使用 <code>setsockopt</code> 设置<code> IP_TTL</code> 和 <code>IP_TOS</code>  在套接字级别，生效套接字的所有传出数据包。 Linux 内核<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/route.c#L179-L197">使用数组</a>转换指定的 TOS 值为优先级。 优先级影响数据包从排队规则传输的方式和时间。 稍后会详细了解这意味着什么。</p>
<p>内核如何处理 <code>sendmsg</code> 在 UDP 套接字上的辅助消息：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (msg-&gt;msg_controllen) &#123;
        err = <span class="hljs-built_in">ip_cmsg_send</span>(<span class="hljs-built_in">sock_net</span>(sk), msg, &amp;ipc,
                           sk-&gt;sk_family == AF_INET6);
        <span class="hljs-keyword">if</span> (err)
                <span class="hljs-keyword">return</span> err;
        <span class="hljs-keyword">if</span> (ipc.opt)
                free = <span class="hljs-number">1</span>;
        connected = <span class="hljs-number">0</span>;
&#125;</code></pre>

<p> <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/ip_sockglue.c#L190-L241">.&#x2F;net&#x2F;ipv4&#x2F;ip_sockglue. c</a> 中的 <code>ip_cmsg_send</code> 负责辅助消息的内部解析。 请注意，只要提供任何辅助数据，都会标记该套接字为未连接。</p>
<h5 id="设置自定义-IP-选项"><a href="#设置自定义-IP-选项" class="headerlink" title="设置自定义 IP 选项"></a>设置自定义 IP 选项</h5><p>接下来，<code>sendmsg</code> 检查用户是否指定了任何带有自定义 IP 选项的辅助消息。 如果设置了选项，则使用这些选项。 如果没有，则使用此套接字已在使用的选项：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (!ipc.opt) &#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ip_options_rcu</span> *inet_opt;

        <span class="hljs-built_in">rcu_read_lock</span>();
        inet_opt = <span class="hljs-built_in">rcu_dereference</span>(inet-&gt;inet_opt);
        <span class="hljs-keyword">if</span> (inet_opt) &#123;
                <span class="hljs-built_in">memcpy</span>(&amp;opt_copy, inet_opt,
                       <span class="hljs-built_in">sizeof</span>(*inet_opt) + inet_opt-&gt;opt.optlen);
                ipc.opt = &amp;opt_copy.opt;
        &#125;
        <span class="hljs-built_in">rcu_read_unlock</span>();
&#125;</code></pre>

<p>接下来，该函数检查是否设置了源记录路由（SRR）IP 选项。 源记录路由有两种类型：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Loose_Source_Routing">宽松源记录路由和严格源记录路由</a>。 如果设置了此选项，记录并存储第一跳地址为 <code>faddr</code>，标记套接字为“未连接”。  <code>faddr</code> 将在后面用到：</p>
<pre><code class="hljs c++">ipc.addr = faddr = daddr;

<span class="hljs-keyword">if</span> (ipc.opt &amp;&amp; ipc.opt-&gt;opt.srr) &#123;
        <span class="hljs-keyword">if</span> (!daddr)
                <span class="hljs-keyword">return</span> -EINVAL;
        faddr = ipc.opt-&gt;opt.faddr;
        connected = <span class="hljs-number">0</span>;
&#125;</code></pre>

<p>在处理 SRR 选项后，从用户辅助消息设置的值，或套接字当前使用的值中，获取 TOS IP 标志。 随后进行检查以确定：</p>
<ul>
<li>套接字是否已设置（使用 <code>setsockopt</code>）<code>SO_DONTROUTE</code> ，或</li>
<li>调用 <code>sendto</code> 或 <code>sendmsg</code> 时，是否已指定 <code>MSG_DONTROUTE</code> 标志，或</li>
<li>是否已设置 <code>is_strictroute</code> ，代表需要严格<a target="_blank" rel="noopener" href="http://www.networksorcery.com/enp/protocol/ip/option009.htm">源记录路由</a></li>
</ul>
<p>然后，置位 <code>tos</code> 的 <code>0x1</code>（<code>RTO_ONLINK</code>）位，且标记套接字为“未连接”：</p>
<pre><code class="hljs c++">tos = <span class="hljs-built_in">get_rttos</span>(&amp;ipc, inet);
<span class="hljs-keyword">if</span> (<span class="hljs-built_in">sock_flag</span>(sk, SOCK_LOCALROUTE) ||
    (msg-&gt;msg_flags &amp; MSG_DONTROUTE) ||
    (ipc.opt &amp;&amp; ipc.opt-&gt;opt.is_strictroute)) &#123;
        tos |= RTO_ONLINK;
        connected = <span class="hljs-number">0</span>;
&#125;</code></pre>

<h5 id="组播还是单播？"><a href="#组播还是单播？" class="headerlink" title="组播还是单播？"></a>组播还是单播？</h5><p>接下来，代码尝试处理组播。 这有点棘手，因为如前所述，用户可以发送辅助 <code>IP_PKTINFO</code> 消息来指定一个源地址或设备索引来发送数据包。</p>
<p>如果目标地址是组播地址：</p>
<ol>
<li>设置组播设备索引为数据包发送的设备索引，并且</li>
<li>设置组播源地址为数据包的源地址。</li>
</ol>
<p>除非用户发送 <code>IP_PKTINFO</code> 辅助消息覆盖设备索引。 我们来看一下：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">ipv4_is_multicast</span>(daddr)) &#123;
        <span class="hljs-keyword">if</span> (!ipc.oif)
                ipc.oif = inet-&gt;mc_index;
        <span class="hljs-keyword">if</span> (!saddr)
                saddr = inet-&gt;mc_addr;
        connected = <span class="hljs-number">0</span>;
&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!ipc.oif)
        ipc.oif = inet-&gt;uc_index;</code></pre>

<p>如果目标地址不是组播地址，则会设置设备索引，除非用户使用 <code>IP_PKTINFO</code> 覆盖了该索引。</p>
<h5 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h5><p>是时候探讨路由了！</p>
<p>UDP 层负责路由的代码从一个快速路径开始。如果套接字已连接，请尝试获取路由结构：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (connected)
        rt = (<span class="hljs-keyword">struct</span> rtable *)<span class="hljs-built_in">sk_dst_check</span>(sk, <span class="hljs-number">0</span>);</code></pre>

<p>如果套接字没有连接，或者虽然连接了，但路由助手 <code>sk_dst_check</code> 判定路由已淘汰，则代码进入慢速路径以生成路由结构。 首先调用 <code>flowi4_init_output</code> 来构造一个描述此 UDP 流的结构：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (rt == <span class="hljs-literal">NULL</span>) &#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net</span> *net = <span class="hljs-built_in">sock_net</span>(sk);

        fl4 = &amp;fl4_stack;
        <span class="hljs-built_in">flowi4_init_output</span>(fl4, ipc.oif, sk-&gt;sk_mark, tos,
                           RT_SCOPE_UNIVERSE, sk-&gt;sk_protocol,
                           <span class="hljs-built_in">inet_sk_flowi_flags</span>(sk)|FLOWI_FLAG_CAN_SLEEP,
                           faddr, saddr, dport, inet-&gt;inet_sport);</code></pre>

<p>一旦该流结构构造完成，套接字及其流结构就被传递到安全子系统，使得诸如 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Security-Enhanced_Linux">SELinux</a> 或 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Smack_(software">SMACK</a> 之类的系统可以在流结构上设置安全 id 值。 接下来，<code>ip_route_output_flow</code> 调用 IP 路由代码来生成此流的路由结构：</p>
<pre><code class="hljs c++"><span class="hljs-built_in">security_sk_classify_flow</span>(sk, <span class="hljs-built_in">flowi4_to_flowi</span>(fl4));
rt = <span class="hljs-built_in">ip_route_output_flow</span>(net, fl4, sk);</code></pre>

<p>如果无法生成路由结构，并且错误为 <code>ENETUNREACH</code>，则 <code>OUTNOROUTES</code> 统计计数器增加。</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">IS_ERR</span>(rt)) &#123;
  err = <span class="hljs-built_in">PTR_ERR</span>(rt);
  rt = <span class="hljs-literal">NULL</span>;
  <span class="hljs-keyword">if</span> (err == -ENETUNREACH)
    <span class="hljs-built_in">IP_INC_STATS</span>(net, IPSTATS_MIB_OUTNOROUTES);
  <span class="hljs-keyword">goto</span> out;
&#125;</code></pre>

<p>保存上述统计计数器的文件的位置、其他计数器及其含义，将在下面的 UDP 监控章节中讨论。</p>
<p>接下来，如果路由用于广播，但是在套接字上没有设置 <code>SOCK_BROADCAST</code> 套接字选项，则代码终止。 如果套接字“已连接”（如本函数所述），则缓存路由结构到套接字：</p>
<pre><code class="hljs c++">err = -EACCES;
<span class="hljs-keyword">if</span> ((rt-&gt;rt_flags &amp; RTCF_BROADCAST) &amp;&amp;
    !<span class="hljs-built_in">sock_flag</span>(sk, SOCK_BROADCAST))
        <span class="hljs-keyword">goto</span> out;
<span class="hljs-keyword">if</span> (connected)
        <span class="hljs-built_in">sk_dst_set</span>(sk, <span class="hljs-built_in">dst_clone</span>(&amp;rt-&gt;dst));</code></pre>

<h5 id="使用-MSG-CONFIRM-阻止-ARP-缓存失效"><a href="#使用-MSG-CONFIRM-阻止-ARP-缓存失效" class="headerlink" title="使用 MSG_CONFIRM 阻止 ARP 缓存失效"></a>使用 <code>MSG_CONFIRM</code> 阻止 ARP 缓存失效</h5><p>在调用 <code>send</code>、<code>sendto</code> 或 <code>sendmsg</code> 时，如果用户指定了 <code>MSG_CONFIRM</code> 标志，UDP 协议层将处理该标志：</p>
<pre><code class="hljs c++">  <span class="hljs-keyword">if</span> (msg-&gt;msg_flags&amp;MSG_CONFIRM)
          <span class="hljs-keyword">goto</span> do_confirm;
back_from_confirm:</code></pre>

<p>此标志指示系统确认 ARP 缓存条目仍然有效，并阻止其被垃圾回收。 <code>dst_confirm</code> 函数只是在目标缓存条目上设置一个标志，在查询邻居缓存并找到条目时再次检查该标志。我们稍后再看。 UDP 网络应用程序常使用此功能 ，以减少不必要的 ARP 流量。 <code>do_confirm</code> 标签位于此函数的末尾附近，但它很简单：</p>
<pre><code class="hljs c++">do_confirm:
        <span class="hljs-built_in">dst_confirm</span>(&amp;rt-&gt;dst);
        <span class="hljs-keyword">if</span> (!(msg-&gt;msg_flags&amp;MSG_PROBE) || len)
                <span class="hljs-keyword">goto</span> back_from_confirm;
        err = <span class="hljs-number">0</span>;
        <span class="hljs-keyword">goto</span> out;</code></pre>

<p>这段代码确认缓存条目，如果不是探测消息，则跳回到 <code>back_from_confirm</code>。</p>
<p>一旦 <code>do_confirm</code> 代码跳回到 <code>back_from_confirm</code>（或者没有跳转<code> do_confirm</code> ），代码会尝试处理 UDP cork 和 uncorked 的情况。</p>
<h5 id="uncorked-UDP-套接字的快速路径：准备传输数据"><a href="#uncorked-UDP-套接字的快速路径：准备传输数据" class="headerlink" title="uncorked UDP 套接字的快速路径：准备传输数据"></a>uncorked UDP 套接字的快速路径：准备传输数据</h5><p>如果未请求 UDP corking，调用 <code>ip_make_skb</code> ，数据可以打包到 <code>struct sk_buff</code>，并传递给 <code>udp_send_skb</code>，以向下移动栈并更接近 IP 协议层。 请注意，前面调用 <code>ip_route_output_flow</code> 生成的路由结构也会传入。 它将被关联到 skb，并稍后在 IP 协议层中使用。</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* Lockless fast path for the non-corking case. */</span>
<span class="hljs-keyword">if</span> (!corkreq) &#123;
        skb = <span class="hljs-built_in">ip_make_skb</span>(sk, fl4, getfrag, msg-&gt;msg_iov, ulen,
                          <span class="hljs-built_in">sizeof</span>(<span class="hljs-keyword">struct</span> udphdr), &amp;ipc, &amp;rt,
                          msg-&gt;msg_flags);
        err = <span class="hljs-built_in">PTR_ERR</span>(skb);
        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">IS_ERR_OR_NULL</span>(skb))
                err = <span class="hljs-built_in">udp_send_skb</span>(skb, fl4);
        <span class="hljs-keyword">goto</span> out;
&#125;</code></pre>

<p><code>ip_make_skb</code> 函数尝试构建一个 skb，其考虑了各种因素，例如：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Maximum_transmission_unit">MTU</a>。</li>
<li>UDP corking（如果启用）。</li>
<li>UDP Fragmentation Offloading（<a target="_blank" rel="noopener" href="https://wiki.linuxfoundation.org/networking/ufo">UFO</a>）。</li>
<li>Fragmentation，如果不支持 UFO ，并且传输数据大于 MTU。</li>
</ul>
<p>大多数网络设备驱动程序不支持 UFO，因为网络硬件本身不支持此功能。 让我们看一下这段代码，记住 corking 是禁用的。 接下来我们查看启用 corking 的路径。</p>
<h6 id="ip-make-skb"><a href="#ip-make-skb" class="headerlink" title="ip_make_skb"></a><code>ip_make_skb</code></h6><p><code>ip_make_skb</code> 函数可以在 <a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_output.c">.&#x2F;net&#x2F;ipv4&#x2F;ip_output.c</a> 中找到。 这个函数有点棘手。 <code>ip_make_skb</code> 依赖底层代码（译者释：<code>__ip_make_skb</code>）构建 skb，它需要传入一个 corking 结构和 skb 排队的队列。 在套接字没有 corked 的情况下，传入一个伪 corking 结构和空队列。</p>
<p>让我们来看看伪 corking 结构和队列是如何构造的：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff</span> *<span class="hljs-built_in">ip_make_skb</span>(<span class="hljs-keyword">struct</span> sock *sk, <span class="hljs-comment">/* more args */</span>)
&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">inet_cork</span> cork;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff_head</span> queue;
        <span class="hljs-type">int</span> err;

        <span class="hljs-keyword">if</span> (flags &amp; MSG_PROBE)
                <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;

        __skb_queue_head_init(&amp;queue);

        cork.flags = <span class="hljs-number">0</span>;
        cork.addr = <span class="hljs-number">0</span>;
        cork.opt = <span class="hljs-literal">NULL</span>;
        err = <span class="hljs-built_in">ip_setup_cork</span>(sk, &amp;cork, <span class="hljs-comment">/* more args */</span>);
        <span class="hljs-keyword">if</span> (err)
                <span class="hljs-keyword">return</span> <span class="hljs-built_in">ERR_PTR</span>(err);</code></pre>

<p>如上所述，corking 结构（<code>cork</code>）和队列（<code>queue</code>）都在栈上分配的；当 <code>ip_make_skb</code> 完成时，两者都不再需要。 调用 <code>ip_setup_cork</code> 来构建伪 corking 结构，它分配内存、并初始化结构。 接下来，调用 <code>__ip_append_data</code>，传入队列和 corking 结构：</p>
<pre><code class="hljs c++">err = __ip_append_data(sk, fl4, &amp;queue, &amp;cork,
                       &amp;current-&gt;task_frag, getfrag,
                       from, length, transhdrlen, flags);</code></pre>

<p>稍后我们将看到这个函数是如何工作的，因为它在套接字是否被 corked 的情况下都会使用。 现在，我们只需要知道 <code>__ip_append_data</code> 会创建一个 skb，向其追加数据，并添加该 skb 到传入的队列中。 如果追加数据失败，则调用 <code>__ip_flush_pending_frame</code> 静默丢弃数据，并向上返回错误码：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (err) &#123;
        __ip_flush_pending_frames(sk, &amp;queue, &amp;cork);
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">ERR_PTR</span>(err);
&#125;</code></pre>

<p>最后，如果没有错误发生，<code>__ip_make_skb</code> 出队队列中的 skb，添加 IP 选项，并返回一个 skb，该 skb 已准备好传递给底层发送：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">return</span> __ip_make_skb(sk, fl4, &amp;queue, &amp;cork);</code></pre>

<h6 id="传输数据！"><a href="#传输数据！" class="headerlink" title="传输数据！"></a>传输数据！</h6><p>如果没有发生错误，则 skb 会交给 <code>udp_send_skb</code>，它传递 skb 到网络栈的下一层，即 IP 协议栈：</p>
<pre><code class="hljs c++">err = <span class="hljs-built_in">PTR_ERR</span>(skb);
<span class="hljs-keyword">if</span> (!<span class="hljs-built_in">IS_ERR_OR_NULL</span>(skb))
        err = <span class="hljs-built_in">udp_send_skb</span>(skb, fl4);
<span class="hljs-keyword">goto</span> out;</code></pre>

<p>如果出现错误，将在稍后计数。 有关详细信息，请参阅 UDP corking 的“错误统计”部分。</p>
<h5 id="corked-UDP-套接字的慢速路径：没有预先存在的-corked-数据"><a href="#corked-UDP-套接字的慢速路径：没有预先存在的-corked-数据" class="headerlink" title="corked UDP 套接字的慢速路径：没有预先存在的 corked 数据"></a>corked UDP 套接字的慢速路径：没有预先存在的 corked 数据</h5><p>如果正在使用 UDP corking，但没有预先存在的 corked 数据，则慢速路径开始：</p>
<ol>
<li>锁定套接字。</li>
<li>检查应用程序缺陷：corked 套接字被 “re-corked”。</li>
<li>准备此 UDP 流的流结构，以进行 corking。</li>
<li>追加要发送的数据到现有数据。</li>
</ol>
<p>你可以在下一段代码中看到这一点，<code>udp_sendmsg</code> 继续向下：</p>
<pre><code class="hljs c++">  <span class="hljs-built_in">lock_sock</span>(sk);
  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(up-&gt;pending)) &#123;
          <span class="hljs-comment">/* The socket is already corked while preparing it. */</span>
          <span class="hljs-comment">/* ... which is an evident application bug. --ANK */</span>
          <span class="hljs-built_in">release_sock</span>(sk);

          <span class="hljs-built_in">LIMIT_NETDEBUG</span>(KERN_DEBUG <span class="hljs-built_in">pr_fmt</span>(<span class="hljs-string">&quot;cork app bug 2\n&quot;</span>));
          err = -EINVAL;
          <span class="hljs-keyword">goto</span> out;
  &#125;
  <span class="hljs-comment">/*</span>
<span class="hljs-comment">   *      Now cork the socket to pend data.</span>
<span class="hljs-comment">   */</span>
  fl4 = &amp;inet-&gt;cork.fl.u.ip4;
  fl4-&gt;daddr = daddr;
  fl4-&gt;saddr = saddr;
  fl4-&gt;fl4_dport = dport;
  fl4-&gt;fl4_sport = inet-&gt;inet_sport;
  up-&gt;pending = AF_INET;

do_append_data:
  up-&gt;len += ulen;
  err = <span class="hljs-built_in">ip_append_data</span>(sk, fl4, getfrag, msg-&gt;msg_iov, ulen,
                       <span class="hljs-built_in">sizeof</span>(<span class="hljs-keyword">struct</span> udphdr), &amp;ipc, &amp;rt,
                       corkreq ? msg-&gt;msg_flags|MSG_MORE : msg-&gt;msg_flags);</code></pre>

<h6 id="ip-append-data"><a href="#ip-append-data" class="headerlink" title="ip_append_data"></a><code>ip_append_data</code></h6><p><code>ip_append_data</code> 是一个小的包装函数，它在调用 <code>__ip__append_data</code> 之前做两件主要事情：</p>
<ol>
<li>检查用户是否传入了 <code>MSG_PROBE</code> 标志。 此标志表示用户不想真正发送数据。 应探测路径（例如，以确定 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Path_MTU_Discovery">PMTU</a>）。</li>
<li>检查套接字的发送队列是否为空。 如果是，意味着没有待处理的 corking 数据，因此调用 <code>ip_setup_cork</code> 来设置 corking。</li>
</ol>
<p>处理完上述条件后，就会调用 <code>__ip_append_data</code> 函数，该函数包含大量逻辑以处理数据为数据包。</p>
<h6 id="ip-append-data-1"><a href="#ip-append-data-1" class="headerlink" title="__ip_append_data"></a><code>__ip_append_data</code></h6><p>如果套接字被 corked，则从 <code>ip_append_data</code> 调用该函数；如果套接字未被 corked ，则从 <code>ip_make_skb</code> 调用该函数。 在这两种情况下，该函数要么分配一个新的缓冲区来存储传入的数据，要么追加数据到现有数据中。</p>
<p>这种工作方式以套接字的发送队列为中心。 等待发送的现有数据（例如，如果套接字被 corked）在队列中有一个条目，可以在其中追加其他数据。</p>
<p>这个函数很复杂；它执行多轮计算，以确定如何构建传递给底层网络层的 skb，并且详细探讨缓冲器分配过程对于理解如何传输网络数据并非绝对必要。</p>
<p>该函数的重点包括：</p>
<ol>
<li>处理 UDP fragmentation offloading（UFO）（如果硬件支持）。 绝大多数网络硬件不支持 UFO。 如果您的网卡驱动程序支持，它将设置功能标志 <code>NETIF_F_UFO</code>。</li>
<li>处理支持 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Vectored_I/O">分散&#x2F;聚集 IO 的网卡</a>。 许多卡都支持此功能，并使用 <code>NETIF_F_SG</code> 功能标志进行通告。 该功能的可用性表明，网络卡能够处理数据分散在一组缓冲区中的数据包；内核不需要花费时间合并多个缓冲区为单个缓冲区。期望的是结果避免额外的复制，大多数网卡都支持该功能。</li>
<li>调用 <code>sock_wmalloc</code> 跟踪发送队列的大小。 当分配一个新的 skb 时，skb 的大小会被计入拥有它的套接字，并且套接字的发送队列的分配字节会增加。 如果发送队列中没有足够的空间，则不分配 skb，并返回并跟踪错误。 我们将在下面的调优部分看到如何设置套接字发送队列大小。</li>
<li>增加错误统计信息。 此函数中的任何错误都将增加 “discard”。 我们将在下面的监控部分看到如何读取这个值。</li>
</ol>
<p>此函数执行成功后，将返回 <code>0</code>。此时传输的数据已组装成适合网络设备的 skb，等待在发送队列上。</p>
<p>在 uncorked 的情况下，持有 skb 的队列传递给上述的 <code>__ip_make_skb</code>，在那里它出队并准备经由 <code>udp_send_skb</code> 发送到更低层。</p>
<p>在 corked 的情况下，向上传递 <code>__ip_append_data</code> 的返回值。 数据停留在发送队列中，直到<code>udp_sendmsg</code> 确定是时候调用 <code>udp_push_pending_frames</code> 确认 skb 并调用 <code>udp_send_skb</code>。</p>
<h6 id="刷新-corked-套接字"><a href="#刷新-corked-套接字" class="headerlink" title="刷新 corked 套接字"></a>刷新 corked 套接字</h6><p>现在，<code>udp_sendmsg</code> 继续检查 <code>___ip_append_skb</code> 的返回值 （下面的  <code>err</code> ）：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (err)
        <span class="hljs-built_in">udp_flush_pending_frames</span>(sk);
<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!corkreq)
        err = <span class="hljs-built_in">udp_push_pending_frames</span>(sk);
<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(<span class="hljs-built_in">skb_queue_empty</span>(&amp;sk-&gt;sk_write_queue)))
        up-&gt;pending = <span class="hljs-number">0</span>;
<span class="hljs-built_in">release_sock</span>(sk);</code></pre>

<p>让我们来看看每个分支：</p>
<ol>
<li>如果出现错误（ <code>err</code> 非零），则调用 <code>udp_flush_pending_frames</code>，从而取消阻塞并从套接字的发送队列中删除所有数据。</li>
<li>如果发送此数据时未指定 <code>MSG_MORE</code>，则称为 <code>udp_push_pending_frames</code>，它尝试传递数据到较低的网络层。</li>
<li>如果发送队列为空，则标记套接字为不再阻塞。</li>
</ol>
<p>如果 append 操作成功完成，并且还有更多的数据要 cork，则代码继续清理并返回所追加的数据的长度：</p>
<pre><code class="hljs c++"><span class="hljs-built_in">ip_rt_put</span>(rt);
<span class="hljs-keyword">if</span> (free)
        <span class="hljs-built_in">kfree</span>(ipc.opt);
<span class="hljs-keyword">if</span> (!err)
        <span class="hljs-keyword">return</span> len;</code></pre>

<p>这就是内核处理 corked 的 UDP 套接字的方式。</p>
<h5 id="错误统计"><a href="#错误统计" class="headerlink" title="错误统计"></a>错误统计</h5><p>如果：</p>
<ol>
<li>non-corking 快速路径无法创建 skb 或 <code>udp_send_skb</code> 报告错误，或</li>
<li><code>ip_append_data</code> 无法追加数据到 corked 的 UDP 套接字，或</li>
<li>在尝试传输 corked skb 时， <code>udp_push_pending_frames</code> 返回从 <code>udp_send_skb</code> 收到的错误</li>
</ol>
<p>只有当收到的错误是 <code>ENOBUFS</code>（没有可用的内核内存）或套接字设置了 <code>SOCK_NOSPACE</code>（发送队列已满）时，<code>SNDBUFERRORS</code> 统计信息才会增加：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/*</span>
<span class="hljs-comment"> * ENOBUFS = no kernel mem, SOCK_NOSPACE = no sndbuf space.  Reporting</span>
<span class="hljs-comment"> * ENOBUFS might not be good (it&#x27;s not tunable per se), but otherwise</span>
<span class="hljs-comment"> * we don&#x27;t have a good statistic (IpOutDiscards but it can be too many</span>
<span class="hljs-comment"> * things).  We could add another new stat but at least for now that</span>
<span class="hljs-comment"> * seems like overkill.</span>
<span class="hljs-comment"> */</span>
<span class="hljs-keyword">if</span> (err == -ENOBUFS || <span class="hljs-built_in">test_bit</span>(SOCK_NOSPACE, &amp;sk-&gt;sk_socket-&gt;flags)) &#123;
        <span class="hljs-built_in">UDP_INC_STATS_USER</span>(<span class="hljs-built_in">sock_net</span>(sk),
                        UDP_MIB_SNDBUFERRORS, is_udplite);
&#125;
<span class="hljs-keyword">return</span> err;</code></pre>

<p>我们将在下面的监控部分看到如何读取这些计数。</p>
<h4 id="udp-send-skb"><a href="#udp-send-skb" class="headerlink" title="udp_send_skb"></a><code>udp_send_skb</code></h4><p><code>udp_sendmsg</code> 调用 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/udp.c#L765-L819"><code>udp_send_skb</code> 函数</a> 最终下推 skb 到网络栈的下一层，在本例中是 IP 协议层。 该函数做了几件重要的事情：</p>
<ol>
<li>添加 UDP 报头到 skb。</li>
<li>处理校验和：软件校验和、硬件校验和或无校验和（如果禁用）。</li>
<li>尝试调用 <code>ip_send_skb</code> 发送 skb 到 IP 协议层。</li>
<li>增加传输成功或失败的统计计数器。</li>
</ol>
<p>我们来看看。 首先，创建 UDP 报头：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title">udp_send_skb</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-keyword">struct</span> flowi4 *fl4)</span></span>
<span class="hljs-function"></span>&#123;
				<span class="hljs-comment">/* useful variables ... */</span>

        <span class="hljs-comment">/*</span>
<span class="hljs-comment">         * Create a UDP header</span>
<span class="hljs-comment">         */</span>
        uh = <span class="hljs-built_in">udp_hdr</span>(skb);
        uh-&gt;source = inet-&gt;inet_sport;
        uh-&gt;dest = fl4-&gt;fl4_dport;
        uh-&gt;len = <span class="hljs-built_in">htons</span>(len);
        uh-&gt;check = <span class="hljs-number">0</span>;</code></pre>

<p>接下来，处理校验和。 有几种情况：</p>
<ol>
<li>首先处理 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/UDP-Lite">UDP-Lite</a> 校验和。</li>
<li>接下来，如果套接字被设置为不生成校验和（通过<code>setsockopt</code> 设置 <code>SO_NO_CHECK</code>），将如此标记 skb。</li>
<li>接下来，如果硬件支持 UDP 校验和，调用 <code>udp4_hwcsum</code> 来设置。 请注意，如果数据包被分段，内核将在软件中生成校验和。 您可以在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/udp.c#L720-L763"><code>udp4_hwcsum</code></a> 的源代码中看到这一点。</li>
<li>最后，调用 <code>udp_csum</code> 生成软件校验和。</li>
</ol>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (is_udplite)                                  <span class="hljs-comment">/*     UDP-Lite      */</span>
        csum = <span class="hljs-built_in">udplite_csum</span>(skb);

<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (sk-&gt;sk_no_check == UDP_CSUM_NOXMIT) &#123;   <span class="hljs-comment">/* UDP csum disabled */</span>

        skb-&gt;ip_summed = CHECKSUM_NONE;
        <span class="hljs-keyword">goto</span> send;

&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (skb-&gt;ip_summed == CHECKSUM_PARTIAL) &#123; <span class="hljs-comment">/* UDP hardware csum */</span>

        <span class="hljs-built_in">udp4_hwcsum</span>(skb, fl4-&gt;saddr, fl4-&gt;daddr);
        <span class="hljs-keyword">goto</span> send;

&#125; <span class="hljs-keyword">else</span>
        csum = <span class="hljs-built_in">udp_csum</span>(skb);</code></pre>

<p>接下来，添加 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/User_Datagram_Protocol#IPv4_Pseudo_Header">psuedo 报头</a>：</p>
<pre><code class="hljs c++">uh-&gt;check = <span class="hljs-built_in">csum_tcpudp_magic</span>(fl4-&gt;saddr, fl4-&gt;daddr, len,
                              sk-&gt;sk_protocol, csum);
<span class="hljs-keyword">if</span> (uh-&gt;check == <span class="hljs-number">0</span>)
        uh-&gt;check = CSUM_MANGLED_0;</code></pre>

<p>如果校验和为 0，则根据 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc768">RFC 768</a> 设置其等效的补码值为校验和。最终，skb 被传递到 IP 协议栈，增加统计信息：</p>
<pre><code class="hljs c++">send:
  err = <span class="hljs-built_in">ip_send_skb</span>(<span class="hljs-built_in">sock_net</span>(sk), skb);
  <span class="hljs-keyword">if</span> (err) &#123;
          <span class="hljs-keyword">if</span> (err == -ENOBUFS &amp;&amp; !inet-&gt;recverr) &#123;
                  <span class="hljs-built_in">UDP_INC_STATS_USER</span>(<span class="hljs-built_in">sock_net</span>(sk),
                                     UDP_MIB_SNDBUFERRORS, is_udplite);
                  err = <span class="hljs-number">0</span>;
          &#125;
  &#125; <span class="hljs-keyword">else</span>
          <span class="hljs-built_in">UDP_INC_STATS_USER</span>(<span class="hljs-built_in">sock_net</span>(sk),
                             UDP_MIB_OUTDATAGRAMS, is_udplite);
  <span class="hljs-keyword">return</span> err;</code></pre>

<p>如果 <code>ip_send_skb</code> 执行成功，则增加 <code>OUTDATAGRAMS</code> 统计信息。 如果 IP 协议层报告错误，则增加 <code>SNDBUFERRORS</code>，但仅当错误为 <code>ENOBUFS</code>（内核内存不足）且未启用错误队列时，才增加。</p>
<p>在讨论 IP 协议层之前，让我们先看看如何在 Linux 内核中监控和调优 UDP 协议层。</p>
<h4 id="监控：UDP-协议层统计信息"><a href="#监控：UDP-协议层统计信息" class="headerlink" title="监控：UDP 协议层统计信息"></a>监控：UDP 协议层统计信息</h4><p>获取 UDP 协议统计信息的两个非常有用的文件是：</p>
<ul>
<li><code>/proc/net/snmp</code></li>
<li><code>/proc/net/udp</code></li>
</ul>
<h5 id="proc-net-snmp"><a href="#proc-net-snmp" class="headerlink" title="/proc/net/snmp"></a><code>/proc/net/snmp</code></h5><p>读取 <code>/proc/net/snmp</code> 监控详细的 UDP 协议统计信息。</p>
<pre><code class="hljs bash">$ <span class="hljs-built_in">cat</span> /proc/net/snmp | grep Udp\:
Udp: InDatagrams NoPorts InErrors OutDatagrams RcvbufErrors SndbufErrors
Udp: 16314 0 0 17161 0 0</code></pre>

<p>为了准确地理解这些统计信息在哪里增加，您需要仔细阅读内核源代码。 在一些情况下，一些错误会计入多个统计量中。</p>
<ul>
<li><code>InDatagrams</code>：当用户程序使用 <code>recvmsg</code> 读取数据报时增加。 当 UDP 数据包被封装并发回处理时，也会增加。</li>
<li><code>NoPorts</code>：当 UDP 数据包到达目的地为没有程序侦听的端口时增加。</li>
<li><code>InErrors</code>：在以下几种情况下增加：接收队列中没有内存，当看到错误的校验和时，<code>sk_add_backlog</code> 无法添加数据报。</li>
<li><code>OutDatagrams</code>：当 UDP 数据包无错误地传递到要发送的 IP 协议层时增加。</li>
<li><code>RcvbufErrors</code>：当 <code>sock_queue_rcv_skb</code> 报告没有可用内存时增加；如果 <code>sk-&gt;sk_rmem_alloc</code> 大于等于 <code>sk-&gt;sk_rcvbuf</code> 就会发生这种情况。</li>
<li><code>SndbufErrors</code>：如果 IP 协议层在尝试发送数据包时报告错误，并且没有设置错误队列，则会增加。 如果没有可用的发送队列空间或内核内存，也会增加。</li>
<li><code>InCsumErrors</code>：检测到 UDP 校验和失败时增加。 请注意，在我能找到的所有情况下，<code>InCsumErrors</code> 与 <code>InErrors</code> 会同时增加。 因此，<code>InErrors</code>-<code>InCsumErros</code> 应当得出接收端的内存相关错误的计数。</li>
</ul>
<p>请注意，UDP 协议层发现的一些错误会报告到其他协议层的统计信息文件。 举个例子：路由错误。 <code>udp_sendmsg</code> 发现的路由错误将增加 IP 协议层的 <code>OutNoRoutes</code> 统计信息。</p>
<h5 id="proc-net-udp"><a href="#proc-net-udp" class="headerlink" title="/proc/net/udp"></a><code>/proc/net/udp</code></h5><p>读取 <code>/proc/net/udp</code> 监控 UDP 套接字统计信息</p>
<pre><code class="hljs bash">$ <span class="hljs-built_in">cat</span> /proc/net/udp
  sl  local_address rem_address   st tx_queue rx_queue <span class="hljs-built_in">tr</span> tm-&gt;when retrnsmt   uid  <span class="hljs-built_in">timeout</span> inode ref pointer drops
  515: 00000000:B346 00000000:0000 07 00000000:00000000 00:00000000 00000000   104        0 7518 2 0000000000000000 0
  558: 00000000:0371 00000000:0000 07 00000000:00000000 00:00000000 00000000     0        0 7408 2 0000000000000000 0
  588: 0100007F:038F 00000000:0000 07 00000000:00000000 00:00000000 00000000     0        0 7511 2 0000000000000000 0
  769: 00000000:0044 00000000:0000 07 00000000:00000000 00:00000000 00000000     0        0 7673 2 0000000000000000 0
  812: 00000000:006F 00000000:0000 07 00000000:00000000 00:00000000 00000000     0        0 7407 2 0000000000000000 0</code></pre>

<p>第一行描述后续行中的每个字段：</p>
<ul>
<li><code>sl</code>：套接字的内核哈希槽</li>
<li><code>local_address</code>：套接字的十六进制本地地址和端口号，以 <code>:</code>分隔。</li>
<li><code>rem_address</code>：套接字的十六进制远程地址和端口号，以 <code>:</code> 分隔。</li>
<li><code>st</code>：套接字的状态。 奇怪的是，UDP 协议层似乎使用了一些 TCP 套接字状态。 在上面的例子中，<code>7</code> 是 <code>TCP_CLOSE</code>。</li>
<li><code>tx_queue</code>：内核中为传出 UDP 数据报分配的内存量。</li>
<li><code>rx_queue</code>：内核中为传入 UDP 数据报分配的内存量。</li>
<li><code>tr</code>，<code>tm-&gt;when</code>，<code>retrnsmt</code>：UDP 协议层未使用这些字段。</li>
<li><code>uid</code>：创建此套接字的用户的有效用户 ID。</li>
<li><code>timeout</code>：UDP 协议层未使用。</li>
<li><code>inode</code>：与此套接字对应的 inode 编号。 您可以使用它来帮助您确定哪个用户进程打开了此套接字。 检查 <code>/proc/[pid]/fd</code>，它将包含到 <code>socket:[inode]</code> 的符号链接。</li>
<li><code>ref</code>：套接字的当前引用计数。</li>
<li><code>pointer</code>：内核中 <code>struct sock</code> 的内存地址。</li>
<li><code>drops</code>：与此套接字关联的数据报丢弃数。 请注意，这不包括任何与发送数据报有关的丢弃（在 corked 的 UDP 套接字上，或其他）；在本博客考察的内核版本中，只在接收路径中增加。</li>
</ul>
<p>可以在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/master/net/ipv4/udp.c#L2396-L2431"><code>net/ipv4/udp.c</code></a> 中找到输出此内容的代码。</p>
<h4 id="调优：套接字发送队列内存"><a href="#调优：套接字发送队列内存" class="headerlink" title="调优：套接字发送队列内存"></a>调优：套接字发送队列内存</h4><p>发送队列（也称为写入队列）的最大大小可以设置 <code>net.core.wmem_max</code> sysctl 来调整</p>
<p>设置 <code>sysctl</code> 增加最大发送缓冲区大小。</p>
<pre><code class="hljs bash">$ sudo sysctl -w net.core.wmem_max=8388608</code></pre>

<p><code>sk-&gt;sk_write_queue</code> 从 <code>net.core.wmem_default</code> 值开始，也可以设置 sysctl 来调整，如下所示：</p>
<p>设置 <code>sysctl</code> 来调整默认的初始发送缓冲区大小 。</p>
<pre><code class="hljs bash">$ sudo sysctl -w net.core.wmem_default=8388608</code></pre>

<p>您还可以从应用程序调用 <a target="_blank" rel="noopener" href="http://www.manpagez.com/man/2/setsockopt/"><code>setsockopt</code></a> 并传递 <code>SO_SNDBUF</code> 来设置 <code>sk-&gt;sk_write_queue</code> 大小 。 您可以使用 <code>setsockopt</code> 设置的最大值是 <code>net.core.wmem_max</code>。</p>
<p>但是，当运行应用程序的用户具有 <code>CAP_NET_ADMIN</code> 权限时，可以调用 <code>setsockopt</code> 并传递 <code>SO_SNDBUFFORCE</code> 来覆盖  <code>net.core.wmem_max</code> 限制。</p>
<p>每次调用 <code>ip_append_data</code> 分配 skb 时，<code>sk-&gt;sk_wmem_alloc</code> 都会增加。 正如我们将看到的，UDP 数据报传输很快，通常不会在发送队列中花费太多时间。</p>
<h3 id="IP-协议层"><a href="#IP-协议层" class="headerlink" title="IP 协议层"></a>IP 协议层</h3><p>UDP 协议层简单地调用 <code>ip_send_skb</code> 传递 skbs 给 IP 协议，因此让我们从那开始，并掌握 IP 协议层！</p>
<h4 id="ip-send-skb"><a href="#ip-send-skb" class="headerlink" title="ip_send_skb"></a><code>ip_send_skb</code></h4><p><code>ip_send_skb</code> 函数位于 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/ip_output.c#L1367-L1380">.&#x2F;net&#x2F;ipv4&#x2F;ip_output.c</a> 中，非常短。 它只是向下调用 <code>ip_local_out</code>，如果 <code>ip_local_out</code> 返回某种错误，它就会增加错误统计信息。 我们来看一下：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">ip_send_skb</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> net *net, <span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-type">int</span> err;

        err = <span class="hljs-built_in">ip_local_out</span>(skb);
        <span class="hljs-keyword">if</span> (err) &#123;
                <span class="hljs-keyword">if</span> (err &gt; <span class="hljs-number">0</span>)
                        err = <span class="hljs-built_in">net_xmit_errno</span>(err);
                <span class="hljs-keyword">if</span> (err)
                        <span class="hljs-built_in">IP_INC_STATS</span>(net, IPSTATS_MIB_OUTDISCARDS);
        &#125;

        <span class="hljs-keyword">return</span> err;
&#125;</code></pre>

<p>如上所述，调用 <code>ip_local_out</code>，然后处理返回值。 调用 <code>net_xmit_errno</code>  “翻译” 来自底层的错误为 IP 和 UDP 协议层可以理解的错误。 如果发生错误，将增加 IP 协议统计信息 “OutDiscards” 。 稍后我们将看到获得此统计信息要读取哪些文件。 现在，让我们继续探索，看看 <code>ip_local_out</code> 会把我们带到哪里。</p>
<h4 id="ip-local-out-和-ip-local-out"><a href="#ip-local-out-和-ip-local-out" class="headerlink" title="ip_local_out 和 __ip_local_out"></a><code>ip_local_out</code> 和 <code>__ip_local_out</code></h4><p>幸运的是，<code>ip_local_out</code> 和 <code>__ip_local_out</code> 都很简单。<code>ip_local_out</code> 只是向下调用 <code>__ip_local_out</code>，并根据返回值调用路由层发送数据包：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">ip_local_out</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-type">int</span> err;

        err = __ip_local_out(skb);
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(err == <span class="hljs-number">1</span>))
                err = <span class="hljs-built_in">dst_output</span>(skb);

        <span class="hljs-keyword">return</span> err;
&#125;</code></pre>

<p>可以从 <code>__ip_local_out</code> 的源代码中看到，该函数首先做了两件重要的事情：</p>
<ol>
<li>设置 IP 数据包的长度</li>
<li>调用 <code>ip_send_check</code> 计算要写入 IP 数据包报头的校验和。 <code>ip_send_check</code> 函数调用 <code>ip_fast_csum</code> 来计算校验和。 在 x86 和 x86_64 体系结构上，此功能以汇编实现。 你可以在这里阅读 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/include/asm/checksum_64.h#L40-L73">64 位的实现</a>，在这里阅读 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/include/asm/checksum_32.h#L63-L98">32 位的实现</a>。</li>
</ol>
<p>接下来，IP 协议层调用 <code>nf_hook</code> 向下调用 netfilter。传回  <code>nf_hook</code> 函数的返回值给 <code>ip_local_out</code>。 如果 <code>nf_hook</code> 返回 <code>1</code>，表明允许数据包通过，调用者应该自己传递它。 正如我们在上面看到的，实际正是如此：<code>ip_local_out</code> 检查返回值 <code>1</code>，并调用 <code>dst_output</code> 传递数据包。 让我们来看看 <code>__ip_local_out</code> 的代码：</p>
<pre><code class="hljs c++"><span class="hljs-type">int</span> __ip_local_out(<span class="hljs-keyword">struct</span> sk_buff *skb)
&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">iphdr</span> *iph = <span class="hljs-built_in">ip_hdr</span>(skb);

        iph-&gt;tot_len = <span class="hljs-built_in">htons</span>(skb-&gt;len);
        <span class="hljs-built_in">ip_send_check</span>(iph);
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">nf_hook</span>(NFPROTO_IPV4, NF_INET_LOCAL_OUT, skb, <span class="hljs-literal">NULL</span>,
                       <span class="hljs-built_in">skb_dst</span>(skb)-&gt;dev, dst_output);
&#125;</code></pre>

<h4 id="netfilter-和-nf-hook"><a href="#netfilter-和-nf-hook" class="headerlink" title="netfilter 和 nf_hook"></a>netfilter 和 <code>nf_hook</code></h4><p>简洁起见，我决定跳过对 netfilter、iptables 和 conntrack 的深入研究。 你可以从 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/linux/netfilter.h#L142-L147">这里</a> 和 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/netfilter/core.c#L168-L209">这里</a> 开始深入了解 netfilter 的源代码。</p>
<p>简版：<code>nf_hook</code> 是一个包装器，它调用 <code>nf_hook_thresh</code>，首先检查指定的协议族和钩子类型（在本例中分别为 <code>NFPROTO_IPV4</code> 和 <code>NF_INET_LOCAL_OUT</code>）是否安装了过滤器，并试图返回执行流程到 IP 协议层，以避免深入 netfilter 和在其下面的钩子，如 iptables 和 conntrack。</p>
<p>请记住：如果你有很多或非常复杂的 netfilter 或 iptables 规则，这些规则将在启动原始 <code>sendmsg</code> 调用的用户进程的 CPU 上下文中执行。 如果您设置了 CPU pinning 以限制此进程的执行到特定的 CPU（或一组 CPU），请注意 CPU 将花费系统时间处理出站 iptables 规则。 根据系统的工作负载，如果您在这里测量性能回归，您可能需要小心地固定进程到 CPU 或降低规则集的复杂性。</p>
<p>为了便于讨论，我们假设 <code>nf_hook</code> 返回 <code>1</code> 表示调用方（在本例中是 IP 协议层）应该自己传递数据包。</p>
<h4 id="目标缓存"><a href="#目标缓存" class="headerlink" title="目标缓存"></a>目标缓存</h4><p>在 Linux 内核中，<code>dst</code> 代码实现了协议无关的目标缓存。 为了理解如何设置 <code>dst</code> 条目以继续发送 UDP 数据报，我们需要简要地探讨一下 <code>dst</code> 条目和路由是如何生成的。 目标缓存、路由和邻居子系统都可以单独进行极其详细的探讨。 出于我们的目的，我们可以快速查看一下这一切是如何结合在一起的。</p>
<p>我们上面看到的代码调用了 <code>dst_output(skb)</code>。 这个函数只是查找 skb 附加的 <code>dst</code> 条目 <code>skb</code> 并调用 output 函数。 我们来看一下：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* Output packet to network from transport.  */</span>
<span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title">dst_output</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">skb_dst</span>(skb)-&gt;<span class="hljs-built_in">output</span>(skb);
&#125;</code></pre>

<p>看起来很简单，但 output  函数起初是如何被关联到 <code>dst</code> 条目的呢？</p>
<p>重要的是要了解，有许多不同的方式添加目标缓存条目。 到目前为止，我们在代码路径中看到的一种方式是从 <code>udp_sendmsg</code> 调用 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/route.c#L2252-L2267"><code>ip_route_output_flow</code></a>。 <code>ip_route_output_flow</code> 函数调用 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/route.c#L1990-L2173"><code>__ip_route_output_key</code></a>，后者调用  <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/route.c#L1868-L1988"><code>__mkroute_output</code></a>。 <code>__mkroute_output</code> 函数创建路由和目标缓存条目。 当它执行时，它会确定适合于此目标的输出函数。 大多数时候，这个函数是 <code>ip_output</code>。</p>
<h4 id="ip-output"><a href="#ip-output" class="headerlink" title="ip_output"></a><code>ip_output</code></h4><p>因此，<code>dst_output</code> 执行 <code>output</code> 函数，在 UDP IPv4 情况下为 <code>ip_output</code>。 <code>ip_output</code> 函数很简单：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">ip_output</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_device</span> *dev = <span class="hljs-built_in">skb_dst</span>(skb)-&gt;dev;

        <span class="hljs-built_in">IP_UPD_PO_STATS</span>(<span class="hljs-built_in">dev_net</span>(dev), IPSTATS_MIB_OUT, skb-&gt;len);

        skb-&gt;dev = dev;
        skb-&gt;protocol = <span class="hljs-built_in">htons</span>(ETH_P_IP);

        <span class="hljs-keyword">return</span> <span class="hljs-built_in">NF_HOOK_COND</span>(NFPROTO_IPV4, NF_INET_POST_ROUTING, skb, <span class="hljs-literal">NULL</span>, dev,
                            ip_finish_output,
                            !(<span class="hljs-built_in">IPCB</span>(skb)-&gt;flags &amp; IPSKB_REROUTED));
&#125;</code></pre>

<p>首先，更新统计计数器 <code>IPSTATS_MIB_OUT</code>。 <code>IP_UPD_PO_STATS</code> 宏增加字节数和数据包数。 我们将在后面的部分中看到如何获得 IP 协议层统计信息以及它们各自的含义。 接下来，设置传输此 skb 的设备、协议。</p>
<p>最后，调用 <code>NF_HOOK_COND</code> 传递控制权给 netfilter。 查看 <code>NF_HOOK_COND</code> 的函数原型有助于更清楚地解释它的工作原理。 来源为 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/linux/netfilter.h#L177-L188">.&#x2F;include&#x2F;linux&#x2F;netfilter.h</a>：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span></span>
<span class="hljs-function"><span class="hljs-title">NF_HOOK_COND</span><span class="hljs-params">(<span class="hljs-type">uint8_t</span> pf, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> hook, <span class="hljs-keyword">struct</span> sk_buff *skb,</span></span>
<span class="hljs-params"><span class="hljs-function">             <span class="hljs-keyword">struct</span> net_device *in, <span class="hljs-keyword">struct</span> net_device *out,</span></span>
<span class="hljs-params"><span class="hljs-function">             <span class="hljs-type">int</span> (*okfn)(<span class="hljs-keyword">struct</span> sk_buff *), <span class="hljs-type">bool</span> cond)</span></span></code></pre>

<p><code>NF_HOOK_COND</code> 检查传入的条件。 在此情况下，条件是 <code>!(IPCB(skb)-&gt;flags &amp; IPSKB_REROUTED</code>。 如果条件为真，那么传递 <code>skb</code> 给 netfilter。 如果 netfilter 允许数据包通过，则调用 <code>okfn</code>。 此情况下，<code>okfn</code> 是 <code>ip_finish_output</code>。</p>
<h4 id="ip-finish-output"><a href="#ip-finish-output" class="headerlink" title="ip_finish_output"></a><code>ip_finish_output</code></h4><p><code>ip_finish_output</code>函数也很简洁明了。 我们来看一下：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title">ip_finish_output</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
<span class="hljs-meta">#<span class="hljs-keyword">if</span> defined(CONFIG_NETFILTER) &amp;&amp; defined(CONFIG_XFRM)</span>
        <span class="hljs-comment">/* Policy lookup after SNAT yielded a new policy */</span>
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">skb_dst</span>(skb)-&gt;xfrm != <span class="hljs-literal">NULL</span>) &#123;
                <span class="hljs-built_in">IPCB</span>(skb)-&gt;flags |= IPSKB_REROUTED;
                <span class="hljs-keyword">return</span> <span class="hljs-built_in">dst_output</span>(skb);
        &#125;
<span class="hljs-meta">#<span class="hljs-keyword">endif</span></span>
        <span class="hljs-keyword">if</span> (skb-&gt;len &gt; <span class="hljs-built_in">ip_skb_dst_mtu</span>(skb) &amp;&amp; !<span class="hljs-built_in">skb_is_gso</span>(skb))
                <span class="hljs-keyword">return</span> <span class="hljs-built_in">ip_fragment</span>(skb, ip_finish_output2);
        <span class="hljs-keyword">else</span>
                <span class="hljs-keyword">return</span> <span class="hljs-built_in">ip_finish_output2</span>(skb);
&#125;</code></pre>

<p>如果在此内核中启用了 netfilter 和数据包转换，会更新 <code>skb</code> 的标志，并通过 <code>dst_output</code> 将其发送回。 两种比较常见的情况是：</p>
<ol>
<li>如果数据包的长度大于 MTU，并且数据包的分段不会卸载到设备，则调用 <code>ip_fragment</code> 以在传输之前对数据包进行分段。</li>
<li>否则，直接传递数据包到 <code>ip_finish_output2</code>。</li>
</ol>
<p>在继续内核学习之前，让我们稍微绕个圈子来讨论一下路径 MTU 发现。</p>
<h5 id="路径-MTU-发现"><a href="#路径-MTU-发现" class="headerlink" title="路径 MTU 发现"></a>路径 MTU 发现</h5><p>Linux 提供了一个我前面避免提到的特性：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Path_MTU_Discovery">路径 MTU 发现</a>。 此功能允许内核自动确定特定路由的最大 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Maximum_transmission_unit">MTU</a>。 确定此值并发送小于或等于路由 MTU 的数据包意味着可以避免 IP 分段。 这是首选设置，因为数据包分段会消耗系统资源，而且似乎很容易避免：简单地发送足够小的数据包，就不需要分段。</p>
<p>调用  <code>setsockopt</code>，您可以在应用程序中使用 <code>SOL_IP</code> 级别和 <code>IP_MTU_DISCOVER</code> optname 调整每个套接字的路径 MTU 发现设置。optval 可以是 <a target="_blank" rel="noopener" href="http://man7.org/linux/man-pages/man7/ip.7.html">IP 协议手册页</a>中描述的几个值之一。 您可能希望设置的值为：<code>IP_PMTUDISC_DO</code> 表示“始终执行路径 MTU 发现”。 更高级的网络应用程序或诊断工具可以选择自己实现 <a target="_blank" rel="noopener" href="https://www.ietf.org/rfc/rfc4821.txt">RFC 4821</a> ，以在应用程序启动时确定特定路由的 PMTU。 在这种情况下，您可以使用 <code>IP_PMTUDISC_PROBE</code> 选项，该选项告诉内核设置“Don’t Fragment”位，允许您发送大于 PMTU 的数据。</p>
<p>调用 <code>getsockopt</code>，您的应用程序可以使用 <code>SOL_IP</code> 和 <code>IP_MTU</code> optname 来检索 PMTU。 您可以使用它来帮助指导应用程序尝试在传输之前构造 UDP 数据报的大小。</p>
<p>如果已启用 PTMU 发现，则任何发送大于 PMTU 的 UDP 数据的尝试都将导致应用程序收到错误码 <code>EMSGSIZE</code>。 然后，应用程序可以使用更少的数据重试。</p>
<p>强烈建议启用 PTMU 发现，因此我将避免详细描述 IP 分段代码路径。 当查看 IP 协议层统计信息时，我将解释所有统计信息，包括与分段相关的统计信息。 其中许多在 <code>ip_fragment</code>。 无论是否分段，都调用了 <code>ip_finish_output2</code>，所以让我们继续。</p>
<h4 id="ip-finish-output2"><a href="#ip-finish-output2" class="headerlink" title="ip_finish_output2"></a><code>ip_finish_output2</code></h4><p><code>ip_finish_output2</code> 在 IP 分段之后被调用，并且也直接从 <code>ip_finish_output</code> 调用。 在向下传递数据包到邻居缓存之前，此函数增加各种统计计数器。 让我们看看它是如何工作的：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title">ip_finish_output2</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;

				<span class="hljs-comment">/* variable declarations */</span>

        <span class="hljs-keyword">if</span> (rt-&gt;rt_type == RTN_MULTICAST) &#123;
                <span class="hljs-built_in">IP_UPD_PO_STATS</span>(<span class="hljs-built_in">dev_net</span>(dev), IPSTATS_MIB_OUTMCAST, skb-&gt;len);
        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (rt-&gt;rt_type == RTN_BROADCAST)
                <span class="hljs-built_in">IP_UPD_PO_STATS</span>(<span class="hljs-built_in">dev_net</span>(dev), IPSTATS_MIB_OUTBCAST, skb-&gt;len);

        <span class="hljs-comment">/* Be paranoid, rather than too clever. */</span>
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(<span class="hljs-built_in">skb_headroom</span>(skb) &lt; hh_len &amp;&amp; dev-&gt;header_ops)) &#123;
                <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff</span> *skb2;

                skb2 = <span class="hljs-built_in">skb_realloc_headroom</span>(skb, <span class="hljs-built_in">LL_RESERVED_SPACE</span>(dev));
                <span class="hljs-keyword">if</span> (skb2 == <span class="hljs-literal">NULL</span>) &#123;
                        <span class="hljs-built_in">kfree_skb</span>(skb);
                        <span class="hljs-keyword">return</span> -ENOMEM;
                &#125;
                <span class="hljs-keyword">if</span> (skb-&gt;sk)
                        <span class="hljs-built_in">skb_set_owner_w</span>(skb2, skb-&gt;sk);
                <span class="hljs-built_in">consume_skb</span>(skb);
                skb = skb2;
        &#125;</code></pre>

<p>如果与此数据包相关联的路由结构是组播类型，使用<code>IP_UPD_PO_STATS</code> 宏来增加 <code> OutMcastPkts</code> 和 <code>OutMcastOctets </code> 计数器。 否则，如果路由类型为广播，则增加 <code>OutBcastPkts</code> 和 <code>OutBcastOctets</code> 计数器。</p>
<p>接下来，执行检查以确保 skb 结构具有足够的空间添加任何需要的链路层报头。 如果没有，则调用 <code>skb_realloc_headroom</code> 来分配额外的空间，并且新 skb 的成本将计入相关套接字。</p>
<pre><code class="hljs coffeescript">rcu_read_lock_bh();
<span class="hljs-function"><span class="hljs-title">nexthop</span> = <span class="hljs-params">(__force u32)</span> <span class="hljs-title">rt_nexthop</span><span class="hljs-params">(rt, ip_hdr(skb)-&gt;daddr)</span>;</span>
<span class="hljs-function"><span class="hljs-title">neigh</span> = <span class="hljs-title">__ipv4_neigh_lookup_noref</span><span class="hljs-params">(dev, nexthop)</span>;</span>
<span class="hljs-function"><span class="hljs-title">if</span> <span class="hljs-params">(unlikely(!neigh))</span></span>
<span class="hljs-function">        <span class="hljs-title">neigh</span> = <span class="hljs-title">__neigh_create</span><span class="hljs-params">(&amp;arp_tbl, &amp;nexthop, dev, <span class="hljs-literal">false</span>)</span>;</span></code></pre>

<p>继续，我们可以看到，下一跳是查询路由层，然后查找邻居缓存得到的。 如果找不到邻居，则调用 <code>__neigh_create</code> 创建一个。 例如，数据第一次发送到另一台主机时可能出现此情况。 请注意，此函数是调用 <code>arp_tbl</code>（在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/arp.c#L160-L187">.&#x2F;net&#x2F;ipv4&#x2F;arp.c</a> 中定义），在 ARP 表中创建邻居条目。 其他系统（如 IPv6 或 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/DECnet">DECnet</a>）维护自己的 ARP 表，并传递不同的结构给 <code>__neigh_create</code>。 本文并不旨在全面介绍邻居缓存，但如果必须创建邻居缓存，那么创建可能会导致缓存增长。 这篇文章将在下面的章节中介绍更多关于邻居缓存的细节。 无论如何，邻居缓存导出自己的统计信息，以便可以测量缓存增长。 有关详细信息，请参阅下面的监控部分。</p>
<pre><code class="hljs c++">        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">IS_ERR</span>(neigh)) &#123;
                <span class="hljs-type">int</span> res = <span class="hljs-built_in">dst_neigh_output</span>(dst, neigh, skb);

                <span class="hljs-built_in">rcu_read_unlock_bh</span>();
                <span class="hljs-keyword">return</span> res;
        &#125;
        <span class="hljs-built_in">rcu_read_unlock_bh</span>();

        <span class="hljs-built_in">net_dbg_ratelimited</span>(<span class="hljs-string">&quot;%s: No header cache and no neighbour!\n&quot;</span>,
                            __func__);
        <span class="hljs-built_in">kfree_skb</span>(skb);
        <span class="hljs-keyword">return</span> -EINVAL;
&#125;</code></pre>

<p>最后，如果没有返回错误，则调用 <code>dst_neigh_output</code> 沿着输出的旅程传递 skb。 否则，释放 skb 并返回 EINVAL。 此处的错误将产生连锁反应，并增加 <code>ip_send_skb</code> 中的 <code>OutDiscards</code>。 让我们继续探索 <code>dst_neigh_output</code>，并继续接近 Linux 内核的网络设备子系统。</p>
<h4 id="dst-neigh-output"><a href="#dst-neigh-output" class="headerlink" title="dst_neigh_output"></a><code>dst_neigh_output</code></h4><p><code>dst_neigh_output</code> 函数为我们做了两件重要的事情。 首先，回想一下在这篇博客文章的前面，我们看到如果用户通过辅助消息指定 <code>MSG_CONFIRM</code> 给 <code>sendmsg</code> 函数，则会翻转一个标志，指示远程主机的目标缓存条目仍然有效，不应被垃圾回收。 该检查在这里发生，设置邻居的 <code>confirmed</code> 字段为当前的 jiffies 计数。</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title">dst_neigh_output</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> dst_entry *dst, <span class="hljs-keyword">struct</span> neighbour *n,</span></span>
<span class="hljs-params"><span class="hljs-function">                                   <span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">hh_cache</span> *hh;

        <span class="hljs-keyword">if</span> (dst-&gt;pending_confirm) &#123;
                <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> now = jiffies;

                dst-&gt;pending_confirm = <span class="hljs-number">0</span>;
                <span class="hljs-comment">/* avoid dirtying neighbour */</span>
                <span class="hljs-keyword">if</span> (n-&gt;confirmed != now)
                        n-&gt;confirmed = now;
        &#125;</code></pre>

<p>其次，检查邻居的状态，并调用适当的输出函数。 让我们来看看以下条件句，试着理解是怎么回事：</p>
<pre><code class="hljs c++">        hh = &amp;n-&gt;hh;
        <span class="hljs-keyword">if</span> ((n-&gt;nud_state &amp; NUD_CONNECTED) &amp;&amp; hh-&gt;hh_len)
                <span class="hljs-keyword">return</span> <span class="hljs-built_in">neigh_hh_output</span>(hh, skb);
        <span class="hljs-keyword">else</span>
                <span class="hljs-keyword">return</span> n-&gt;<span class="hljs-built_in">output</span>(n, skb);
&#125;</code></pre>

<p>如果邻居被认为是 <code>NUD_CONNECTED</code>，则意味着它是以下情况的一种或多种：</p>
<ul>
<li><code>NUD_PERMANENT</code>：静态路由。</li>
<li><code>NUD_NOARP</code>：不需要 ARP 请求（例如，目的地是组播或广播地址，或环回设备）。</li>
<li><code>NUD_REACHABLE</code>：邻居是“可达的”。只要 ARP 请求 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/arp.c#L905-L923">成功处理</a>，目的地就会被标记为可达。</li>
</ul>
<p><em>且</em> “硬件头”（<code>hh</code>）已缓存（因为之前发送过数据并已生成它），则调用 <code>neigh_hh_output</code>。否则，调用 <code>output</code> 函数。两条代码路径都以 <code>dev_queue_xmit</code> 结束，它传递 skb 到 Linux  网络设备子系统，在到达设备驱动程序层之前会进行更多处理。让我们跟随 <code>neigh_hh_output</code> 和 <code>n-&gt;output</code> 代码路径，直至 <code>dev_queue_xmit</code>。</p>
<h4 id="neigh-hh-output"><a href="#neigh-hh-output" class="headerlink" title="neigh_hh_output"></a><code>neigh_hh_output</code></h4><p>如果目标是 <code>NUD_CONNECTED</code>，并且硬件头已缓存，则调用 <code>neigh_hh_output</code> ，它在移交skb 给  <code>dev_queue_xmit</code> 之前执行一小段处理逻辑。 让我们从 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/net/neighbour.h#L336-L356">.&#x2F;include&#x2F;net&#x2F;neighbor.h</a> 来看看：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title">neigh_hh_output</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> hh_cache *hh, <span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> seq;
        <span class="hljs-type">int</span> hh_len;

        <span class="hljs-keyword">do</span> &#123;
                seq = <span class="hljs-built_in">read_seqbegin</span>(&amp;hh-&gt;hh_lock);
                hh_len = hh-&gt;hh_len;
                <span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(hh_len &lt;= HH_DATA_MOD)) &#123;
                        <span class="hljs-comment">/* this is inlined by gcc */</span>
                        <span class="hljs-built_in">memcpy</span>(skb-&gt;data - HH_DATA_MOD, hh-&gt;hh_data, HH_DATA_MOD);
                 &#125; <span class="hljs-keyword">else</span> &#123;
                         <span class="hljs-type">int</span> hh_alen = <span class="hljs-built_in">HH_DATA_ALIGN</span>(hh_len);

                         <span class="hljs-built_in">memcpy</span>(skb-&gt;data - hh_alen, hh-&gt;hh_data, hh_alen);
                 &#125;
         &#125; <span class="hljs-keyword">while</span> (<span class="hljs-built_in">read_seqretry</span>(&amp;hh-&gt;hh_lock, seq));

         <span class="hljs-built_in">skb_push</span>(skb, hh_len);
         <span class="hljs-keyword">return</span> <span class="hljs-built_in">dev_queue_xmit</span>(skb);
&#125;</code></pre>

<p>这个函数有点难以理解，部分原因是同步读&#x2F;写已缓存硬件头的锁定原语。 这段代码使用了一种叫做 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Seqlock">seqlock</a> 的东西。 你可以把上面的 <code>do &#123; &#125; while()</code> 循环想象成一种简单的重试机制，它将尝试执行循环中的操作，直到成功执行为止。</p>
<p>循环本身试图确定在复制之前是否需要对齐硬件头部的长度。 这是必需的，因为某些硬件报头（如 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/linux/ieee80211.h#L210-L218">IEEE 802.11</a> 报头）大于 <code>HH_DATA_MOD</code>（16 字节）。</p>
<p>一旦数据被复制到 skb，并且 <code>skb_push</code> 更新了 skb 的内部指针跟踪数据，skb 就会传递给 <code>dev_queue_xmit</code> 进入 Linux 网络设备子系统。</p>
<h4 id="n-gt-output"><a href="#n-gt-output" class="headerlink" title="n-&gt;output"></a><code>n-&gt;output</code></h4><p>如果目标不是 <code>NUD_CONNECTED</code> 或硬件头尚未缓存，则代码沿着 <code>n-&gt;output</code> 路径继续。 邻居结构的输出函数指针关联了什么 <code>output</code>？ 嗯，那要看情况了。 为了理解这是如何设置的，我们需要了解更多关于邻居缓存的工作原理。</p>
<p>一个 <code>struct neighbour</code> 包含几个重要的字段。 上面看到的 <code>nud_state</code> 字段，<code>output</code> 函数和 <code>ops</code> 结构。 回想一下之前看到的，如果在缓存中没有找到现有的条目，则从 <code>ip_finish_output2</code>  调用 <code>__neigh_create</code>。 当调用 <code>__neigh_creaet</code> 时，邻居被分配，其 <code>output</code> <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/neighbour.c#L294">函数初始设置</a>为 <code>neigh_blackhole</code>。 随着 <code>__neigh_create</code> 代码执行，它根据邻居的状态调整 <code>output</code> 的值以指向适当的 <code>output</code> 函数。</p>
<p>例如，当代码确定要连接的邻居时，<code>neigh_connect</code> 设置 <code>output</code> 指针为 <code>neigh-&gt;ops-&gt;connected_output</code>。 或者，在代码怀疑邻居可能关闭时（例如，如果自发送探测以来已经超过<code>/proc/sys/net/ipv4/neigh/default/delay_first_probe_time</code> 秒），<code>neigh_suspect</code> 设置 <code>output</code> 指针为 <code>neigh-&gt;ops-&gt;output</code>。</p>
<p>换句话说：<code>neigh-&gt;output</code> 设置为 <code>neigh-&gt;ops_connected_output</code> 还是 <code>neigh-&gt;ops-&gt;output</code>， 取决于邻居的状态。 <code>neigh-&gt;ops</code> 从何而来？</p>
<p>在分配邻居之后，<code>arp_constructor</code>（来自 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/arp.c#L220-L313">.&#x2F;net&#x2F;ipv4&#x2F;arp.c</a>）被调用来设置 <code>struct neighbour</code> 的一些字段。 特别地，此函数检查与邻居相关联的设备，并且如果该设备暴露包含<code>cache</code>（<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ethernet/eth.c#L342-L348">以太网设备这样做</a>）函数的 <code>header_ops</code> 结构 ，则 <code>neigh-&gt;ops</code> 被设置为 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/ipv4/arp.c#L138-L144">.&#x2F;net&#x2F;ipv4&#x2F;arp. c</a> 中定义的以下结构：</p>
<pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">neigh_ops</span> arp_hh_ops = &#123;
        .family =               AF_INET,
        .solicit =              arp_solicit,
        .error_report =         arp_error_report,
        .output =               neigh_resolve_output,
        .connected_output =     neigh_resolve_output,
&#125;;</code></pre>

<p>因此，无论邻居缓存代码是否视邻居为 “已连接”或“可疑”，都将关联 <code>neigh_resolve_output</code> 函数到 <code>neigh-&gt;output</code>，并且在调用 <code>n-&gt;output</code> 时被调用。</p>
<h5 id="neigh-resolve-output"><a href="#neigh-resolve-output" class="headerlink" title="neigh_resolve_output"></a><code>neigh_resolve_output</code></h5><p>此函数的目的是尝试解析未连接的邻居，或已连接但没有缓存硬件头的邻居。 让我们来看看这个函数是如何工作的：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* Slow and careful. */</span>

<span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">neigh_resolve_output</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> neighbour *neigh, <span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">dst_entry</span> *dst = <span class="hljs-built_in">skb_dst</span>(skb);
        <span class="hljs-type">int</span> rc = <span class="hljs-number">0</span>;

        <span class="hljs-keyword">if</span> (!dst)
                <span class="hljs-keyword">goto</span> discard;

        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">neigh_event_send</span>(neigh, skb)) &#123;
                <span class="hljs-type">int</span> err;
                <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_device</span> *dev = neigh-&gt;dev;
                <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> seq;</code></pre>

<p>代码首先执行一些基本检查，然后继续调用 <code>neigh_event_send</code>。 <code>neigh_event_send</code> 函数是<code>__neigh_event_send</code> 的简单包装。<code>__neigh_event_send</code> 实际完成解析邻居的繁重工作。 您可以在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/neighbour.c#L964-L1028">.&#x2F;net&#x2F;core&#x2F;neighbor.c</a> 中阅读 <code>__neigh_event_send</code> 的源代码，但从代码中可以看出，用户最感兴趣的有三点：</p>
<ol>
<li>假设<code>/proc/sys/net/ipv4/neigh/default/app_solicit</code> <code>/proc/sys/net/ipv4/neigh/default/mcast_solicit </code> 中设置的值允许发送探测，则 <code>NUD_NONE</code>  状态（分配时的默认状态）的邻居将立即发送 ARP 请求（如果不允许，则标记状态为 <code>NUD_FAILED</code>）。 邻居状态被更新并设置为 <code>NUD_INCOMPLETE</code>。</li>
<li>更新状态为 <code>NUD_STALE</code> 的邻居为 <code>NUD_DELAYED</code>，并设置一个计时器以稍后探测它们（稍后：当前时间 +<code>/proc/sys/net/ipv4/neigh/default/delay_first_probe_time</code> 秒）。</li>
<li>检查 <code>NUD_INCOMPLETE</code> 的任何邻居 （包括上面第一点），以确保未解析邻居的排队数据包数量小于等于 <code>/proc/sys/net/ipv4/neigh/default/unres_qlen</code>。 如果有更多的数据包，则将数据包出队并丢弃，直到长度低于等于 proc 中的值。针对此类情况，邻居缓存统计中的统计计数器都将增加。</li>
</ol>
<p>如果需要立刻发送 ARP 探测，它就会发送。<code>__neigh_event_send</code> 将返回 <code>0</code>，指示邻居被视为“已连接”或“已延迟”的，否则返回 <code>1</code>。 返回值 <code>0</code> 允许 <code>neigh_resolve_output</code> 函数继续执行：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (dev-&gt;header_ops-&gt;cache &amp;&amp; !neigh-&gt;hh.hh_len)
        <span class="hljs-built_in">neigh_hh_init</span>(neigh, dst);</code></pre>

<p>如果邻居关联的设备的协议实现（在此例子中是以太网）支持缓存硬件报头，并且它当前没有被缓存，则调用 <code>neigh_hh_init</code> 缓存它。</p>
<pre><code class="hljs c++"><span class="hljs-keyword">do</span> &#123;
        __skb_pull(skb, <span class="hljs-built_in">skb_network_offset</span>(skb));
        seq = <span class="hljs-built_in">read_seqbegin</span>(&amp;neigh-&gt;ha_lock);
        err = <span class="hljs-built_in">dev_hard_header</span>(skb, dev, <span class="hljs-built_in">ntohs</span>(skb-&gt;protocol),
                              neigh-&gt;ha, <span class="hljs-literal">NULL</span>, skb-&gt;len);
&#125; <span class="hljs-keyword">while</span> (<span class="hljs-built_in">read_seqretry</span>(&amp;neigh-&gt;ha_lock, seq));</code></pre>

<p>接下来，使用 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Seqlock">seqlock</a> 同步访问邻居结构的硬件地址，当尝试为 skb 创建以太网报头时，<code>dev_hard_header</code> 将读取该地址。 一旦 seqlock 允许继续执行，就会进行错误检查：</p>
<pre><code class="hljs c++">        <span class="hljs-keyword">if</span> (err &gt;= <span class="hljs-number">0</span>)
                rc = <span class="hljs-built_in">dev_queue_xmit</span>(skb);
        <span class="hljs-keyword">else</span>
                <span class="hljs-keyword">goto</span> out_kfree_skb;
&#125;</code></pre>

<p>如果以太网头被写入而没有返回错误，则 skb 被传递到 <code>dev_queue_xmit</code>，以通过 Linux 网络设备子系统进行传输。 如果有错误，<code>goto</code> 将丢弃 skb，设置返回代码并返回错误：</p>
<pre><code class="hljs c++">out:
        <span class="hljs-keyword">return</span> rc;
discard:
        <span class="hljs-built_in">neigh_dbg</span>(<span class="hljs-number">1</span>, <span class="hljs-string">&quot;%s: dst=%p neigh=%p\n&quot;</span>, __func__, dst, neigh);
out_kfree_skb:
        rc = -EINVAL;
        <span class="hljs-built_in">kfree_skb</span>(skb);
        <span class="hljs-keyword">goto</span> out;
&#125;
<span class="hljs-built_in">EXPORT_SYMBOL</span>(neigh_resolve_output);</code></pre>

<p>在进入 Linux 网络设备子系统前，让我们看一下一些监控和调优 IP 协议层的文件。</p>
<h4 id="监控：IP-协议层"><a href="#监控：IP-协议层" class="headerlink" title="监控：IP 协议层"></a>监控：IP 协议层</h4><h5 id="proc-net-snmp-1"><a href="#proc-net-snmp-1" class="headerlink" title="/proc/net/snmp"></a><code>/proc/net/snmp</code></h5><p>读取 <code>/proc/net/snmp</code> 监控详细的 IP 协议统计信息。</p>
<pre><code class="hljs bash">$ <span class="hljs-built_in">cat</span> /proc/net/snmp
Ip: Forwarding DefaultTTL InReceives InHdrErrors InAddrErrors ForwDatagrams InUnknownProtos InDiscards InDelivers OutRequests OutDiscards OutNoRoutes ReasmTimeout ReasmReqds ReasmOKs ReasmFails FragOKs FragFails FragCreates
Ip: 1 64 25922988125 0 0 15771700 0 0 25898327616 22789396404 12987882 51 1 10129840 2196520 1 0 0 0
...</code></pre>

<p>此文件包含多个协议层的统计信息。 首先显示 IP 协议层。第一行包含空格分隔的名称，每个名称对应下一行中的相应值。</p>
<p>在 IP 协议层中，您会发现统计计数器正在增加。计数器引用 C 枚举类型。 <code>/proc/net/snmp</code> 所有有效的枚举值和它们对应的字段名称可以在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/uapi/linux/snmp.h#L10-L59">include&#x2F;uapi&#x2F;linux&#x2F;snmp.h</a> 中找到：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">enum</span>
&#123;
  IPSTATS_MIB_NUM = <span class="hljs-number">0</span>,
<span class="hljs-comment">/* frequently written fields in fast path, kept in same cache line */</span>
  IPSTATS_MIB_INPKTS,     <span class="hljs-comment">/* InReceives */</span>
  IPSTATS_MIB_INOCTETS,     <span class="hljs-comment">/* InOctets */</span>
  IPSTATS_MIB_INDELIVERS,     <span class="hljs-comment">/* InDelivers */</span>
  IPSTATS_MIB_OUTFORWDATAGRAMS,   <span class="hljs-comment">/* OutForwDatagrams */</span>
  IPSTATS_MIB_OUTPKTS,      <span class="hljs-comment">/* OutRequests */</span>
  IPSTATS_MIB_OUTOCTETS,      <span class="hljs-comment">/* OutOctets */</span>

  <span class="hljs-comment">/* ... */</span></code></pre>

<p>一些有趣的统计数据：</p>
<ul>
<li><code>OutRequests</code>：每次尝试发送 IP 数据包时增加。 看起来，每次是否成功，都会增加此值。</li>
<li><code>OutDiscards</code>：每次丢弃 IP 数据包时增加。 如果数据追加到 skb（对于 corked 的套接字）失败，或者 IP 下面的层返回错误，就会发生这种情况。</li>
<li><code>OutNoRoute</code>：在多个位置增加，例如在 UDP 协议层（<code>udp_sendmsg</code>），如果无法为给定目标生成路由。 当应用程序在 UDP 套接字上调用 “connect” 但找不到路由时也会增加。</li>
<li><code>FragOKs</code>：每个被分段的数据包增加一次。 例如，被分割成 3 个片段的数据包增加该计数器一次。</li>
<li><code>FragCreates</code>：每个创建的片段增加一次。 例如，被分割成 3 个片段的数据包增加该计数器三次。</li>
<li><code>FragFails</code>：如果尝试分段，但不允许分段，则增加（因为设置了 “Don’t Fragment” 位）。 如果输出片段失败，也会增加。</li>
</ul>
<p>其他统计数据记录在<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#monitoring-ip-protocol-layer-statistics">接收端博客文章中</a>。</p>
<h5 id="proc-net-netstat"><a href="#proc-net-netstat" class="headerlink" title="/proc/net/netstat"></a><code>/proc/net/netstat</code></h5><p>读取 <code>/proc/net/netstat</code> 监控扩展 IP 协议统计信息。</p>
<pre><code class="hljs bash">$ <span class="hljs-built_in">cat</span> /proc/net/netstat | grep IpExt
IpExt: InNoRoutes InTruncatedPkts InMcastPkts OutMcastPkts InBcastPkts OutBcastPkts InOctets OutOctets InMcastOctets OutMcastOctets InBcastOctets OutBcastOctets InCsumErrors InNoECTPkts InECT0Pktsu InCEPkts
IpExt: 0 0 0 0 277959 0 14568040307695 32991309088496 0 0 58649349 0 0 0 0 0</code></pre>

<p>格式类似于 <code>/proc/net/snmp</code>，不同之处在于行的前缀是 <code>IpExt</code>。</p>
<p>一些有趣的统计数据：</p>
<ul>
<li><code>OutMcastPkts</code>：每次发送目的地为组播地址的数据包时增加。</li>
<li><code>OutBcastPkts</code>：每次发送目的地为广播地址的数据包时增加。</li>
<li><code>OutOctects</code>：输出的数据包字节数。</li>
<li><code>OutMcastOctets</code>：输出的组播数据包字节数。</li>
<li><code>OutBcastOctets</code>：输出的广播数据包字节数。</li>
</ul>
<p>其他统计数据记录在<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#monitoring-ip-protocol-layer-statistics">接收端博客文章中</a>。</p>
<p>请注意，这些值都是在 IP 层的特定位置增加的。代码有时会移动，可能会出现双重计数错误或其他统计错误。如果这些统计数据对您很重要，强烈建议您阅读 IP 协议层源代码，了解您重要的指标何时增加（或不增加）。</p>
<h3 id="Linux-网络设备子系统"><a href="#Linux-网络设备子系统" class="headerlink" title="Linux 网络设备子系统"></a>Linux 网络设备子系统</h3><p>在我们继续讨论 <code>dev_queue_xmit</code> 的数据包传输路径之前，让我们花一点时间来谈谈一些重要的概念，这些概念将出现在接下来的部分。</p>
<h4 id="Linux-流量控制"><a href="#Linux-流量控制" class="headerlink" title="Linux 流量控制"></a>Linux 流量控制</h4><p>Linux 支持一种叫做<a target="_blank" rel="noopener" href="http://tldp.org/HOWTO/Traffic-Control-HOWTO/intro.html">流量控制</a>的特性。 此功能允许系统管理员控制如何从计算机传输数据包。 本文不会深入讨论 Linux 流量控制的各方面的细节。<a target="_blank" rel="noopener" href="http://tldp.org/HOWTO/Traffic-Control-HOWTO/">这篇文档</a>提供了对系统、其控制和特性的深入研究。 有几个概念值得一提，以使下面看到的代码更容易理解。</p>
<p>流量控制系统包含几种不同的排队系统，它们为控制流量提供不同的功能。单个排队系统通常称为 <code>qdisc</code>，也称为排队规则。您可以将 qdisc 视为调度程序；qdisc 决定何时以及如何传输数据包。</p>
<p>在 Linux 上，每个接口都有一个与之关联的默认 qdisc。对于仅支持单个传输队列的网络硬件，使用默认 qdisc <code>pfifo_fast</code>。支持多个传输队列的网络硬件使用默认 qdisc <code>mq</code>。您可以运行 <code>tc qdisc</code> 来检查您的系统。</p>
<p>还需要注意的是，有些设备支持硬件流量控制，这可以让管理员将流量控制卸载到网络硬件上，从而节省系统上的 CPU 资源。</p>
<p>现在这些想法已经介绍过了，让我们从 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L2890-L2894">.&#x2F;net&#x2F;core&#x2F;dev.c</a> 继续沿着 <code>dev_queue_xmit</code> 进行。</p>
<h4 id="dev-queue-xmit-和-dev-queue-xmit"><a href="#dev-queue-xmit-和-dev-queue-xmit" class="headerlink" title="dev_queue_xmit 和 __dev_queue_xmit"></a><code>dev_queue_xmit</code> 和 <code>__dev_queue_xmit</code></h4><p><code>dev_queue_xmit</code> 是 <code>__dev_queue_xmit</code> 的一个简单包装：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">dev_queue_xmit</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">return</span> __dev_queue_xmit(skb, <span class="hljs-literal">NULL</span>);
&#125;
<span class="hljs-built_in">EXPORT_SYMBOL</span>(dev_queue_xmit);</code></pre>

<p>在此之后，<code>__dev_queue_xmit</code> 是完成繁重工作的地方。 让我们一步一步地看一下这段代码，<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L2808-L2825">继续</a>：</p>
<pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-type">int</span> __dev_queue_xmit(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-type">void</span> *accel_priv)
&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_device</span> *dev = skb-&gt;dev;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">netdev_queue</span> *txq;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Qdisc</span> *q;
        <span class="hljs-type">int</span> rc = -ENOMEM;

        <span class="hljs-built_in">skb_reset_mac_header</span>(skb);

        <span class="hljs-comment">/* Disable soft irqs for various locks below. Also</span>
<span class="hljs-comment">         * stops preemption for RCU.</span>
<span class="hljs-comment">         */</span>
        <span class="hljs-built_in">rcu_read_lock_bh</span>();

        <span class="hljs-built_in">skb_update_prio</span>(skb);</code></pre>

<p>上面的代码开始于：</p>
<ol>
<li>声明变量。</li>
<li>调用 <code>skb_reset_mac_header</code> 来准备要处理的 skb。 这将重置 skb 的内部指针，以便可以访问以太网报头。</li>
<li>调用 <code>rcu_read_lock_bh</code> 来准备读取 RCU 保护的数据结构。<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/RCU/checklist.txt">阅读更多关于安全使用 RCU 的信息</a>。</li>
<li>如果<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/Documentation/cgroups/net_prio.txt">正在使用网络优先级 cgroup</a>，调用 <code>skb_update_prio</code> 来设置 skb 的优先级。</li>
</ol>
<p>现在，我们将开始更复杂的数据传输部分 ;）</p>
<pre><code class="hljs c++">txq = <span class="hljs-built_in">netdev_pick_tx</span>(dev, skb, accel_priv);</code></pre>

<p>在这里，代码试图确定要使用哪个传输队列。 正如您将在本文后面看到的，一些网络设备公开了多个传输队列来传输数据。 让我们来详细看看这是如何工作的。</p>
<h5 id="netdev-pick-tx"><a href="#netdev-pick-tx" class="headerlink" title="netdev_pick_tx"></a><code>netdev_pick_tx</code></h5><p><code>netdev_pick_tx</code> 代码位于 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/flow_dissector.c#L397-L417">.&#x2F;net&#x2F;core&#x2F;flow_dissector.c</a> 中。 我们来看一下：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">netdev_queue</span> *<span class="hljs-built_in">netdev_pick_tx</span>(<span class="hljs-keyword">struct</span> net_device *dev,
                                    <span class="hljs-keyword">struct</span> sk_buff *skb,
                                    <span class="hljs-type">void</span> *accel_priv)
&#123;
        <span class="hljs-type">int</span> queue_index = <span class="hljs-number">0</span>;

        <span class="hljs-keyword">if</span> (dev-&gt;real_num_tx_queues != <span class="hljs-number">1</span>) &#123;
                <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_device_ops</span> *ops = dev-&gt;netdev_ops;
                <span class="hljs-keyword">if</span> (ops-&gt;ndo_select_queue)
                        queue_index = ops-&gt;<span class="hljs-built_in">ndo_select_queue</span>(dev, skb,
                                                            accel_priv);
                <span class="hljs-keyword">else</span>
                        queue_index = __netdev_pick_tx(dev, skb);

                <span class="hljs-keyword">if</span> (!accel_priv)
                        queue_index = <span class="hljs-built_in">dev_cap_txqueue</span>(dev, queue_index);
        &#125;

        <span class="hljs-built_in">skb_set_queue_mapping</span>(skb, queue_index);
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">netdev_get_tx_queue</span>(dev, queue_index);
&#125;</code></pre>

<p>正如您在上面看到的，如果网络设备只支持单个传输队列，则会跳过更复杂的代码，并返回单个传输队列。 在高端服务器上使用的大多数设备具有多个传输队列。 具有多个传输队列的设备有两种情况：</p>
<ol>
<li>驱动程序实现 <code>ndo_select_queue</code>，它可以以硬件或功能特定的方式更智能地选择传输队列，或者</li>
<li>驱动程序没有实现 <code>ndo_select_queue</code>，所以内核应该自己选择设备。</li>
</ol>
<p>截止 3.13 内核，实现 <code>ndo_select_queue</code> 的驱动程序并不多。 bnx2x 和 ixgbe 驱动程序实现了此功能，但它仅用于<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Fibre_Channel_over_Ethernet">以太网光纤通道（FCoE）</a>。 鉴于此，让我们假设网络设备不实现<code>ndo_select_queue</code> 和&#x2F;或 FCoE 未被使用。 在这种情况下，内核将选择具有 <code>__netdev_pick_tx</code>。</p>
<p>一旦 <code>__netdev_pick_tx </code>确定了队列的索引，<code>skb_set_queue_mapping</code> 将缓存该值（稍后将在流量控制代码中使用），<code>netdev_get_tx_queue</code> 将查找并返回指向该队列的指针。 在回到 <code>__dev_queue_xmit</code> 之前，让我们看看 <code>__netdev_pick_tx</code> 是如何工作 。</p>
<h5 id="netdev-pick-tx-1"><a href="#netdev-pick-tx-1" class="headerlink" title="__netdev_pick_tx"></a><code>__netdev_pick_tx</code></h5><p>让我们来看看内核如何选择传输队列来传输数据。 来自 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/flow_dissector.c#L375-L395">.&#x2F;net&#x2F;core&#x2F;flow_dissector.c</a>：</p>
<pre><code class="hljs c++">u16 __netdev_pick_tx(<span class="hljs-keyword">struct</span> net_device *dev, <span class="hljs-keyword">struct</span> sk_buff *skb)
&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sock</span> *sk = skb-&gt;sk;
        <span class="hljs-type">int</span> queue_index = <span class="hljs-built_in">sk_tx_queue_get</span>(sk);

        <span class="hljs-keyword">if</span> (queue_index &lt; <span class="hljs-number">0</span> || skb-&gt;ooo_okay ||
            queue_index &gt;= dev-&gt;real_num_tx_queues) &#123;
                <span class="hljs-type">int</span> new_index = <span class="hljs-built_in">get_xps_queue</span>(dev, skb);
                <span class="hljs-keyword">if</span> (new_index &lt; <span class="hljs-number">0</span>)
                        new_index = <span class="hljs-built_in">skb_tx_hash</span>(dev, skb);

                <span class="hljs-keyword">if</span> (queue_index != new_index &amp;&amp; sk &amp;&amp;
                    <span class="hljs-built_in">rcu_access_pointer</span>(sk-&gt;sk_dst_cache))
                        <span class="hljs-built_in">sk_tx_queue_set</span>(sk, new_index);

                queue_index = new_index;
        &#125;

        <span class="hljs-keyword">return</span> queue_index;
&#125;</code></pre>

<p>代码首先调用 <code>sk_tx_queue_get</code> 检查传输队列是否已经缓存在套接字上。如果没有缓存，则返回 <code>-1</code>。</p>
<p>下一个 if 语句检查以下任一项是否为真：</p>
<ul>
<li>queue_index 小于 0。 如果尚未设置队列，则会发生这种情况。</li>
<li><code>ooo_okay</code> 标志置位 。 如果设置了该标志，则意味着现在允许乱序数据包。 协议层必须适当地设置此标志。 在流的所有未完成数据包都已确认时，TCP 协议层会设置此标志。 当这种情况发生时，内核可以为该数据包选择不同的传输队列。 UDP 协议层不设置此标志-因此 UDP 数据包永远不会设置 <code>ooo_okay</code> 为非零值。</li>
<li>队列索引大于队列数。 如果用户最近通过 <code>ethtool</code> 更改了设备上的队列计数，则可能会发生这种情况。 稍后会详细介绍。</li>
</ul>
<p>以上任一情况下，代码都会进入慢速路径以获取传输队列。首先调用 <code>get_xps_queue</code>，它试图使用用户配置映射传输队列到 CPU。这称为“Transmit Packet Steering(XPS)”。我们稍后将更详细地了解 Transmit Packet Steering(XPS) 是什么以及它是如何工作的。</p>
<p>如果 <code>get_xps_queue</code> 返回 <code>-1</code>，则此内核不支持 XPS，或系统管理员未配置 XPS，或配置的映射指向无效队列，则代码将继续调用 <code>skb_tx_hash</code>。</p>
<p>一旦使用 XPS 或内核自动使用 <code>skb_tx_hash</code> 选择了队列，将使用 <code>sk_tx_queue_set</code> 缓存该队列到套接字对象上，并返回。在继续 <code>dev_queue_xmit</code> 之前，让我们看看 XPS 和 <code>skb_tx_hash</code> 是如何工作的。</p>
<h6 id="Transmit-Packet-Steering-XPS"><a href="#Transmit-Packet-Steering-XPS" class="headerlink" title="Transmit Packet Steering(XPS)"></a>Transmit Packet Steering(XPS)</h6><p>Transmit Packet Steering(XPS)是一项特性，允许系统管理员确定哪些 CPU 可以处理设备的哪些传输队列的传输操作。此功能的主要目的是避免在处理传输请求时出现锁争用。使用 XPS 时，还期望获得其他好处，如减少缓存驱逐和避免在 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Non-uniform_memory_access">NUMA 机器</a> 上进行远程内存访问。</p>
<p>您可以 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L364-L422">查看 XPS 的内核文档</a> 来了解更多关于 XPS 如何工作的信息。我们将在下面研究如何为您的系统调整 XPS，但现在，您需要知道的是，要配置 XPS，系统管理员可以定义一个位图，映射传输队列到 CPU。</p>
<p>上面代码中调用 <code>get_xps_queue</code> 函数将查询此用户指定的映射，以确定应使用哪个传输队列。如果 <code>get_xps_queue</code> 返回 <code>-1</code>，则将改用 <code>skb_tx_hash</code>。</p>
<h6 id="skb-tx-hash"><a href="#skb-tx-hash" class="headerlink" title="skb_tx_hash"></a><code>skb_tx_hash</code></h6><p>如果内核未包含 XPS，或未配置 XPS，或建议的队列不可用（可能是因为用户调整了队列计数），则 <code>skb_tx_hash</code> 接管以确定发送数据到哪个队列。根据传输工作负载，准确了解 <code>skb_tx_hash</code> 工作原理非常重要。 请注意，这段代码已经随着时间的推移进行了调整，因此如果您使用的内核版本与本文档不同，您应该直接查阅您的内核源代码。</p>
<p>让我们看看它是如何工作的，来自 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/linux/netdevice.h#L2331-L2340">.&#x2F;include&#x2F;linux&#x2F;netdevice.h</a>：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/*</span>
<span class="hljs-comment"> * Returns a Tx hash for the given packet when dev-&gt;real_num_tx_queues is used</span>
<span class="hljs-comment"> * as a distribution range limit for the returned value.</span>
<span class="hljs-comment"> */</span>
<span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> u16 <span class="hljs-title">skb_tx_hash</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> net_device *dev,</span></span>
<span class="hljs-params"><span class="hljs-function">                              <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> sk_buff *skb)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">return</span> __skb_tx_hash(dev, skb, dev-&gt;real_num_tx_queues);
&#125;</code></pre>

<p>代码只是调用 <code>__skb_tx_hash</code>，来自 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/flow_dissector.c#L239-L271">.&#x2F;net&#x2F;core&#x2F;flow_dissector.c</a>。这个函数中有一些有趣的代码，让我们来看看：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/*</span>
<span class="hljs-comment"> * Returns a Tx hash based on the given packet descriptor a Tx queues&#x27; number</span>
<span class="hljs-comment"> * to be used as a distribution range.</span>
<span class="hljs-comment"> */</span>
u16 __skb_tx_hash(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> net_device *dev, <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> sk_buff *skb,
                  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> num_tx_queues)
&#123;
        u32 hash;
        u16 qoffset = <span class="hljs-number">0</span>;
        u16 qcount = num_tx_queues;

        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">skb_rx_queue_recorded</span>(skb)) &#123;
                hash = <span class="hljs-built_in">skb_get_rx_queue</span>(skb);
                <span class="hljs-keyword">while</span> (<span class="hljs-built_in">unlikely</span>(hash &gt;= num_tx_queues))
                        hash -= num_tx_queues;
                <span class="hljs-keyword">return</span> hash;
        &#125;</code></pre>

<p>函数中的第一个 if 语句是一个有趣的短路。函数名 <code>skb_rx_queue_recorded</code> 有些误导。skb 有一个 <code>queue_mapping</code> 字段，用于 rx 和 tx。无论如何，如果您的系统正在接收数据包，并转发它们到其他地方，则此 if 语句为真。如果不是这种情况，则代码继续。</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (dev-&gt;num_tc) &#123;
        u8 tc = <span class="hljs-built_in">netdev_get_prio_tc_map</span>(dev, skb-&gt;priority);
        qoffset = dev-&gt;tc_to_txq[tc].offset;
        qcount = dev-&gt;tc_to_txq[tc].count;
&#125;</code></pre>

<p>要理解这段代码，重要的是要提到程序可以设置套接字发送数据的优先级。这可以使用 <code>setsockopt</code> 与 <code>SOL_SOCKET</code> 和 <code>SO_PRIORITY</code> 级别和 optname 分别完成。有关 <code>SO_PRIORITY</code> 的更多信息，请参阅 <a target="_blank" rel="noopener" href="http://man7.org/linux/man-pages/man7/socket.7.html">socket(7) 手册页</a>。</p>
<p>请注意，如果您在应用程序中使用了 <code>setsockopt</code> 选项 <code>IP_TOS</code> 来设置特定套接字发送的 IP 数据包的 TOS 标志（或者如果作为辅助消息传递给 <code>sendmsg</code> 则按每个数据包设置），则内核转换您设置的 TOS 选项为优先级，最终进入 <code>skb-&gt;priority</code>。</p>
<p>如前所述，某些网络设备支持基于硬件的流量控制系统。如果 <code>num_tc</code> 非零，则表示此设备支持基于硬件的流量控制。</p>
<p>如果该数字非零，则表示此设备支持基于硬件的流量控制。将查询优先级映射，优先级映射映射数据包优先级到基于硬件的流量控制。根据此映射为数据优先级选择适当的流量类别。</p>
<p>接下来，将生成适合流量类别的传输队列范围。它们将确定传输队列。</p>
<p>如果 <code>num_tc</code> 为零（因为网络设备不支持基于硬件的流量控制），则 <code>qcount</code> 和 <code>qoffset</code> 变量分别设置为传输队列数和 <code>0</code>。</p>
<p>使用 <code>qcount</code> 和 <code>qoffset</code>，可以计算传输队列的索引：</p>
<pre><code class="hljs c++">        <span class="hljs-keyword">if</span> (skb-&gt;sk &amp;&amp; skb-&gt;sk-&gt;sk_hash)
                hash = skb-&gt;sk-&gt;sk_hash;
        <span class="hljs-keyword">else</span>
                hash = (__force u16) skb-&gt;protocol;
        hash = __flow_hash_1word(hash);

        <span class="hljs-keyword">return</span> (u16) (((u64) hash * qcount) &gt;&gt; <span class="hljs-number">32</span>) + qoffset;
&#125;
<span class="hljs-built_in">EXPORT_SYMBOL</span>(__skb_tx_hash);</code></pre>

<p>最后，返回适当的队列索引到 <code>__netdev_pick_tx</code>。</p>
<h4 id="恢复-dev-queue-xmit"><a href="#恢复-dev-queue-xmit" class="headerlink" title="恢复 __dev_queue_xmit"></a>恢复 <code>__dev_queue_xmit</code></h4><p>此时，已选择适当的传输队列。<code>__dev_queue_xmit</code> 可以继续：</p>
<pre><code class="hljs c++">        q = <span class="hljs-built_in">rcu_dereference_bh</span>(txq-&gt;qdisc);

<span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> CONFIG_NET_CLS_ACT</span>
        skb-&gt;tc_verd = <span class="hljs-built_in">SET_TC_AT</span>(skb-&gt;tc_verd, AT_EGRESS);
<span class="hljs-meta">#<span class="hljs-keyword">endif</span></span>
        <span class="hljs-built_in">trace_net_dev_queue</span>(skb);
        <span class="hljs-keyword">if</span> (q-&gt;enqueue) &#123;
                rc = __dev_xmit_skb(skb, q, dev, txq);
                <span class="hljs-keyword">goto</span> out;
        &#125;</code></pre>

<p>它首先获得与此队列相关联的排队规则的引用。回想一下，我们之前看到，对于单个传输队列设备，默认值是 <code>pfifo_fast</code> qdisc，而对于多队列设备，它是 <code>mq</code> qdisc。</p>
<p>接下来，如果在内核中启用了数据包分类 API，则代码会为传出数据分配一个流量分类“决定”。接下来，检查排队规则是否有方法将数据排队。像 <code>noqueue</code> qdisc 这样的一些排队规则没有队列。如果有队列，则代码调用 <code>__dev_xmit_skb</code> 来继续处理要传输的数据。之后，执行跳转到此函数的结尾。我们稍后将看一下 <code>__dev_xmit_skb</code>。现在，让我们看看如果没有队列会发生什么，从一个非常有用的注释开始：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* The device has no queue. Common case for software devices:</span>
<span class="hljs-comment">   loopback, all the sorts of tunnels...</span>
<span class="hljs-comment"></span>
<span class="hljs-comment">   Really, it is unlikely that netif_tx_lock protection is necessary</span>
<span class="hljs-comment">   here.  (f.e. loopback and IP tunnels are clean ignoring statistics</span>
<span class="hljs-comment">   counters.)</span>
<span class="hljs-comment">   However, it is possible, that they rely on protection</span>
<span class="hljs-comment">   made by us here.</span>
<span class="hljs-comment"></span>
<span class="hljs-comment">   Check this and shot the lock. It is not prone from deadlocks.</span>
<span class="hljs-comment">   Either shot noqueue qdisc, it is even simpler 8)</span>
<span class="hljs-comment"> */</span>
<span class="hljs-keyword">if</span> (dev-&gt;flags &amp; IFF_UP) &#123;
        <span class="hljs-type">int</span> cpu = <span class="hljs-built_in">smp_processor_id</span>(); <span class="hljs-comment">/* ok because BHs are off */</span></code></pre>

<p>正如注释所示，唯一可以拥有不带队列的 qdisc 的设备是环回设备和隧道设备。 如果设备当前已启动，则保存当前 CPU。 它用于下一项检查，这有点棘手，让我们来看看：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (txq-&gt;xmit_lock_owner != cpu) &#123;

        <span class="hljs-keyword">if</span> (__this_cpu_read(xmit_recursion) &gt; RECURSION_LIMIT)
                <span class="hljs-keyword">goto</span> recursion_alert;</code></pre>

<p>此处有两个分支：该设备队列上的传输锁是否由该 CPU 拥有。 如果是，则在此处检查为每个 CPU 分配的计数器变量 <code>xmit_recursion</code>，以确定计数是否超过 <code>RECURSION_LIMIT</code>。 一个程序可能试图发送数据，并在代码中的这个地方被抢占。 调度程序可以选择另一个程序来运行。 如果第二个程序也试图发送数据并运行到这里。 因此，<code>xmit_recursion</code> 计数器防止超过<code>RECURSION_LIMIT</code> 程序此处竞争传输数据。 让我们继续：</p>
<pre><code class="hljs c++">                        <span class="hljs-built_in">HARD_TX_LOCK</span>(dev, txq, cpu);

                        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">netif_xmit_stopped</span>(txq)) &#123;
                                __this_cpu_inc(xmit_recursion);
                                rc = <span class="hljs-built_in">dev_hard_start_xmit</span>(skb, dev, txq);
                                __this_cpu_dec(xmit_recursion);
                                <span class="hljs-keyword">if</span> (<span class="hljs-built_in">dev_xmit_complete</span>(rc)) &#123;
                                        <span class="hljs-built_in">HARD_TX_UNLOCK</span>(dev, txq);
                                        <span class="hljs-keyword">goto</span> out;
                                &#125;
                        &#125;
                        <span class="hljs-built_in">HARD_TX_UNLOCK</span>(dev, txq);
                        <span class="hljs-built_in">net_crit_ratelimited</span>(<span class="hljs-string">&quot;Virtual device %s asks to queue packet!\n&quot;</span>,
                                             dev-&gt;name);
                &#125; <span class="hljs-keyword">else</span> &#123;
                        <span class="hljs-comment">/* Recursion is detected! It is possible,</span>
<span class="hljs-comment">                         * unfortunately</span>
<span class="hljs-comment">                         */</span>
recursion_alert:
                        <span class="hljs-built_in">net_crit_ratelimited</span>(<span class="hljs-string">&quot;Dead loop on virtual device %s, fix it urgently!\n&quot;</span>,
                                             dev-&gt;name);
                &#125;
        &#125;</code></pre>

<p>代码的其余部分首先尝试获取传输锁。检查要使用的设备的传输队列，以查看是否停止传输。如果没有，则增加 <code>xmit_recursion</code> 变量，并传递数据到更靠近设备的位置进行传输。我们稍后会更详细地看到 <code>dev_hard_start_xmit</code>。完成后，释放锁并打印警告。</p>
<p>另外，如果当前 CPU 是传输锁所有者，或者如果达到了 <code>RECURSION_LIMIT</code>，则不进行传输，但会打印警告。函数中剩余的代码设置错误码并返回。</p>
<p>由于我们对真实以太网设备感兴趣，因此让我们继续沿着前面 <code>__dev_xmit_skb</code> 为那些设备所采用的代码路径。</p>
<h4 id="dev-xmit-skb"><a href="#dev-xmit-skb" class="headerlink" title="__dev_xmit_skb"></a><code>__dev_xmit_skb</code></h4><p>现在我们从 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L2684-L2745">.&#x2F;net&#x2F;core&#x2F;dev. c</a> 进入 <code>__dev_xmit_skb</code>，并配备了排队规则、网络设备和传输队列引用：</p>
<pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> __dev_xmit_skb(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-keyword">struct</span> Qdisc *q,
                                 <span class="hljs-keyword">struct</span> net_device *dev,
                                 <span class="hljs-keyword">struct</span> netdev_queue *txq)
&#123;
        <span class="hljs-type">spinlock_t</span> *root_lock = <span class="hljs-built_in">qdisc_lock</span>(q);
        <span class="hljs-type">bool</span> contended;
        <span class="hljs-type">int</span> rc;

        <span class="hljs-built_in">qdisc_pkt_len_init</span>(skb);
        <span class="hljs-built_in">qdisc_calculate_pkt_len</span>(skb, q);
        <span class="hljs-comment">/*</span>
<span class="hljs-comment">         * Heuristic to force contended enqueues to serialize on a</span>
<span class="hljs-comment">         * separate lock before trying to get qdisc main lock.</span>
<span class="hljs-comment">         * This permits __QDISC_STATE_RUNNING owner to get the lock more often</span>
<span class="hljs-comment">         * and dequeue packets faster.</span>
<span class="hljs-comment">         */</span>
        contended = <span class="hljs-built_in">qdisc_is_running</span>(q);
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(contended))
                <span class="hljs-built_in">spin_lock</span>(&amp;q-&gt;busylock);</code></pre>

<p>这段代码首先使用 <code>qdisc_pkt_len_init</code> 和 <code>qdisc_calculate_pkt_len</code> 计算 qdisc 稍后将使用的数据的准确长度。 这对于基于硬件的发送卸载（例如 UDP 分段卸载，如我们之前所看到的）的 skb 是必要的，因为需要考虑在分段发生时添加的附加报头。</p>
<p>接下来，使用一把锁来帮助减少 qdisc 主锁（稍后我们将看到第二把锁）的竞争。 如果 qdisc 当前正在运行，则其他试图传输的程序将竞争 qdisc 的 <code>busylock</code>。 使得运行中的 qdisc 处理数据包，并与较少数量的程序竞争第二把主锁。 该技巧减少了竞争者的数量，从而增加了吞吐量。 你可以在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/commit/79640a4ca6955e3ebdb7038508fa7a0cd7fa5527">这里</a> 阅读描述这一点的原始提交消息。 接下来，主锁被占用：</p>
<pre><code class="hljs c++"><span class="hljs-built_in">spin_lock</span>(root_lock);</code></pre>

<p>现在，我们接近一个 if 语句，它处理 3 种可能的情况：</p>
<ol>
<li>qdisc 已停用。</li>
<li>qdisc 允许数据包绕过排队系统，且没有其他数据包要发送，且 qdisc 当前未运行。 qdisc 变为 “工作节省” qdisc ，允许数据包绕过 —— 换句话说，流量整形目的的 qdisc 不延迟数据包传输。</li>
<li>所有其他情况。</li>
</ol>
<p>让我们来看看在这些情况下会发生什么，从停用的 qdisc 开始：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(<span class="hljs-built_in">test_bit</span>(__QDISC_STATE_DEACTIVATED, &amp;q-&gt;state))) &#123;
        <span class="hljs-built_in">kfree_skb</span>(skb);
        rc = NET_XMIT_DROP;</code></pre>

<p>这是直截了当的。 如果 qdisc 已停用，请释放数据并设置返回码为 <code>NET_XMIT_DROP</code>。 接下来，qdisc 允许数据包旁路，没有其他未完成的数据包，且 qdisc 当前未运行：</p>
<pre><code class="hljs c++">&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((q-&gt;flags &amp; TCQ_F_CAN_BYPASS) &amp;&amp; !<span class="hljs-built_in">qdisc_qlen</span>(q) &amp;&amp;
           <span class="hljs-built_in">qdisc_run_begin</span>(q)) &#123;
        <span class="hljs-comment">/*</span>
<span class="hljs-comment">         * This is a work-conserving queue; there are no old skbs</span>
<span class="hljs-comment">         * waiting to be sent out; and the qdisc is not running -</span>
<span class="hljs-comment">         * xmit the skb directly.</span>
<span class="hljs-comment">         */</span>
        <span class="hljs-keyword">if</span> (!(dev-&gt;priv_flags &amp; IFF_XMIT_DST_RELEASE))
                <span class="hljs-built_in">skb_dst_force</span>(skb);

        <span class="hljs-built_in">qdisc_bstats_update</span>(q, skb);

        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">sch_direct_xmit</span>(skb, q, dev, txq, root_lock)) &#123;
                <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(contended)) &#123;
                        <span class="hljs-built_in">spin_unlock</span>(&amp;q-&gt;busylock);
                        contended = <span class="hljs-literal">false</span>;
                &#125;
                __qdisc_run(q);
        &#125; <span class="hljs-keyword">else</span>
                <span class="hljs-built_in">qdisc_run_end</span>(q);

        rc = NET_XMIT_SUCCESS;</code></pre>

<p>这个 if 语句有点棘手。 如果以下所有条件均为 <code>true</code>，则整个语句的计算结果为真：</p>
<ol>
<li><code>q-&gt;flags &amp; TCQ_F_CAN_BYPASS</code>：qdisc 允许数据包绕过排队系统。 这对于“工作节省”的 qdisc 是 true；即，出于流量整形目的而不延迟数据包传输的 qdisc 被认为是 “工作节省” 的，并且允许数据包绕过。 <code>pfifo_fast</code> qdisc 允许数据包绕过排队系统。</li>
<li><code>！qdisc_qlen（q）</code>：qdisc 的队列中没有等待传输的数据。</li>
<li><code>qdisc_run_begin(p)</code>：此函数调用设置 qdisc 的状态为 “running” 并返回 true，如果 qdisc 已经在运行则返回 false。</li>
</ol>
<p>如果上述所有值均为 true，则：</p>
<ul>
<li>检查 <code>IFF_XMIT_DST_RELEASE</code> 标志。 如果启用，此标志表示允许内核释放 skb 的目标缓存结构。 此函数中的代码检查标志是否被禁用，并强制对该结构进行引用计数。</li>
<li><code>qdisc_bstats_update</code> 增加 qdisc 发送的字节数和数据包数。</li>
<li><code>sch_direct_xmit</code> 尝试发送数据包。 我们将很快深入研究 <code>sch_direct_xmit</code>，因为它也用于较慢的代码路径中。</li>
</ul>
<p>在两种情况下检查 <code>sch_direct_xmit</code> 的返回值：</p>
<ol>
<li>队列不为空（返回 <code>&gt; 0</code> ）。在这种情况下，会释放防止其他程序争用的锁，并调用<code>__qdisc_run</code> 重新启动 qdisc 处理。</li>
<li>队列为空（返回 <code>0</code>）。在这种情况下，调用 <code>qdisc_run_end</code> 关闭 qdisc 处理。</li>
</ol>
<p>在这两种情况下，返回值 <code>NET_XMIT_SUCCESS</code> 都被设置为返回码。 还不算太糟。 让我们看看最后一个分支，即捕获所有情况：</p>
<pre><code class="hljs c++">&#125; <span class="hljs-keyword">else</span> &#123;
        <span class="hljs-built_in">skb_dst_force</span>(skb);
        rc = q-&gt;<span class="hljs-built_in">enqueue</span>(skb, q) &amp; NET_XMIT_MASK;
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">qdisc_run_begin</span>(q)) &#123;
                <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(contended)) &#123;
                        <span class="hljs-built_in">spin_unlock</span>(&amp;q-&gt;busylock);
                        contended = <span class="hljs-literal">false</span>;
                &#125;
                __qdisc_run(q);
        &#125;
&#125;</code></pre>

<p>在所有其他情况下：</p>
<ol>
<li>调用 <code>skb_dst_force</code> 强制增加 skb 的目标缓存引用计数。</li>
<li>调用 qdisc 的 <code>enqueue</code> 函数排队数据到 qdisc。 存储返回码。</li>
<li>调用 <code>qdisc_run_begin(p)</code> 标记 qdisc 为正在运行。 如果尚未运行，则释放 <code>busylock</code> 并调用 <code>__qdisc_run(p)</code> 来启动 qdisc 处理。</li>
</ol>
<p>然后，该函数释放一些锁，并返回返回码：</p>
<pre><code class="hljs c++"><span class="hljs-built_in">spin_unlock</span>(root_lock);
<span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(contended))
        <span class="hljs-built_in">spin_unlock</span>(&amp;q-&gt;busylock);
<span class="hljs-keyword">return</span> rc;</code></pre>

<h4 id="调优：Transmit-Packet-Steering-XPS"><a href="#调优：Transmit-Packet-Steering-XPS" class="headerlink" title="调优：Transmit Packet Steering(XPS)"></a>调优：Transmit Packet Steering(XPS)</h4><p>要使 XPS 工作，必须在内核配置中启用它（在 Ubuntu 的内核 3.13.0 上是启用的），并且需要一个位掩码来描述哪些 CPU 应该处理给定接口和传输队列的数据包。</p>
<p>这些位掩码类似于 <a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#receive-packet-steering-rps">RPS</a> 位掩码，您可以在内核文档中找到关于这些位掩码的一些 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L147-L150">文档</a>。</p>
<p>简而言之，要修改的位掩码位于：</p>
<p><code>/sys/class/net/DEVICE_NAME/queues/QUEUE/xps_cpus</code></p>
<p>因此，对于 eth0 和传输队列 0，您需要修改文件：<code>/sys/class/net/eth0/queues/tx-0/xps_cpus</code>，其中十六进制数指示哪些 CPU 应处理来自 <code>eth0</code> 的传输队列 0 的传输完成。 正如<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L412-L422">文档</a>所指出的，XPS 在某些配置中可能是不必要的。</p>
<h3 id="排队规则！"><a href="#排队规则！" class="headerlink" title="排队规则！"></a>排队规则！</h3><p>要了解网络数据的路径，我们需要稍微了解一下 qdisc 代码。本文不打算涵盖每个不同传输队列选项的具体细节。 如果你对此感兴趣，请<a target="_blank" rel="noopener" href="http://lartc.org/howto/index.html">查看这本优秀的指南</a>。</p>
<p>在这篇博客文章中，我们将继续代码路径，研究通用包调度器代码是如何工作的。 特别是，我们将探索 <code>qdisc_run_begin</code>、<code>qdisc_run_end</code>、<code>__qdisc_run</code> 和 <code>sch_direct_xmit</code> 如何移动网络数据到更靠近传输驱动程序的位置。</p>
<p>让我们先看看 <code>qdisc_run_begin</code> 是如何工作的，并从那里开始。</p>
<h4 id="qdisc-run-begin-和-qdisc-run-end"><a href="#qdisc-run-begin-和-qdisc-run-end" class="headerlink" title="qdisc_run_begin 和 qdisc_run_end"></a><code>qdisc_run_begin</code> 和 <code>qdisc_run_end</code></h4><p><code>qdisc_run_begin</code> 函数可以在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/net/sch_generic.h#L101-L107">.&#x2F;include&#x2F;net&#x2F;sch_generic.h</a> 中找到：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">bool</span> <span class="hljs-title">qdisc_run_begin</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> Qdisc *qdisc)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">qdisc_is_running</span>(qdisc))
                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;
        qdisc-&gt;__state |= __QDISC___STATE_RUNNING;
        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;
&#125;</code></pre>

<p>这个函数很简单：检查 qdisc 的 <code>__state</code> 标志。 如果它已经在运行，则返回 <code>false</code>。 否则，更新 <code>__state</code>  以启用 <code>__QDISC___STATE_RUNNING</code> 位。</p>
<p>同样，<code>qdisc_run_end</code> <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/net/sch_generic.h#L109-L113">也是寡淡的</a>：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">qdisc_run_end</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> Qdisc *qdisc)</span></span>
<span class="hljs-function"></span>&#123;
        qdisc-&gt;__state &amp;= ~__QDISC___STATE_RUNNING;
&#125;</code></pre>

<p>它只是禁用 qdisc <code>__state</code> 字段中的 <code>__QDISC__STATE_RUNNING</code> 位。 需要注意的是，这两个函数都只是翻转位；自己既不实际开始，也不停止处理。 另一方面，函数 <code>__qdisc_run</code> 实际上开始处理。</p>
<h4 id="qdisc-run"><a href="#qdisc-run" class="headerlink" title="__qdisc_run"></a><code>__qdisc_run</code></h4><p><code>__qdisc_run</code> 看起来很简短：</p>
<pre><code class="hljs c++"><span class="hljs-type">void</span> __qdisc_run(<span class="hljs-keyword">struct</span> Qdisc *q)
&#123;
        <span class="hljs-type">int</span> quota = weight_p;

        <span class="hljs-keyword">while</span> (<span class="hljs-built_in">qdisc_restart</span>(q)) &#123;
                <span class="hljs-comment">/*</span>
<span class="hljs-comment">                 * Ordered by possible occurrence: Postpone processing if</span>
<span class="hljs-comment">                 * 1. we&#x27;ve exceeded packet quota</span>
<span class="hljs-comment">                 * 2. another process needs the CPU;</span>
<span class="hljs-comment">                 */</span>
                <span class="hljs-keyword">if</span> (--quota &lt;= <span class="hljs-number">0</span> || <span class="hljs-built_in">need_resched</span>()) &#123;
                        __netif_schedule(q);
                        <span class="hljs-keyword">break</span>;
                &#125;
        &#125;

        <span class="hljs-built_in">qdisc_run_end</span>(q);
&#125;</code></pre>

<p>该函数首先获取 <code>weight_p</code> 值。 该值通常是 sysctl 设置的，也会在接收路径中使用。我们稍后会看到如何调整这个值。 这个循环做两件事：</p>
<ol>
<li>它在一个繁忙的循环中调用 <code>qdisc_restart</code>，直到返回 false（或者触发下面的 break）。</li>
<li>确定配额是否降至零以下或 <code>need_resched()</code> 返回 true。 如果其中一个为 <code>true</code>，则调用 <code>__netif_schedule</code> 并中断循环。</li>
</ol>
<p>记住：到现在为止，内核仍然在执行代表用户程序对 <code>sendmsg</code> 的原始调用；用户程序当前正在累积系统时间。 如果用户程序已经用完了内核中的时间配额，那么 <code>need_resched</code> 将返回 true。 如果仍然有可用的配额，并且用户程序尚未使用完其时间片，<code>qdisc_restart</code> 将再次被调用。</p>
<p>让我们看看 <code>qdisc_restart(q)</code> 是如何工作的，然后我们将深入研究 <code>__netif_schedule(q)</code>。</p>
<h4 id="qdisc-restart"><a href="#qdisc-restart" class="headerlink" title="qdisc_restart"></a><code>qdisc_restart</code></h4><p>让我们跳到 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L156-L192"><code>qdisc_restart</code></a> 的代码中：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/*</span>
<span class="hljs-comment"> * <span class="hljs-doctag">NOTE:</span> Called under qdisc_lock(q) with locally disabled BH.</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> * __QDISC_STATE_RUNNING guarantees only one CPU can process</span>
<span class="hljs-comment"> * this qdisc at a time. qdisc_lock(q) serializes queue accesses for</span>
<span class="hljs-comment"> * this queue.</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> *  netif_tx_lock serializes accesses to device driver.</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> *  qdisc_lock(q) and netif_tx_lock are mutually exclusive,</span>
<span class="hljs-comment"> *  if one is grabbed, another must be free.</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> * Note, that this procedure can be called by a watchdog timer</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> * Returns to the caller:</span>
<span class="hljs-comment"> *                                0  - queue is empty or throttled.</span>
<span class="hljs-comment"> *                                &gt;0 - queue is not empty.</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> */</span>
<span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title">qdisc_restart</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> Qdisc *q)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">netdev_queue</span> *txq;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_device</span> *dev;
        <span class="hljs-type">spinlock_t</span> *root_lock;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff</span> *skb;

        <span class="hljs-comment">/* Dequeue packet */</span>
        skb = <span class="hljs-built_in">dequeue_skb</span>(q);
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(!skb))
                <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
        <span class="hljs-built_in">WARN_ON_ONCE</span>(<span class="hljs-built_in">skb_dst_is_noref</span>(skb));
        root_lock = <span class="hljs-built_in">qdisc_lock</span>(q);
        dev = <span class="hljs-built_in">qdisc_dev</span>(q);
        txq = <span class="hljs-built_in">netdev_get_tx_queue</span>(dev, <span class="hljs-built_in">skb_get_queue_mapping</span>(skb));

        <span class="hljs-keyword">return</span> <span class="hljs-built_in">sch_direct_xmit</span>(skb, q, dev, txq, root_lock);
&#125;</code></pre>

<p><code>qdisc_restart</code> 函数以一个有用的注释开始，该注释描述了调用此函数的一些加锁约束。 此函数执行的第一个操作是尝试从 qdisc 出队 skb。</p>
<p>函数 <code>dequeue_skb</code> 尝试获得下一个要传输的数据包。 如果队列为空 <code>qdisc_restart</code> 将返回 false（导致 <code>__qdisc_run</code> 退出）。</p>
<p>假设存在要传输的数据，则代码继续获取 qdisc 队列锁、qdisc 的关联设备和传输队列的引用。</p>
<p>所有这些都会传递到 <code>sch_direct_xmit</code>。 让我们先看一下 <code>dequeue_skb</code>，然后再看 <code>sch_direct_xmit</code>。</p>
<h5 id="dequeue-skb"><a href="#dequeue-skb" class="headerlink" title="dequeue_skb"></a><code>dequeue_skb</code></h5><p>让我们看一下 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L59-L78">.&#x2F;net&#x2F;sched&#x2F;sch_generic.c</a> 中的 <code>dequeue_skb</code>。 此函数处理两种主要情况：</p>
<ol>
<li>将之前无法发送而重新排队的数据出队，或</li>
<li>将要处理的新数据从 qdisc 出队。</li>
</ol>
<p>我们来看一下第一个案例：</p>
<pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff</span> *<span class="hljs-built_in">dequeue_skb</span>(<span class="hljs-keyword">struct</span> Qdisc *q)
&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff</span> *skb = q-&gt;gso_skb;
        <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">netdev_queue</span> *txq = q-&gt;dev_queue;

        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(skb)) &#123;
                <span class="hljs-comment">/* check the reason of requeuing without tx lock first */</span>
                txq = <span class="hljs-built_in">netdev_get_tx_queue</span>(txq-&gt;dev, <span class="hljs-built_in">skb_get_queue_mapping</span>(skb));
                <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">netif_xmit_frozen_or_stopped</span>(txq)) &#123;
                        q-&gt;gso_skb = <span class="hljs-literal">NULL</span>;
                        q-&gt;q.qlen--;
                &#125; <span class="hljs-keyword">else</span>
                        skb = <span class="hljs-literal">NULL</span>;</code></pre>

<p>请注意，该代码首先引用 qdisc 的 <code>gso_skb</code> 字段。 此字段保存重新排队的数据的引用。 如果未重新排队数据，则此字段将为 <code>NULL</code>。 如果该字段不为 <code>NULL</code>，则代码继续获取数据的传输队列并检查队列是否停止。 如果队列没有停止，则清除 <code>gso_skb</code> 字段，并且减少队列长度计数器。 如果队列停止，数据仍然关联到 <code>gso_skb</code>，但此函数将返回 <code>NULL</code>。</p>
<p>让我们检查下一个案例，其中没有重新排队的数据：</p>
<pre><code class="hljs c++">        &#125; <span class="hljs-keyword">else</span> &#123;
                <span class="hljs-keyword">if</span> (!(q-&gt;flags &amp; TCQ_F_ONETXQUEUE) || !<span class="hljs-built_in">netif_xmit_frozen_or_stopped</span>(txq))
                        skb = q-&gt;<span class="hljs-built_in">dequeue</span>(q);
        &#125;

        <span class="hljs-keyword">return</span> skb;
&#125;</code></pre>

<p>在没有数据被重新排队的情况下，另一个复杂的复合 if 语句被求值。 如果：</p>
<ol>
<li>qdisc 没有单个传输队列，或者</li>
<li>传输队列未停止</li>
</ol>
<p>然后，调用 qdisc 的 <code>dequeue</code> 函数以获取新数据。 <code>dequeue</code> 的内部实现根据 qdisc 的实现和特性而有所不同。</p>
<p>该函数以返回待处理的数据结束。</p>
<h5 id="sch-direct-xmit"><a href="#sch-direct-xmit" class="headerlink" title="sch_direct_xmit"></a><code>sch_direct_xmit</code></h5><p>现在我们来看看 <code>sch_direct_xmit</code>（在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L109-L154">.&#x2F;net&#x2F;sched&#x2F;sch_generic.c</a> 中），它是向下移动数据到网络设备的重要参与者。 让我们一点一点地来看看：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/*</span>
<span class="hljs-comment"> * Transmit one skb, and handle the return status as required. Holding the</span>
<span class="hljs-comment"> * __QDISC_STATE_RUNNING bit guarantees that only one CPU can execute this</span>
<span class="hljs-comment"> * function.</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> * Returns to the caller:</span>
<span class="hljs-comment"> *                                0  - queue is empty or throttled.</span>
<span class="hljs-comment"> *                                &gt;0 - queue is not empty.</span>
<span class="hljs-comment"> */</span>
<span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">sch_direct_xmit</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-keyword">struct</span> Qdisc *q,</span></span>
<span class="hljs-params"><span class="hljs-function">                    <span class="hljs-keyword">struct</span> net_device *dev, <span class="hljs-keyword">struct</span> netdev_queue *txq,</span></span>
<span class="hljs-params"><span class="hljs-function">                    <span class="hljs-type">spinlock_t</span> *root_lock)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-type">int</span> ret = NETDEV_TX_BUSY;

        <span class="hljs-comment">/* And release qdisc */</span>
        <span class="hljs-built_in">spin_unlock</span>(root_lock);

        <span class="hljs-built_in">HARD_TX_LOCK</span>(dev, txq, <span class="hljs-built_in">smp_processor_id</span>());
        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">netif_xmit_frozen_or_stopped</span>(txq))
                ret = <span class="hljs-built_in">dev_hard_start_xmit</span>(skb, dev, txq);

        <span class="hljs-built_in">HARD_TX_UNLOCK</span>(dev, txq);</code></pre>

<p>该代码首先释放 qdisc 锁，然后锁定传输锁。 注意，<code>HARD_TX_LOCK</code> 是一个宏：</p>
<pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> HARD_TX_LOCK(dev, txq, cpu) &#123;                   \</span>
<span class="hljs-meta">        <span class="hljs-keyword">if</span> ((dev-&gt;features &amp; NETIF_F_LLTX) == 0) &#123;      \</span>
<span class="hljs-meta">                __netif_tx_lock(txq, cpu);              \</span>
<span class="hljs-meta">        &#125;                                               \</span>
<span class="hljs-meta">&#125;</span></code></pre>

<p>此宏检查设备功能标志中是否设置了 <code>NETIF_F_LLTX</code> 标志。 此标志已弃用，新设备驱动程序不应使用此标志。 此内核版本中的大多数驱动程序都不使用此标志，因此此检查将评估为 true，并将获得此数据的传输队列的锁。</p>
<p>接下来，检查传输队列以确保它没有停止，然后调用 <code>dev_hard_start_xmit</code>。 我们将在后面看到，<code>dev_hard_start_xmit</code> 从 Linux 内核的网络设备子系统转换网络数据到设备驱动程序本身以进行传输。 存储此函数的返回码，然后检查该返回码以确定传输是否成功。</p>
<p>一旦这已经运行（或者由于队列停止而被跳过），则释放队列的传输锁。 让我们继续：</p>
<pre><code class="hljs c++"><span class="hljs-built_in">spin_lock</span>(root_lock);

<span class="hljs-keyword">if</span> (<span class="hljs-built_in">dev_xmit_complete</span>(ret)) &#123;
        <span class="hljs-comment">/* Driver sent out skb successfully or skb was consumed */</span>
        ret = <span class="hljs-built_in">qdisc_qlen</span>(q);
&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ret == NETDEV_TX_LOCKED) &#123;
        <span class="hljs-comment">/* Driver try lock failed */</span>
        ret = <span class="hljs-built_in">handle_dev_cpu_collision</span>(skb, txq, q);</code></pre>

<p>接下来，再次获取此 qdisc 的锁，然后检查 <code>dev_hard_start_xmit</code>。 第一种情况是调用 <code>dev_xmit_complete</code> 检查，它只是检查返回值以确定数据是否成功发送。 如果是，则设置 qdisc 队列长度为返回值。</p>
<p>如果 <code>dev_xmit_complete</code> 返回 false，则将检查返回值以查看 <code>dev_hard_start_xmit</code> 是否从设备驱动程序返回 <code>NETDEV_TX_LOCKED</code>。 当驱动程序尝试自己锁定传输队列并失败时，具有不推荐使用的 <code>NETIF_F_LLTX</code> 功能标志的设备可以返回 <code>NETDEV_TX_LOCKED</code>。 在这种情况下，调用 <code>handle_dev_cpu_collision</code> 来处理锁竞争。 我们稍后会仔细研究 <code>handle_dev_cpu_collision</code>，但现在，让我们继续 <code>sch_direct_xmit</code> 并查看捕获所有的分支：</p>
<pre><code class="hljs c++">&#125; <span class="hljs-keyword">else</span> &#123;
        <span class="hljs-comment">/* Driver returned NETDEV_TX_BUSY - requeue skb */</span>
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(ret != NETDEV_TX_BUSY))
                <span class="hljs-built_in">net_warn_ratelimited</span>(<span class="hljs-string">&quot;BUG %s code %d qlen %d\n&quot;</span>,
                                     dev-&gt;name, ret, q-&gt;q.qlen);

        ret = <span class="hljs-built_in">dev_requeue_skb</span>(skb, q);
&#125;</code></pre>

<p>因此，如果驱动程序没有传输数据，并且传输锁未被持有，则可能是由于 <code>NETDEV_TX_BUSY</code> （如果没有打印警告）。<code>NETDEV_TX_BUSY</code> 可以由驱动程序返回，以指示设备或驱动程序“忙碌”并且现在不能传输数据。 在本例中，调用 <code>dev_requeue_skb</code> 将要重试的数据重新入队。</p>
<p>该函数（可能）调整返回值来结束：</p>
<pre><code class="hljs stata"><span class="hljs-keyword">if</span> (<span class="hljs-keyword">ret</span> &amp;&amp; netif_xmit_frozen_or_stopped(txq))
        <span class="hljs-keyword">ret</span> = 0;

<span class="hljs-keyword">return</span> <span class="hljs-keyword">ret</span>;</code></pre>

<p>让我们深入了解 <code>handle_dev_cpu_collision</code> 和 <code>dev_requeue_skb</code>。</p>
<h5 id="handle-dev-cpu-collision"><a href="#handle-dev-cpu-collision" class="headerlink" title="handle_dev_cpu_collision"></a><code>handle_dev_cpu_collision</code></h5><p>来自 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L80-L107">.&#x2F;net&#x2F;sched&#x2F;sch_generic.c</a>  的代码 <code>handle_dev_cpu_collision</code> 处理两种情况：</p>
<ol>
<li>传输锁由当前 CPU 持有。</li>
<li>传输锁由其他 CPU 持有。</li>
</ol>
<p>在第一种情况下，这被作为配置问题处理，因此打印警告。 在第二种情况下，增加统计计数器<code>cpu_collision</code>，并且数据经 <code>dev_requeue_skb</code> 发送，以便稍后重新排队传输。 回想一下，我们在  <code>dequeue_skb</code> 中看到的专门处理重新排队的 skb 代码。</p>
<p><code>handle_dev_cpu_collision</code> 的代码很短，值得快速阅读：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title">handle_dev_cpu_collision</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb,</span></span>
<span class="hljs-params"><span class="hljs-function">                                           <span class="hljs-keyword">struct</span> netdev_queue *dev_queue,</span></span>
<span class="hljs-params"><span class="hljs-function">                                           <span class="hljs-keyword">struct</span> Qdisc *q)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-type">int</span> ret;

        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(dev_queue-&gt;xmit_lock_owner == <span class="hljs-built_in">smp_processor_id</span>())) &#123;
                <span class="hljs-comment">/*</span>
<span class="hljs-comment">                 * Same CPU holding the lock. It may be a transient</span>
<span class="hljs-comment">                 * configuration error, when hard_start_xmit() recurses. We</span>
<span class="hljs-comment">                 * detect it by checking xmit owner and drop the packet when</span>
<span class="hljs-comment">                 * deadloop is detected. Return OK to try the next skb.</span>
<span class="hljs-comment">                 */</span>
                <span class="hljs-built_in">kfree_skb</span>(skb);
                <span class="hljs-built_in">net_warn_ratelimited</span>(<span class="hljs-string">&quot;Dead loop on netdevice %s, fix it urgently!\n&quot;</span>,
                                     dev_queue-&gt;dev-&gt;name);
                ret = <span class="hljs-built_in">qdisc_qlen</span>(q);
        &#125; <span class="hljs-keyword">else</span> &#123;
                <span class="hljs-comment">/*</span>
<span class="hljs-comment">                 * Another cpu is holding lock, requeue &amp; delay xmits for</span>
<span class="hljs-comment">                 * some time.</span>
<span class="hljs-comment">                 */</span>
                __this_cpu_inc(softnet_data.cpu_collision);
                ret = <span class="hljs-built_in">dev_requeue_skb</span>(skb, q);
        &#125;

        <span class="hljs-keyword">return</span> ret;
&#125;</code></pre>

<p>让我们来看看 <code>dev_requeue_skb</code> 做了什么，因为我们将看到这个函数是从 <code>sch_direct_xmit</code> 调用的。</p>
<h5 id="dev-requeue-skb"><a href="#dev-requeue-skb" class="headerlink" title="dev_requeue_skb"></a><code>dev_requeue_skb</code></h5><p>值得庆幸的是，<code>dev_requeue_skb</code> 的源代码很短，而且直截了当，来自 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L39-L57">.&#x2F;net&#x2F;sched&#x2F;sch_generic.c</a>：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* Modifications to data participating in scheduling must be protected with</span>
<span class="hljs-comment"> * qdisc_lock(qdisc) spinlock.</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> * The idea is the following:</span>
<span class="hljs-comment"> * - enqueue, dequeue are serialized via qdisc root lock</span>
<span class="hljs-comment"> * - ingress filtering is also serialized via qdisc root lock</span>
<span class="hljs-comment"> * - updates to tree and tree walking are only done under the rtnl mutex.</span>
<span class="hljs-comment"> */</span>

<span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title">dev_requeue_skb</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-keyword">struct</span> Qdisc *q)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-built_in">skb_dst_force</span>(skb);
        q-&gt;gso_skb = skb;
        q-&gt;qstats.requeues++;
        q-&gt;q.qlen++;        <span class="hljs-comment">/* it&#x27;s still part of the queue */</span>
        __netif_schedule(q);

        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
&#125;</code></pre>

<p>这个函数做了几件事：</p>
<ol>
<li>它强制增加 skb 引用计数。</li>
<li>它关联 skb 到 qdisc 的 <code>gso_skb</code> 字段。 回想一下，我们之前看到，在从 qdisc 的队列中取出数据之前，会在 <code>dequeue_skb</code> 中检查此字段。</li>
<li>增加统计计数器。</li>
<li>增加队列的大小。</li>
<li>调用 <code>__netif_schedule</code>。</li>
</ol>
<p>简单明了。 让我们回顾一下我们是如何到达这里的，然后探讨 <code>__netif_schedule</code>。</p>
<h4 id="提醒，-qdisc-run-中的-while-循环"><a href="#提醒，-qdisc-run-中的-while-循环" class="headerlink" title="提醒， __qdisc_run 中的 while 循环"></a>提醒， <code>__qdisc_run</code> 中的 while 循环</h4><p>回想一下，我们是检查函数  <code>__qdisc_run</code>  得出的这一点，该函数包含以下代码：</p>
<pre><code class="hljs c++"><span class="hljs-type">void</span> __qdisc_run(<span class="hljs-keyword">struct</span> Qdisc *q)
&#123;
        <span class="hljs-type">int</span> quota = weight_p;

        <span class="hljs-keyword">while</span> (<span class="hljs-built_in">qdisc_restart</span>(q)) &#123;
                <span class="hljs-comment">/*</span>
<span class="hljs-comment">                 * Ordered by possible occurrence: Postpone processing if</span>
<span class="hljs-comment">                 * 1. we&#x27;ve exceeded packet quota</span>
<span class="hljs-comment">                 * 2. another process needs the CPU;</span>
<span class="hljs-comment">                 */</span>
                <span class="hljs-keyword">if</span> (--quota &lt;= <span class="hljs-number">0</span> || <span class="hljs-built_in">need_resched</span>()) &#123;
                        __netif_schedule(q);
                        <span class="hljs-keyword">break</span>;
                &#125;
        &#125;

        <span class="hljs-built_in">qdisc_run_end</span>(q);
&#125;</code></pre>

<p>这段代码的工作原理是在一个循环中反复调用 <code>qdisc_restart</code>，在内部，它会使 skb 出队，并试图调用 <code>sch_direct_xmit</code> 来传输 skb，而 sch_direct_xmit 会调用 <code>dev_hard_start_xmit</code> 来执行实际的传输。 任何不能传输的内容都将在 <code>NET_TX</code> 软中断中重新排队以进行传输。</p>
<p>传输过程中的下一步是检查 <code>dev_hard_start_xmit</code>，以了解如何调用驱动程序来发送数据。 在此之前，我们应该研究 <code>__netif_schedule</code> 以完全理解 <code>__qdisc_run</code> 和 <code>dev_requeue_skb</code> 是如何工作的。</p>
<h5 id="netif-schedule"><a href="#netif-schedule" class="headerlink" title="__netif_schedule"></a><code>__netif_schedule</code></h5><p>让我们从 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L2127-L2146">.&#x2F;net&#x2F;core&#x2F;dev.c</a> 跳到 <code>__netif_schedule</code>：</p>
<pre><code class="hljs c++"><span class="hljs-type">void</span> __netif_schedule(<span class="hljs-keyword">struct</span> Qdisc *q)
&#123;
        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">test_and_set_bit</span>(__QDISC_STATE_SCHED, &amp;q-&gt;state))
                __netif_reschedule(q);
&#125;
<span class="hljs-built_in">EXPORT_SYMBOL</span>(__netif_schedule);</code></pre>

<p>此代码检查并设置 qdisc 状态的 <code>__QDISC_STATE_SCHED</code> 位。 如果该位被翻转（意味着它之前没有处于 <code>__QDISC_STATE_SCHED</code> 状态），代码将调用 <code>__netif_reschedule</code>，这并不长，但有非常有趣的附带作用。 我们来看一下：</p>
<pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> __netif_reschedule(<span class="hljs-keyword">struct</span> Qdisc *q)
&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">softnet_data</span> *sd;
        <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> flags;

        <span class="hljs-built_in">local_irq_save</span>(flags);
        sd = &amp;__get_cpu_var(softnet_data);
        q-&gt;next_sched = <span class="hljs-literal">NULL</span>;
        *sd-&gt;output_queue_tailp = q;
        sd-&gt;output_queue_tailp = &amp;q-&gt;next_sched;
        <span class="hljs-built_in">raise_softirq_irqoff</span>(NET_TX_SOFTIRQ);
        <span class="hljs-built_in">local_irq_restore</span>(flags);
&#125;</code></pre>

<p>此函数执行以下操作：</p>
<ol>
<li>保存当前的本地 IRQ 状态，并调用 <code>local_irq_save</code> 禁用 IRQ。</li>
<li>获取当前 CPU <code>softnet_data</code> 结构。</li>
<li>添加 qdisc 到 <code>softnet_data</code> 的输出队列。</li>
<li>触发 <code>NET_TX_SOFTIRQ</code> 软中断。</li>
<li>恢复 IRQ 状态并重新启用中断。</li>
</ol>
<p>你可以阅读我们之前关于网络栈接收端的文章，来了解更多关于 <a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#linux-network-device-subsystem"><code>softnet_data</code></a>  数据结构初始化的信息。</p>
<p>上面函数中的重要代码是：<code>raise_softirq_irqoff</code> 触发 <code>NET_TX_SOFTIRQ</code> 软中断。<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#softirqs">softirq 及其注册</a>也在我们的前一篇文章中介绍过。 简单地说，您可以认为软中断是内核线程，它们以非常高的优先级执行，并代表内核处理数据。 它们处理传入的网络数据，也处理传出的数据。</p>
<p>正如你在上一篇文章中看到的，<code>NET_TX_SOFTIRQ</code> 软中断注册了函数 <code>net_tx_action</code>。这意味着有一个内核线程在执行 <code>net_tx_action</code>。 该线程偶尔会暂停，<code>raise_softirq_irqoff</code> 会恢复它。让我们来看看 <code>net_tx_action</code> 是做什么的，这样我们就可以理解内核是如何处理传输请求的。</p>
<h5 id="net-tx-action"><a href="#net-tx-action" class="headerlink" title="net_tx_action"></a><code>net_tx_action</code></h5><p><code>net_tx_action</code> 函数位于 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3297-L3353">.&#x2F;net&#x2F;core&#x2F;dev.c</a> 文件中，它在运行时处理两个主要内容：</p>
<ol>
<li>执行 CPU 的 <code>softnet_data</code> 结构的完成队列。</li>
<li>执行 CPU 的 <code>softnet_data</code> 结构的输出队列。</li>
</ol>
<p>实际上，该函数的代码是两个大的 if 块。 让我们一次查看一个，同时记住这段代码是作为一个独立的内核线程在软中断上下文中执行的。 <code>net_tx_action</code> 的目的是在整个网络对战的传输侧执行不能在热点路径中执行的代码；工作被延迟，稍后由执行 <code>net_tx_action</code> 的线程进行处理。</p>
<h6 id="net-tx-action-完成队列"><a href="#net-tx-action-完成队列" class="headerlink" title="net_tx_action 完成队列"></a><code>net_tx_action</code> 完成队列</h6><p><code>softnet_data</code> 的完成队列只是一个等待释放的 skb 队列。 函数 <code>dev_kfree_skb_irq</code> 添加 skb 到队列中以便稍后释放。 设备驱动程序通常使用此选项来延迟释放已使用的 skb。 驱动程序希望延迟释放 skb 而不是简单地释放 skb，原因是释放内存可能需要时间，在某些实例（如 hardirq 处理程序）中，代码需要尽可能快地执行并返回。</p>
<p>看一下 <code>net_tx_action</code> 代码，它处理在完成队列上释放 skb：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (sd-&gt;completion_queue) &#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff</span> *clist;

        <span class="hljs-built_in">local_irq_disable</span>();
        clist = sd-&gt;completion_queue;
        sd-&gt;completion_queue = <span class="hljs-literal">NULL</span>;
        <span class="hljs-built_in">local_irq_enable</span>();

        <span class="hljs-keyword">while</span> (clist) &#123;
                <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff</span> *skb = clist;
                clist = clist-&gt;next;

                <span class="hljs-built_in">WARN_ON</span>(<span class="hljs-built_in">atomic_read</span>(&amp;skb-&gt;users));
                <span class="hljs-built_in">trace_kfree_skb</span>(skb, net_tx_action);
                __kfree_skb(skb);
        &#125;
&#125;</code></pre>

<p>如果完成队列有条目，<code>while</code> 循环将遍历 skb 的链表，并对每个 skb 调用 <code>__kfree_skb</code> 以释放它们的内存。 请记住，这段代码是在一个单独的“线程”中运行的，该线程名为 softirq – 它并不代表任何特定的用户程序运行。</p>
<h6 id="net-tx-action-输出队列"><a href="#net-tx-action-输出队列" class="headerlink" title="net_tx_action 输出队列"></a><code>net_tx_action</code> 输出队列</h6><p>输出队列的用途完全不同。 如前所述，调用 <code>__netif_reschedule</code> 添加数据到输出队列，该调用通常从 <code>__netif_schedule</code> 调用的。 到目前为止，在我们在两个实例中看到过调用了 <code>__netif_schedule</code>  函数：</p>
<ul>
<li><code>dev_requeue_skb</code>：正如我们所看到的，如果驱动程序报告错误码 <code>NETDEV_TX_BUSY</code> 或 CPU 冲突，则可以调用此函数。</li>
<li><code>__qdisc_run</code>：我们之前也看到过这个函数。 一旦超过配额或需要重新调度进程，它还会调用 <code>__netif_schedule</code>。</li>
</ul>
<p>在这两种情况下，都将调用 <code>__netif_schedule</code> 函数，该函数添加 qdisc 到 <code>softnet_data</code> 的输出队列中进行处理。 我将输出队列处理代码分成了三个块。 我们先来看看第一个：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (sd-&gt;output_queue) &#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Qdisc</span> *head;

        <span class="hljs-built_in">local_irq_disable</span>();
        head = sd-&gt;output_queue;
        sd-&gt;output_queue = <span class="hljs-literal">NULL</span>;
        sd-&gt;output_queue_tailp = &amp;sd-&gt;output_queue;
        <span class="hljs-built_in">local_irq_enable</span>();</code></pre>

<p>这个块只是确保输出队列上有 qdisc，如果有，它设置 <code>head</code> 为第一个条目，并移动队列的尾指针。</p>
<p>接下来，遍历 qdsics 列表的 <code>while</code> 循环开始：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">while</span> (head) &#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Qdisc</span> *q = head;
        <span class="hljs-type">spinlock_t</span> *root_lock;

        head = head-&gt;next_sched;

        root_lock = <span class="hljs-built_in">qdisc_lock</span>(q);
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">spin_trylock</span>(root_lock)) &#123;
                <span class="hljs-built_in">smp_mb__before_clear_bit</span>();
                <span class="hljs-built_in">clear_bit</span>(__QDISC_STATE_SCHED,
                          &amp;q-&gt;state);
                <span class="hljs-built_in">qdisc_run</span>(q);
                <span class="hljs-built_in">spin_unlock</span>(root_lock);</code></pre>

<p>上面的代码段向前移动头指针，并获得对 qdisc 锁的引用。<code>spin_trylock</code> 检查是否可以获得锁；注意，该调用是专门使用的，因为它不阻塞。 如果锁已经被持有，<code>spin_trylock</code> 将立即返回，而不是等待获得锁。</p>
<p>如果 <code>spin_trylock</code> 成功获得锁，则返回一个非零值。 在这种情况下，qdisc 的状态字段的<code>__QDISC_STATE_SCHED</code> 位翻转，<code>qdisc_run</code> 被调用，从而翻转 <code>__QDISC___STATE_RUNNING</code>位，并开始执行 <code>__qdisc_run</code>。</p>
<p>这很重要。这里发生的情况是，我们之前检查过的代表用户进行系统调用的处理循环，现在再次运行，但在 softirq 上下文中，因为此 qdisc 的 skb 传输无法传输。 这种区别很重要，因为它会影响您如何监控发送大量数据的应用程序的 CPU 使用情况。 让我换个方式说：</p>
<ul>
<li>程序的系统时间包括调用驱动程序以尝试发送数据所花费的时间，无论发送是否完成或驱动程序是否返回错误。</li>
<li>如果在驱动程序层发送不成功（例如，因为设备忙于发送其他内容），则添加 qdisc 到输出队列并稍后由 softirq 线程处理。 在这种情况下，将花费 softirq（si）时间来尝试传输您的数据。</li>
</ul>
<p>因此，发送数据所花费的总时间是与发送相关的系统调用的系统时间和 <code>NET_TX</code> 软中断的软中断时间的组合。</p>
<p>无论如何，上面的代码释放 qdisc 锁来完成。 如果上面获取锁的 <code>spin_trylock</code> 调用失败，则执行以下代码：</p>
<pre><code class="hljs c++">                &#125; <span class="hljs-keyword">else</span> &#123;
                        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">test_bit</span>(__QDISC_STATE_DEACTIVATED,
                                      &amp;q-&gt;state)) &#123;
                                __netif_reschedule(q);
                        &#125; <span class="hljs-keyword">else</span> &#123;
                                <span class="hljs-built_in">smp_mb__before_clear_bit</span>();
                                <span class="hljs-built_in">clear_bit</span>(__QDISC_STATE_SCHED,
                                          &amp;q-&gt;state);
                        &#125;
                &#125;
        &#125;
&#125;</code></pre>

<p>这段代码只在无法获得 qdisc 锁时执行，它处理两种情况。 两者之一：</p>
<ol>
<li>未停用 qdisc，但无法获取执行 <code>qdisc_run</code> 的锁。 所以，调用 <code>__netif_reschedule</code>。 在这里调用 <code>__netif_reschedule</code> 会将 qdisc 放回该函数当前出列的队列中。这允许在以后可能已经放弃锁时再次检查 qdisc。</li>
<li>qdisc 被标记为停用，确保 <code>__QDISC_STATE_SCHED</code> 状态标志也被清除。</li>
</ol>
<h4 id="最后，我们来看看我们的朋友-dev-hard-start-xmit"><a href="#最后，我们来看看我们的朋友-dev-hard-start-xmit" class="headerlink" title="最后，我们来看看我们的朋友 dev_hard_start_xmit"></a>最后，我们来看看我们的朋友 <code>dev_hard_start_xmit</code></h4><p>因此，我们已经遍历了整个网络栈，直到 <code>dev_hard_start_xmit</code>。 也许你是经 <code>sendmsg</code> 系统调用直接到达这里的，或者你是经 qdisc 上处理网络数据的 softirq 线程到达这里的。<code>dev_hard_start_xmit</code> 将向下调用设备驱动程序来实际执行传输操作。</p>
<p><code>dev_hard_start_xmit</code>函数处理两种主要情况：</p>
<ul>
<li>准备发送的网络数据，或</li>
<li>具有需要处理的分段卸载的网络数据。</li>
</ul>
<p>我们将看到这两种情况是如何处理的，从准备发送的网络数据开始。 让我们一起来看看（如下所示：<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L2541-L2652">.&#x2F;net&#x2F;code&#x2F;dev.c</a>：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">dev_hard_start_xmit</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-keyword">struct</span> net_device *dev,</span></span>
<span class="hljs-params"><span class="hljs-function">                        <span class="hljs-keyword">struct</span> netdev_queue *txq)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_device_ops</span> *ops = dev-&gt;netdev_ops;
        <span class="hljs-type">int</span> rc = NETDEV_TX_OK;
        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> skb_len;

        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(!skb-&gt;next)) &#123;
                <span class="hljs-type">netdev_features_t</span> features;

                <span class="hljs-comment">/*</span>
<span class="hljs-comment">                 * If device doesn&#x27;t need skb-&gt;dst, release it right now while</span>
<span class="hljs-comment">                 * its hot in this cpu cache</span>
<span class="hljs-comment">                 */</span>
                <span class="hljs-keyword">if</span> (dev-&gt;priv_flags &amp; IFF_XMIT_DST_RELEASE)
                        <span class="hljs-built_in">skb_dst_drop</span>(skb);

                features = <span class="hljs-built_in">netif_skb_features</span>(skb);</code></pre>

<p>这段代码首先 <code>ops</code> 获取设备驱动程序暴露的操作的引用。当需要驱动程序执行一些工作来传输数据时，将使用它。 代码检查 <code>skb-&gt;next</code> 以确保此数据不是数据链的一部分，该数据链已分段准备就绪，并继续执行两件事：</p>
<ol>
<li>首先，它检查设备是否设置了 <code>IFF_XMIT_DST_RELEASE</code> 标志。 此内核中的任何“真正的”以太网设备都不使用此标志。 但是，它被环回设备和其他一些软件设备使用。 如果启用此标志，则可以减少目标缓存条目的引用计数，因为驱动程序不需要它。</li>
<li>接下来，<code>netif_skb_features</code> 从设备获取特性标志，并根据数据的目的协议（<code>dev-&gt;protocol</code>）对它们进行一些修改。 例如，如果协议是设备可以校验和的协议，则标记 skb 为这样的协议。 VLAN 标记（如果已设置）也会导致其他功能标志翻转。</li>
</ol>
<p>接下来，将检查 VLAN 标记，如果设备无法卸载 VLAN 标记，则将在软件中<code>__vlan_put_tag</code> 来执行此操作：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">vlan_tx_tag_present</span>(skb) &amp;&amp;
    !<span class="hljs-built_in">vlan_hw_offload_capable</span>(features, skb-&gt;vlan_proto)) &#123;
        skb = __vlan_put_tag(skb, skb-&gt;vlan_proto,
                             <span class="hljs-built_in">vlan_tx_tag_get</span>(skb));
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(!skb))
                <span class="hljs-keyword">goto</span> out;

        skb-&gt;vlan_tci = <span class="hljs-number">0</span>;
&#125;</code></pre>

<p>接下来，将检查数据是否是封装卸载请求，例如，可能是 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Generic_Routing_Encapsulation">GRE</a>。 在这种情况下，更新功能标志，以包括可用的任何特定于设备的硬件封装功能：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* If encapsulation offload request, verify we are testing</span>
<span class="hljs-comment"> * hardware encapsulation features instead of standard</span>
<span class="hljs-comment"> * features for the netdev</span>
<span class="hljs-comment"> */</span>
<span class="hljs-keyword">if</span> (skb-&gt;encapsulation)
        features &amp;= dev-&gt;hw_enc_features;</code></pre>

<p>接下来，<code>netif_needs_gso</code> 来确定 skb 本身是否需要分段。 如果 skb 需要分段，但设备不支持，则 <code>netif_needs_gso</code> 将返回 <code>true</code> 指示分段应在软件中进行。 在本例中，调用<code>dev_gso_segment</code> 来执行分段，代码将跳转到 <code>gso</code> 来传输数据包。 稍后我们将看到 GSO 路径。</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">netif_needs_gso</span>(skb, features)) &#123;
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(<span class="hljs-built_in">dev_gso_segment</span>(skb, features)))
                <span class="hljs-keyword">goto</span> out_kfree_skb;
        <span class="hljs-keyword">if</span> (skb-&gt;next)
                <span class="hljs-keyword">goto</span> gso;
&#125;</code></pre>

<p>如果数据不需要分割，则处理一些其他情况。 第一：数据是否需要线性化？ 也就是说，如果数据分布在多个缓冲区中，设备是否可以支持发送网络数据，或者是否需要首先组合所有数据到单个线性缓冲区中？ 绝大多数网卡不需要在传输之前对数据进行线性化，因此在几乎所有情况下，这将被计算为 false 并跳过。</p>
<pre><code class="hljs c++"><span class="hljs-keyword">else</span> &#123;
              <span class="hljs-keyword">if</span> (<span class="hljs-built_in">skb_needs_linearize</span>(skb, features) &amp;&amp;
                  __skb_linearize(skb))
                      <span class="hljs-keyword">goto</span> out_kfree_skb;</code></pre>

<p>接下来提供了一个有用的注释，解释了下一个分支。 检查数据包以确定它是否仍需要校验和。 如果设备不支持校验和，则在软件中生成校验和：</p>
<pre><code class="hljs c++">        <span class="hljs-comment">/* If packet is not checksummed and device does not</span>
<span class="hljs-comment">         * support checksumming for this protocol, complete</span>
<span class="hljs-comment">         * checksumming here.</span>
<span class="hljs-comment">         */</span>
        <span class="hljs-keyword">if</span> (skb-&gt;ip_summed == CHECKSUM_PARTIAL) &#123;
                <span class="hljs-keyword">if</span> (skb-&gt;encapsulation)
                        <span class="hljs-built_in">skb_set_inner_transport_header</span>(skb,
                                <span class="hljs-built_in">skb_checksum_start_offset</span>(skb));
                <span class="hljs-keyword">else</span>
                        <span class="hljs-built_in">skb_set_transport_header</span>(skb,
                                <span class="hljs-built_in">skb_checksum_start_offset</span>(skb));
                <span class="hljs-keyword">if</span> (!(features &amp; NETIF_F_ALL_CSUM) &amp;&amp;
                     <span class="hljs-built_in">skb_checksum_help</span>(skb))
                        <span class="hljs-keyword">goto</span> out_kfree_skb;
        &#125;
&#125;</code></pre>

<p>现在我们继续讨论数据包抓取！回想一下，在 <a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#netifreceiveskbcore-special-box-delivers-data-to-packet-taps-and-protocol-layers">接收端博客文章</a> 中，我们看到了如何传递数据包给数据包抓取（例如 <a target="_blank" rel="noopener" href="http://www.tcpdump.org/manpages/pcap.3pcap.html">PCAP</a>）。此函数中的下一块代码将即将传输的数据包交给数据包抓取（如果有的话）。</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (!<span class="hljs-built_in">list_empty</span>(&amp;ptype_all))
        <span class="hljs-built_in">dev_queue_xmit_nit</span>(skb, dev);</code></pre>

<p>最后，驱动程序的 <code>ops</code> 调用 <code>ndo_start_xmit</code> 向下传递数据到设备：</p>
<pre><code class="hljs c++">        skb_len = skb-&gt;len;
        rc = ops-&gt;<span class="hljs-built_in">ndo_start_xmit</span>(skb, dev);

        <span class="hljs-built_in">trace_net_dev_xmit</span>(skb, rc, dev, skb_len);
        <span class="hljs-keyword">if</span> (rc == NETDEV_TX_OK)
                <span class="hljs-built_in">txq_trans_update</span>(txq);
        <span class="hljs-keyword">return</span> rc;
&#125;</code></pre>

<p>返回 <code>ndo_start_xmit</code> 的返回值，指示数据包是否被传输。 我们看到了这个返回值将如何影响上层：由该函数调用方的 QDisc 重新排队数据，以便它可以稍后再次传输。</p>
<p>让我们来看看 GSO 的案例。 如果 skb 已经由于在此函数中发生的分段，而被分离成一个数据包链，或者先前分段但未能发送并排队等待再次发送的数据包，则此代码将运行。</p>
<pre><code class="hljs c++">gso:
        <span class="hljs-keyword">do</span> &#123;
                <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff</span> *nskb = skb-&gt;next;

                skb-&gt;next = nskb-&gt;next;
                nskb-&gt;next = <span class="hljs-literal">NULL</span>;

                <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">list_empty</span>(&amp;ptype_all))
                        <span class="hljs-built_in">dev_queue_xmit_nit</span>(nskb, dev);

                skb_len = nskb-&gt;len;
                rc = ops-&gt;<span class="hljs-built_in">ndo_start_xmit</span>(nskb, dev);
                <span class="hljs-built_in">trace_net_dev_xmit</span>(nskb, rc, dev, skb_len);
                <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(rc != NETDEV_TX_OK)) &#123;
                        <span class="hljs-keyword">if</span> (rc &amp; ~NETDEV_TX_MASK)
                                <span class="hljs-keyword">goto</span> out_kfree_gso_skb;
                        nskb-&gt;next = skb-&gt;next;
                        skb-&gt;next = nskb;
                        <span class="hljs-keyword">return</span> rc;
                &#125;
                <span class="hljs-built_in">txq_trans_update</span>(txq);
                <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(<span class="hljs-built_in">netif_xmit_stopped</span>(txq) &amp;&amp; skb-&gt;next))
                        <span class="hljs-keyword">return</span> NETDEV_TX_BUSY;
        &#125; <span class="hljs-keyword">while</span> (skb-&gt;next);</code></pre>

<p>您可能已经猜到了，这段代码是一个 while 循环，它遍历在数据分段时生成的 skb 列表。</p>
<p>每个数据包：</p>
<ul>
<li>通过数据包抓取（如果有）。</li>
<li>通过 <code>ndo_start_xmit</code> 传递给驱动器进行传输。</li>
</ul>
<p>传输数据包中的任何错误都会调整需要发送的 skb 列表来处理。 错误将返回堆栈，未发送的 skb 可能会被重新排队，以便稍后再次发送。</p>
<p>此函数的最后一部分处理清理，并可能在出现上述错误时释放数据：</p>
<pre><code class="hljs c++">out_kfree_gso_skb:
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(skb-&gt;next == <span class="hljs-literal">NULL</span>)) &#123;
                skb-&gt;destructor = <span class="hljs-built_in">DEV_GSO_CB</span>(skb)-&gt;destructor;
                <span class="hljs-built_in">consume_skb</span>(skb);
                <span class="hljs-keyword">return</span> rc;
        &#125;
out_kfree_skb:
        <span class="hljs-built_in">kfree_skb</span>(skb);
out:
        <span class="hljs-keyword">return</span> rc;
&#125;
<span class="hljs-built_in">EXPORT_SYMBOL_GPL</span>(dev_hard_start_xmit);</code></pre>

<p>在继续讨论设备驱动程序之前，让我们看一下可以对我们刚刚浏览的代码进行的一些监控和调优。</p>
<h4 id="监控-qdiscs"><a href="#监控-qdiscs" class="headerlink" title="监控 qdiscs"></a>监控 qdiscs</h4><h5 id="使用-tc-命令行工具"><a href="#使用-tc-命令行工具" class="headerlink" title="使用 tc 命令行工具"></a>使用 <code>tc</code> 命令行工具</h5><p>使用 <code>tc</code> 监控您的 qdisc 统计数据</p>
<pre><code class="hljs bash">$ tc -s qdisc show dev eth1
qdisc mq 0: root
 Sent 31973946891907 bytes 2298757402 pkt (dropped 0, overlimits 0 requeues 1776429)
 backlog 0b 0p requeues 1776429</code></pre>

<p>为了监控系统的数据包传输状况，检查连接到网络设备的队列规则的统计信息至关重要。 您可以运行命令行工具 <code>tc</code> 来检查状态。 上面的示例显示了如何检查 <code>eth1</code> 接口的统计信息。</p>
<ul>
<li><code>bytes</code>：下推到驱动程序进行传输的字节数。</li>
<li><code>pkt</code>：下推到驱动程序进行传输的数据包数量。</li>
<li><code>dropped</code>：qdisc 丢弃的数据包数。 如果传输队列长度不足以容纳排队的数据，则可能发生这种情况。</li>
<li><code>overlimits</code>：取决于排队规则，但可以是由于达到限制而无法入队的数据包数量，和&#x2F;或在出队时触发节流事件的数据包数量。</li>
<li><code>requeues</code>：调用 <code>dev_requeue_skb</code> 重新排队 skb 的次数。 请注意，多次重新排队的 skb 将在每次重新排队时增加此计数器。</li>
<li><code>backlog</code>：当前在 qdisc 队列中的字节数。 这个数字通常在每次数据包入队时增加。</li>
</ul>
<p>某些 qdics 可能会导出其他统计信息。 每个 qdisc 是不同的，并且可以在不同的时间增加这些计数器。 您可能需要研究您正在使用的 qdisc 的源代码，以准确了解这些值何时可以在您的系统上增加，从而帮助了解对您的影响。</p>
<h4 id="调优-qdiscs"><a href="#调优-qdiscs" class="headerlink" title="调优 qdiscs"></a>调优 qdiscs</h4><h5 id="增加-qdisc-run"><a href="#增加-qdisc-run" class="headerlink" title="增加 __qdisc_run"></a>增加 <code>__qdisc_run</code></h5><p>您可以调整前面看到 <code>__qdisc_run</code> 循环的权重（上面看到的<code>quota</code>变量），这将导致执行更多<code>__netif_schedule</code> 的调用。 结果是当前 qdisc 更多次被添加到当前 CPU 的 <code>output_queue</code> 列表中，这应该会导致对传输数据包的额外处理。</p>
<p>示例：使用 <code>sysctl</code> 增加所有 qdisc 的 <code>__qdisc_run</code> 配额。</p>
<pre><code class="hljs bash">$ sudo sysctl -w net.core.dev_weight=600</code></pre>

<h5 id="增加传输队列长度"><a href="#增加传输队列长度" class="headerlink" title="增加传输队列长度"></a>增加传输队列长度</h5><p>每个网络设备都有一个可以修改的 <code>txqueuelen</code> 调节旋钮。大多数 qdisc 在对最终应由 qdisc 传输的数据排队时，都会检查设备是否具有足够的 <code>txqueuelen</code> 字节。您可以调整此参数以增加 qdisc 可排队的字节数。</p>
<p>示例：增加 <code>eth0</code> 的 <code>txqueuelen</code> 到 <code>10000</code>。</p>
<pre><code class="hljs bash">$ sudo ifconfig eth0 txqueuelen 10000</code></pre>

<p>以太网设备的默认值为 <code>1000</code>。 您可以读取 <code>ifconfig</code> 的输出来检查网络设备的  <code>txqueuelen</code>。</p>
<h3 id="网络设备驱动程序"><a href="#网络设备驱动程序" class="headerlink" title="网络设备驱动程序"></a>网络设备驱动程序</h3><p>我们的旅程就要结束了。 关于数据包传输有一个重要的概念需要理解。 大多数设备和驱动程序将数据包传输处理分为两步过程：</p>
<ol>
<li>数据被正确地排列，并且触发设备从 RAM DMA 写入数据到网络</li>
<li>传输完成后，设备引发中断，以便驱动程序可以取消缓冲区映射、释放内存或以其他方式清除其状态。</li>
</ol>
<p>第二阶段通常被称为“传输完成”阶段。 我们将研究这两个阶段，但我们将从第一阶段开始：传输阶段。</p>
<p>我们看到 <code>dev_hard_start_xmit</code> 调用了 <code>ndo_start_xmit</code>（持有锁）来传输数据，所以让我们从检查驱动程序如何注册 <code>ndo_start_xmit</code> 开始，然后我们将深入研究该函数如何工作。</p>
<p>和 <a target="_blank" rel="noopener" href="https://packagecloud.io/blog/illustrated-guide-monitoring-tuning-linux-networking-stack-receiving-data/">上一篇博文一样，</a> 我们将研究 <code>igb</code> 驱动程序。</p>
<h4 id="驱动操作注册"><a href="#驱动操作注册" class="headerlink" title="驱动操作注册"></a>驱动操作注册</h4><p>驱动程序为各种操作实现一系列功能，例如：</p>
<ul>
<li>发送数据（<code>ndo_start_xmit</code>）</li>
<li>获取统计信息（<code>ndo_get_stats64</code>）</li>
<li>处理设备 <code>ioctls</code>（<code>ndo_do_ioctl</code>）</li>
<li>还有更多。</li>
</ul>
<p>函数被导出为一系列排列在结构中的函数指针。 让我们来看看 <code>igb</code> <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L1905-L1928">驱动程序源代码</a>中这些操作的结构定义：</p>
<pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_device_ops</span> igb_netdev_ops = &#123;
        .ndo_open               = igb_open,
        .ndo_stop               = igb_close,
        .ndo_start_xmit         = igb_xmit_frame,
        .ndo_get_stats64        = igb_get_stats64,

				<span class="hljs-comment">/* ... more fields ... */</span>
&#125;;</code></pre>

<p>此结构在 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L2090"><code>igb_probe</code></a> 函数中注册：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title">igb_probe</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> pci_dev *pdev, <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> pci_device_id *ent)</span></span>
<span class="hljs-function"></span>&#123;
				<span class="hljs-comment">/* ... lots of other stuff ... */</span>

        netdev-&gt;netdev_ops = &amp;igb_netdev_ops;

				<span class="hljs-comment">/* ... more code ... */</span>
&#125;</code></pre>

<p>正如我们在上一节中看到的，更高层的代码将获得对设备的 <code>netdev_ops</code> 结构的引用，并调用相应的函数。 如果你想了解更多关于 PCI 设备是如何启动的，以及何时&#x2F;何地调用 <code>igb_probe</code> 的信息，请查看我们的其他博客文章中的<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#initialization">驱动程序初始化</a>部分。</p>
<h4 id="使用-ndo-start-xmit-传输数据"><a href="#使用-ndo-start-xmit-传输数据" class="headerlink" title="使用 ndo_start_xmit 传输数据"></a>使用 <code>ndo_start_xmit</code> 传输数据</h4><p>网络栈的较高层使用 <code>net_device_ops</code> 结构调用驱动程序来执行各种操作。 正如我们前面看到的，qdisc 代码调用 <code>ndo_start_xmit</code> 传递数据给驱动程序进行传输。 对于大多数硬件设备，<code>ndo_start_xmit</code> 函数在锁被持有时被调用，正如我们上面看到的。</p>
<p>在 <code>igb</code> 设备驱动程序中，注册到 <code>ndo_start_xmit</code> 称为 <code>igb_xmit_frame</code>，因此让我们从<code>igb_xmit_frame</code> 开始，了解此驱动程序如何传输数据。 进入 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L4664-L4741">.&#x2F;drivers&#x2F;net&#x2F;ethernet&#x2F;intel&#x2F;igb&#x2F;igb_main.c</a> ，并记住，在执行以下代码的整个过程中，都会持有一个锁：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">netdev_tx_t</span> <span class="hljs-title">igb_xmit_frame_ring</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb,</span></span>
<span class="hljs-params"><span class="hljs-function">                                <span class="hljs-keyword">struct</span> igb_ring *tx_ring)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">igb_tx_buffer</span> *first;
        <span class="hljs-type">int</span> tso;
        u32 tx_flags = <span class="hljs-number">0</span>;
        u16 count = <span class="hljs-built_in">TXD_USE_COUNT</span>(<span class="hljs-built_in">skb_headlen</span>(skb));
        __be16 protocol = <span class="hljs-built_in">vlan_get_protocol</span>(skb);
        u8 hdr_len = <span class="hljs-number">0</span>;

        <span class="hljs-comment">/* need: 1 descriptor per page * PAGE_SIZE/IGB_MAX_DATA_PER_TXD,</span>
<span class="hljs-comment">         *       + 1 desc for skb_headlen/IGB_MAX_DATA_PER_TXD,</span>
<span class="hljs-comment">         *       + 2 desc gap to keep tail from touching head,</span>
<span class="hljs-comment">         *       + 1 desc for context descriptor,</span>
<span class="hljs-comment">         * otherwise try next time</span>
<span class="hljs-comment">         */</span>
        <span class="hljs-keyword">if</span> (NETDEV_FRAG_PAGE_MAX_SIZE &gt; IGB_MAX_DATA_PER_TXD) &#123;
                <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> f;
                <span class="hljs-keyword">for</span> (f = <span class="hljs-number">0</span>; f &lt; <span class="hljs-built_in">skb_shinfo</span>(skb)-&gt;nr_frags; f++)
                        count += <span class="hljs-built_in">TXD_USE_COUNT</span>(<span class="hljs-built_in">skb_shinfo</span>(skb)-&gt;frags[f].size);
        &#125; <span class="hljs-keyword">else</span> &#123;
                count += <span class="hljs-built_in">skb_shinfo</span>(skb)-&gt;nr_frags;
        &#125;</code></pre>

<p>该函数开始使用 <code>TXD_USER_COUNT</code> 宏来确定需要多少个传输描述符来传输传入的数据。 <code>count</code> 值初始化为适合 skb 的描述符数量。 然后考虑需要传输的任何附加片段，对其进行调整。</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">igb_maybe_stop_tx</span>(tx_ring, count + <span class="hljs-number">3</span>)) &#123;
        <span class="hljs-comment">/* this is a hard error */</span>
        <span class="hljs-keyword">return</span> NETDEV_TX_BUSY;
&#125;</code></pre>

<p>然后驱动程序调用一个内部函数 <code>igb_maybe_stop_tx</code>，该函数检查所需的描述符数量，以确保传输队列有足够的可用资源。 如果没有，则在此处返回 <code>NETDEV_TX_BUSY</code>。 正如我们前面在 qdisc 代码中看到的，这将导致 qdisc 重新排队数据以便稍后重试。</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* record the location of the first descriptor for this packet */</span>
first = &amp;tx_ring-&gt;tx_buffer_info[tx_ring-&gt;next_to_use];
first-&gt;skb = skb;
first-&gt;bytecount = skb-&gt;len;
first-&gt;gso_segs = <span class="hljs-number">1</span>;</code></pre>

<p>然后，代码获得对传输队列中的下一个可用缓冲区信息的引用。 此结构将跟踪稍后设置缓冲区描述符所需的信息。 对数据包的引用及其大小被复制到缓冲区信息结构中。</p>
<pre><code class="hljs c++"><span class="hljs-built_in">skb_tx_timestamp</span>(skb);</code></pre>

<p>上面的代码调用 <code>skb_tx_timestamp</code> 获得基于软件的发送时间戳。 应用程序可以使用发送时间戳来确定数据包通过网络栈的传输路径所花费的时间量。</p>
<p>一些设备还支持为在硬件中传输的数据包生成时间戳。 这允许系统卸载时间戳到设备，并且它允许程序员获得更准确的时间戳，因为它将更接近硬件的实际传输发生的时间。 现在我们来看看这段代码：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(<span class="hljs-built_in">skb_shinfo</span>(skb)-&gt;tx_flags &amp; SKBTX_HW_TSTAMP)) &#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">igb_adapter</span> *adapter = <span class="hljs-built_in">netdev_priv</span>(tx_ring-&gt;netdev);

        <span class="hljs-keyword">if</span> (!(adapter-&gt;ptp_tx_skb)) &#123;
                <span class="hljs-built_in">skb_shinfo</span>(skb)-&gt;tx_flags |= SKBTX_IN_PROGRESS;
                tx_flags |= IGB_TX_FLAGS_TSTAMP;

                adapter-&gt;ptp_tx_skb = <span class="hljs-built_in">skb_get</span>(skb);
                adapter-&gt;ptp_tx_start = jiffies;
                <span class="hljs-keyword">if</span> (adapter-&gt;hw.mac.type == e1000_82576)
                        <span class="hljs-built_in">schedule_work</span>(&amp;adapter-&gt;ptp_tx_work);
        &#125;
&#125;</code></pre>

<p>一些网络设备可以使用<a target="_blank" rel="noopener" href="https://events.linuxfoundation.org/sites/events/files/slides/lcjp14_ichikawa_0.pdf">精确时间协议</a>在硬件中对数据包加时间戳。 当用户请求硬件时间戳时，驱动程序代码将在此处处理此问题。</p>
<p>上面的 <code>if</code> 语句检查 <code>SKBTX_HW_TSTAMP</code> 标志。 此标志指示用户请求了硬件时间戳。 如果用户请求了硬件时间戳，代码接下来检查是否设置 <code>ptp_tx_skb</code>。 一次可以对一个数据包加时间戳，，因此在此处获取正在进行时间戳的数据包的引用，并在 skb 上设置 <code>SKBTX_IN_PROGRESS</code> 标志。 更新 <code>tx_flags</code> 以标记 <code>IGB_TX_FLAGS_TSTAMP</code> 标志。 变量稍后复制 <code>tx_flags</code> 到 buffer info 结构中。</p>
<p>获取 skb 的引用，复制当前 jiffies 计数到 <code>ptp_tx_start</code>。驱动程序中的其他代码将使用此值来确保 TX 硬件时间戳不会挂起。最后，如果这是一个 <code>82576</code> 以太网硬件适配器，则使用 <code>schedule_work</code> 函数来启动 <a target="_blank" rel="noopener" href="http://www.makelinux.net/ldd3/chp-7-sect-6">工作队列</a>。</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">vlan_tx_tag_present</span>(skb)) &#123;
        tx_flags |= IGB_TX_FLAGS_VLAN;
        tx_flags |= (<span class="hljs-built_in">vlan_tx_tag_get</span>(skb) &lt;&lt; IGB_TX_FLAGS_VLAN_SHIFT);
&#125;</code></pre>

<p>上面的代码检查是否设置了 skb 的 <code>vlan_tci</code> 字段。 如果已设置，则启用<code>IGB_TX_FLAGS_VLAN</code> 标志并存储 vlan ID。</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* record initial flags and protocol */</span>
first-&gt;tx_flags = tx_flags;
first-&gt;protocol = protocol;</code></pre>

<p>标志和协议被记录到缓冲区信息结构。</p>
<pre><code class="hljs c++">tso = <span class="hljs-built_in">igb_tso</span>(tx_ring, first, &amp;hdr_len);
<span class="hljs-keyword">if</span> (tso &lt; <span class="hljs-number">0</span>)
        <span class="hljs-keyword">goto</span> out_drop;
<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!tso)
        <span class="hljs-built_in">igb_tx_csum</span>(tx_ring, first);</code></pre>

<p>接下来，驱动程序调用其内部函数 <code>igb_tso</code>。 此函数确定 skb 是否需要分段。 如果是，则缓冲器信息引用（<code>first</code>）更新其标志以向硬件指示需要 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Large_segment_offload">TSO</a>。</p>
<p>如果 tso 不必要，<code>igb_tso</code> 将返回 <code>0</code>，否则返回 <code>1</code>。 如果返回 <code>0</code>，<code>igb_tx_csum</code> 来处理启用校验和卸载（如果需要并且该协议支持）。 <code>igb_tx_csum</code> 函数检查 skb 的属性，并首先翻转 缓冲区 <code>first</code> 中的一些标志位，以指示需要卸载校验和。</p>
<pre><code class="hljs c++"><span class="hljs-built_in">igb_tx_map</span>(tx_ring, first, hdr_len);</code></pre>

<p>调用 <code>igb_tx_map</code> 函数来准备设备要消耗的数据以进行传输。 接下来我们将详细研究这个函数。</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* Make sure there is space in the ring for the next send. */</span>
<span class="hljs-built_in">igb_maybe_stop_tx</span>(tx_ring, DESC_NEEDED);

<span class="hljs-keyword">return</span> NETDEV_TX_OK;</code></pre>

<p>传输完成后，驱动程序进行检查，以确保有足够的空间可用于另一次传输。 如果没有，则关闭队列。 在任何一种情况下，<code>NETDEV_TX_OK</code> 都会返回到更高层（qdisc 代码）。</p>
<pre><code class="hljs c++">out_drop:
        <span class="hljs-built_in">igb_unmap_and_free_tx_resource</span>(tx_ring, first);

        <span class="hljs-keyword">return</span> NETDEV_TX_OK;
&#125;</code></pre>

<p>最后是一些错误处理代码。 这段代码只在 <code>igb_tso</code> 遇到某种错误时才被命中。 <code>igb_unmap_and_free_tx_resource</code> 清理数据。在这种情况下也返回 <code>NETDEV_TX_OK</code>。 传输不成功，但驱动程序释放了关联的资源，没有什么可做的了。 请注意，在这种情况下，此驱动程序不会增加数据包丢弃，但它可能应该这样做。</p>
<h4 id="igb-tx-map"><a href="#igb-tx-map" class="headerlink" title="igb_tx_map"></a><code>igb_tx_map</code></h4><p><code>igb_tx_map</code>函数处理映射 skb 数据到 RAM 的可 DMA 区域的细节。 它还更新设备上的传输队列的尾指针，这是触发设备“唤醒”、从 RAM 获取数据，并开始传输数据。</p>
<p>让我们简单地看看<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L4501-L4627">这个函数</a>是如何工作的：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title">igb_tx_map</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> igb_ring *tx_ring,</span></span>
<span class="hljs-params"><span class="hljs-function">                       <span class="hljs-keyword">struct</span> igb_tx_buffer *first,</span></span>
<span class="hljs-params"><span class="hljs-function">                       <span class="hljs-type">const</span> u8 hdr_len)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sk_buff</span> *skb = first-&gt;skb;

				<span class="hljs-comment">/* ... other variables ... */</span>

        u32 tx_flags = first-&gt;tx_flags;
        u32 cmd_type = <span class="hljs-built_in">igb_tx_cmd_type</span>(skb, tx_flags);
        u16 i = tx_ring-&gt;next_to_use;

        tx_desc = <span class="hljs-built_in">IGB_TX_DESC</span>(tx_ring, i);

        <span class="hljs-built_in">igb_tx_olinfo_status</span>(tx_ring, tx_desc, tx_flags, skb-&gt;len - hdr_len);

        size = <span class="hljs-built_in">skb_headlen</span>(skb);
        data_len = skb-&gt;data_len;

        dma = <span class="hljs-built_in">dma_map_single</span>(tx_ring-&gt;dev, skb-&gt;data, size, DMA_TO_DEVICE);</code></pre>

<p>上面的代码做了几件事：</p>
<ol>
<li>声明一组变量并初始化它们。</li>
<li>使用 <code>IGB_TX_DESC</code>宏确定获取下一个可用描述符的引用。</li>
<li><code>igb_tx_olinfo_status</code> 更新 <code>tx_flags</code> 并复制其到描述符（<code>tx_desc</code>）中。</li>
<li>捕获大小和数据长度，以便稍后使用。</li>
<li><code>dma_map_single</code>  构造获得 <code>skb-&gt;data</code> 数据的 DMA 可访问地址所需的任何内存映射。 这样做使得设备可以从存储器读取数据包数据。</li>
</ol>
<p>接下来是驱动程序中的一个非常密集的循环，为 skb 的每个片段生成有效的映射。 具体如何发生这种情况的细节并不特别重要，但值得一提：</p>
<ul>
<li>驱动程序遍历数据包片段的集合。</li>
<li>当前描述符中填入数据的 DMA 地址。</li>
<li>如果片段的大小大于单个IGB描述符可以传输的大小，则构造多个描述符以指向可DMA区域的块，直到描述符指向整个片段。</li>
<li>增加描述符迭代器。</li>
<li>减少剩余长度。</li>
<li>当出现以下情况时，循环终止：没有剩余片段或者整个数据长度已经被消耗。</li>
</ul>
<p>以下提供循环的代码，以供参考以上描述。 这应该进一步向读者说明，如果可能的话，避免碎片化是一个好主意。 需要在堆栈的每一层运行大量额外的代码来处理它，包括驱动程序。</p>
<pre><code class="hljs c++">tx_buffer = first;

<span class="hljs-keyword">for</span> (frag = &amp;<span class="hljs-built_in">skb_shinfo</span>(skb)-&gt;frags[<span class="hljs-number">0</span>];; frag++) &#123;
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">dma_mapping_error</span>(tx_ring-&gt;dev, dma))
                <span class="hljs-keyword">goto</span> dma_error;

        <span class="hljs-comment">/* record length, and DMA address */</span>
        <span class="hljs-built_in">dma_unmap_len_set</span>(tx_buffer, len, size);
        <span class="hljs-built_in">dma_unmap_addr_set</span>(tx_buffer, dma, dma);

        tx_desc-&gt;read.buffer_addr = <span class="hljs-built_in">cpu_to_le64</span>(dma);

        <span class="hljs-keyword">while</span> (<span class="hljs-built_in">unlikely</span>(size &gt; IGB_MAX_DATA_PER_TXD)) &#123;
                tx_desc-&gt;read.cmd_type_len =
                        <span class="hljs-built_in">cpu_to_le32</span>(cmd_type ^ IGB_MAX_DATA_PER_TXD);

                i++;
                tx_desc++;
                <span class="hljs-keyword">if</span> (i == tx_ring-&gt;count) &#123;
                        tx_desc = <span class="hljs-built_in">IGB_TX_DESC</span>(tx_ring, <span class="hljs-number">0</span>);
                        i = <span class="hljs-number">0</span>;
                &#125;
                tx_desc-&gt;read.olinfo_status = <span class="hljs-number">0</span>;

                dma += IGB_MAX_DATA_PER_TXD;
                size -= IGB_MAX_DATA_PER_TXD;

                tx_desc-&gt;read.buffer_addr = <span class="hljs-built_in">cpu_to_le64</span>(dma);
        &#125;

        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(!data_len))
                <span class="hljs-keyword">break</span>;

        tx_desc-&gt;read.cmd_type_len = <span class="hljs-built_in">cpu_to_le32</span>(cmd_type ^ size);

        i++;
        tx_desc++;
        <span class="hljs-keyword">if</span> (i == tx_ring-&gt;count) &#123;
                tx_desc = <span class="hljs-built_in">IGB_TX_DESC</span>(tx_ring, <span class="hljs-number">0</span>);
                i = <span class="hljs-number">0</span>;
        &#125;
        tx_desc-&gt;read.olinfo_status = <span class="hljs-number">0</span>;

        size = <span class="hljs-built_in">skb_frag_size</span>(frag);
        data_len -= size;

        dma = <span class="hljs-built_in">skb_frag_dma_map</span>(tx_ring-&gt;dev, frag, <span class="hljs-number">0</span>,
                               size, DMA_TO_DEVICE);

        tx_buffer = &amp;tx_ring-&gt;tx_buffer_info[i];
&#125;</code></pre>

<p>一旦所有必要的描述符都已构建，并且所有 skb 的数据都已映射到 DMA 地址，驱动程序将继续执行其最后步骤以触发传输：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* write last descriptor with RS and EOP bits */</span>
cmd_type |= size | IGB_TXD_DCMD;
tx_desc-&gt;read.cmd_type_len = <span class="hljs-built_in">cpu_to_le32</span>(cmd_type);</code></pre>

<p>写入终止描述符以向设备指示它是最后一个描述符。</p>
<pre><code class="hljs c++"><span class="hljs-built_in">netdev_tx_sent_queue</span>(<span class="hljs-built_in">txring_txq</span>(tx_ring), first-&gt;bytecount);

<span class="hljs-comment">/* set the timestamp */</span>
first-&gt;time_stamp = jiffies;</code></pre>

<p>调用 <code>netdev_tx_sent_queue</code> 函数时，会添加字节数到此传输队列。 这个函数是字节查询限制特性的一部分，我们稍后会详细介绍。 当前 jiffies 被存储在第一缓冲器信息结构中。</p>
<p>接下来，有一点棘手：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* Force memory writes to complete before letting h/w know there</span>
<span class="hljs-comment"> * are new descriptors to fetch.  (Only applicable for weak-ordered</span>
<span class="hljs-comment"> * memory model archs, such as IA-64).</span>
<span class="hljs-comment"> *</span>
<span class="hljs-comment"> * We also need this memory barrier to make certain all of the</span>
<span class="hljs-comment"> * status bits have been updated before next_to_watch is written.</span>
<span class="hljs-comment"> */</span>
<span class="hljs-built_in">wmb</span>();

<span class="hljs-comment">/* set next_to_watch value indicating a packet is present */</span>
first-&gt;next_to_watch = tx_desc;

i++;
<span class="hljs-keyword">if</span> (i == tx_ring-&gt;count)
        i = <span class="hljs-number">0</span>;

tx_ring-&gt;next_to_use = i;

<span class="hljs-built_in">writel</span>(i, tx_ring-&gt;tail);

<span class="hljs-comment">/* we need this if more than one processor can write to our tail</span>
<span class="hljs-comment"> * at a time, it synchronizes IO on IA64/Altix systems</span>
<span class="hljs-comment"> */</span>
<span class="hljs-built_in">mmiowb</span>();

<span class="hljs-keyword">return</span>;</code></pre>

<p>上面的代码正在执行一些重要的操作：</p>
<ol>
<li>首先调用 <code>wmb</code> 函数强制完成内存写入。这将作为适用于 CPU 平台的特殊指令执行，通常称为“写屏障”。这在某些 CPU 架构上很重要，因为如果我们在没有确保所有更新内部状态的内存写入都已完成之前触发设备启动 DMA，则设备可能会从 RAM 中读取不一致状态的数据。<a target="_blank" rel="noopener" href="http://preshing.com/20120930/weak-vs-strong-memory-models/">这篇文章</a> 和这个 <a target="_blank" rel="noopener" href="http://www.cs.utexas.edu/~pingali/CS378/2012fa/lectures/consistency.pdf">讲座</a> 深入探讨了有关内存排序的细节。</li>
<li>设置 <code>next_to_watch</code> 字段。它将在完成阶段后使用。</li>
<li>增加计数器，并更新传输队列的 <code>next_to_use</code> 字段为下一个可用描述符。</li>
<li>使用 <code>writel</code> 函数更新传输队列的尾部。<code>writel</code> 将一个 “long” 写入 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Memory-mapped_I/O">内存映射 I&#x2F;O</a> 地址。在这种情况下，地址是 <code>tx_ring-&gt;tail</code>（这是一个硬件地址），要写入的值是 <code>i</code>。此写入会触发设备，让它知道有更多数据准备好从 RAM 进行 DMA 并写入网络。</li>
<li>最后，调用 <code>mmiowb</code> 函数。此函数将执行适用于 CPU 架构的指令，使内存映射写入操作有序。它也是一个写屏障，但用于内存映射 I&#x2F;O 写入。</li>
</ol>
<p>如果您想了解更多关于 <code>wmb</code>、<code>mmiowb</code> 以及何时使用它们，可以阅读 Linux 内核中包含的一些出色的 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/Documentation/memory-barriers.txt">关于内存屏障的文档</a>。</p>
<p>最后，只有当从 DMA API 返回错误时（当尝试映射 skb 数据地址到可 DMA 地址时），才会执行此代码。</p>
<pre><code class="hljs c++">dma_error:
        <span class="hljs-built_in">dev_err</span>(tx_ring-&gt;dev, <span class="hljs-string">&quot;TX DMA map failed\n&quot;</span>);

        <span class="hljs-comment">/* clear dma mappings for failed tx_buffer_info map */</span>
        <span class="hljs-keyword">for</span> (;;) &#123;
                tx_buffer = &amp;tx_ring-&gt;tx_buffer_info[i];
                <span class="hljs-built_in">igb_unmap_and_free_tx_resource</span>(tx_ring, tx_buffer);
                <span class="hljs-keyword">if</span> (tx_buffer == first)
                        <span class="hljs-keyword">break</span>;
                <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span>)
                        i = tx_ring-&gt;count;
                i--;
        &#125;

        tx_ring-&gt;next_to_use = i;</code></pre>

<p>在继续传输完成之前，让我们检查一下上面传递的内容：动态队列限制。</p>
<h5 id="动态队列限制（DQL）"><a href="#动态队列限制（DQL）" class="headerlink" title="动态队列限制（DQL）"></a>动态队列限制（DQL）</h5><p>正如你在这篇文章中看到的那样，随着网络数据越来越靠近传输设备，它会在不同阶段花费大量时间排队。随着队列大小的增加，数据包在未传输的队列中停留的时间更长，即数据包传输延迟随着队列大小增加而增加。</p>
<p>对抗这种情况的一种方法是背压。动态队列限制（DQL）系统是一种机制，设备驱动程序可以使用该机制向网络系统施加背压，</p>
<p>要使用此系统，网络设备驱动程序需要在其传输和完成例程期间进行一些简单的 API 调用。 DQL 系统内部使用一种算法来确定何时有足够的数据传输。 一旦达到此限制，传输队列将暂时禁用。 这种队列禁用是对网络系统产生背压的原因。当DQL系统确定有足够的数据完成传输时，队列将自动重新启用。</p>
<p>查看这组<a target="_blank" rel="noopener" href="https://www.linuxplumbersconf.org/2012/wp-content/uploads/2012/08/bql_slide.pdf">关于 DQL 系统的优秀幻灯片</a>，了解一些性能数据和 DQL 内部算法的解释。</p>
<p>我们刚才看到的代码中调用的函数 <code>netdev_tx_sent_queue</code> 是 DQL API 的一部分。 当数据排队到设备进行传输时，会调用此函数。 传输完成后，驱动程序调用 就会调用 <code>netdev_tx_completed_queue</code>。 在内部，这两个函数都将调用 DQL 库（位于 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/lib/dynamic_queue_limits.c">.&#x2F;lib&#x2F;dynamic_queue_limits.c</a> 和 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/include/linux/dynamic_queue_limits.h">.&#x2F;include&#x2F;linux&#x2F;dynamic_queue_limits.h</a> 中），以确定传输队列是否应该被禁用、重新启用或保持原样。</p>
<p>DQL 在 sysfs 中导出统计信息和调优旋钮。 调优 DQL 应该是不必要的；该算法将随时间调整其参数。 不过，为了完整起见，我们将在后面看到如何监控和调优 DQL。</p>
<h4 id="传输完成"><a href="#传输完成" class="headerlink" title="传输完成"></a>传输完成</h4><p>一旦设备传输了数据，它将产生一个中断信号，表示传输完成。 然后设备驱动程序可以安排一些长时间运行的工作来完成，比如取消映射内存区域和释放数据。 具体如何工作取决于设备。 在 <code>igb</code> 驱动程序（及其相关设备）的情况下，发射相同的 IRQ 以完成传输和接收数据包。 这意味着对于 <code>igb</code> 驱动程序，<code>NET_RX</code> 处理发送完成和传入数据包接收。</p>
<p>让我重申这一点，以强调其重要性：您的设备可能会在接收数据包时发出与发送数据包完成信号相同的中断。如果是，<code>NET_RX</code> 软中断将运行处理传入数据包和传输完成。</p>
<p>由于两个操作共享同一个 IRQ，因此只能注册一个 IRQ 处理函数，并且它必须处理两种可能的情况。 当接收到网络数据时，调用以下流程：</p>
<ol>
<li>接收网络数据。</li>
<li>网络设备引发 IRQ。</li>
<li>设备驱动程序的 IRQ 处理程序执行，清除 IRQ 并确保 <a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#softirqs">softIRQ</a> 被调度运行（如果尚未运行）。 这里触发的软中断是 <code>NET_RX</code> 软中断。</li>
<li>软中断本质上是作为一个单独的内核线程执行的。 它运行并实现 <a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#napi">NAPI</a> 轮询循环。</li>
<li>NAPI 轮询循环只是一段代码，只要有足够的预算，它就在循环中执行，收集数据包。</li>
<li>每次处理数据包时，预算都会减少，直到没有更多的数据包要处理，预算达到 0，或者时间片到期为止。</li>
</ol>
<p><code>igb</code> 驱动程序（和 <code>ixgbe</code> 驱动程序[greetings，tyler]）中的上述步骤 5 在处理传入数据之前处理传输完成。 请记住，根据驱动程序的实现，传输完成和传入数据的处理功能可能共享相同的处理预算。 <code>igb</code> 和 <code>ixgbe</code> 驱动器分别跟踪传输完成和传入数据包预算，因此处理传输完成将不一定耗尽传入预算。</p>
<p>也就是说，整个 NAPI 轮询循环<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#netrxaction-processing-loop">在硬编码的时间片内运行</a>。 这意味着，如果要处理大量的传输完成处理，传输完成可能会比处理传入数据占用更多的时间片。 对于那些在非常高的负载环境中运行网络硬件的人来说，这可能是一个重要的考虑因素。</p>
<p>让我们看看 <code>igb</code> 驱动程序在实践中是如何做到这一点的。</p>
<h5 id="传输完成-IRQ"><a href="#传输完成-IRQ" class="headerlink" title="传输完成 IRQ"></a>传输完成 IRQ</h5><p>这篇文章将不再重复<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/">Linux 内核接收端网络博客文章</a>中已经涵盖的信息，而是按顺序列出步骤，并链接到接收端博客文章中的相应部分，直到传输完成。</p>
<p>所以，让我们从头开始：</p>
<ol>
<li>网络设备<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#bringing-a-network-device-up">启动</a>。</li>
<li><a href="https%EF%BC%9A//packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#register-an-interrupt-handler">IRQ 处理程序已注册</a>。</li>
<li>用户程序发送数据到网络套接字。 数据在网络栈中传输，直到设备从内存中获取数据并将其传输。</li>
<li>设备完成数据传输并引发 IRQ 以通知传输完成。</li>
<li>驱动程序的<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#interrupt-handler">IRQ 处理程序执行以处理中断</a>。</li>
<li>IRQ 处理程序调用 <code>napi_schedule</code> 来响应 IRQ。</li>
<li><a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#napi-and-napischedule">NAPI 代码</a> 触发 <code>NET_RX</code> 软中断执行。</li>
<li><code>NET_RX</code> 软中断函数 <code>net_rx_action</code> <a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#network-data-processing-begins">开始执行</a>。</li>
<li><code>net_rx_action</code> 函数调用<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#napi-poll-function-and-weight">驱动程序注册的 NAPI 轮询函数</a>。</li>
<li><a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#igbpoll">执行</a> NAPI 轮询函数 <code>igb_poll</code>。</li>
</ol>
<p>轮询函数 <code>igb_poll</code> 是代码分离并处理传入数据包和传输完成的地方。 让我们深入研究这个函数的代码，看看它在哪里发生的。</p>
<h5 id="igb-poll"><a href="#igb-poll" class="headerlink" title="igb_poll"></a><code>igb_poll</code></h5><p>让我们来看看 <code>igb_poll</code>（来自 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L5987-L6018">.&#x2F;drivers&#x2F;net&#x2F;ethernet&#x2F;intel&#x2F;igb&#x2F;igb_main.c</a>）：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/**</span>
<span class="hljs-comment"> *  igb_poll - NAPI Rx polling callback</span>
<span class="hljs-comment"> *  @napi: napi polling structure</span>
<span class="hljs-comment"> *  @budget: count of how many packets we should handle</span>
<span class="hljs-comment"> **/</span>
<span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title">igb_poll</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> napi_struct *napi, <span class="hljs-type">int</span> budget)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">igb_q_vector</span> *q_vector = <span class="hljs-built_in">container_of</span>(napi,
                                                     <span class="hljs-keyword">struct</span> igb_q_vector,
                                                     napi);
        <span class="hljs-type">bool</span> clean_complete = <span class="hljs-literal">true</span>;

<span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> CONFIG_IGB_DCA</span>
        <span class="hljs-keyword">if</span> (q_vector-&gt;adapter-&gt;flags &amp; IGB_FLAG_DCA_ENABLED)
                <span class="hljs-built_in">igb_update_dca</span>(q_vector);
<span class="hljs-meta">#<span class="hljs-keyword">endif</span></span>
        <span class="hljs-keyword">if</span> (q_vector-&gt;tx.ring)
                clean_complete = <span class="hljs-built_in">igb_clean_tx_irq</span>(q_vector);

        <span class="hljs-keyword">if</span> (q_vector-&gt;rx.ring)
                clean_complete &amp;= <span class="hljs-built_in">igb_clean_rx_irq</span>(q_vector, budget);

        <span class="hljs-comment">/* If all work not completed, return budget and keep polling */</span>
        <span class="hljs-keyword">if</span> (!clean_complete)
                <span class="hljs-keyword">return</span> budget;

        <span class="hljs-comment">/* If not enough Rx work done, exit the polling mode */</span>
        <span class="hljs-built_in">napi_complete</span>(napi);
        <span class="hljs-built_in">igb_ring_irq_enable</span>(q_vector);

        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
&#125;</code></pre>

<p>此函数执行几个操作，顺序如下：</p>
<ol>
<li>如果在内核中启用了<a target="_blank" rel="noopener" href="https://lwn.net/Articles/247493/">直接缓存访问（DCA）</a>支持，则 CPU 缓存将预热，以便对 RX 环的访问将命中 CPU 缓存。 您可以在接收端网络帖子的附加部分<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#direct-cache-access-dca">阅读有关 DCA 的更多信息</a>。</li>
<li>调用 <code>igb_clean_tx_irq</code>，执行发送完成操作。</li>
<li>接下来调用 <code>igb_clean_rx_irq</code>，其执行传入数据包处理。</li>
<li>最后，检查 <code>clean_complete</code> 以确定是否还有更多的工作可以完成。 如果是，则返回<code>budget</code>。 如果发生这种情况，<code>net_rx_action</code> 移动这个 NAPI 结构到轮询列表的末尾，以便稍后再次处理。</li>
</ol>
<p>要了解更多关于 <code>igb_clean_rx_irq</code> 工作原理，请阅读上一篇博客文章的<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#igbcleanrxirq">这一部分</a>。</p>
<p>这篇博客文章主要关注发送端，所以我们将继续研究上面的 <code>igb_clean_tx_irq</code> 是如何工作的。</p>
<h5 id="igb-clean-tx-irq"><a href="#igb-clean-tx-irq" class="headerlink" title="igb_clean_tx_irq"></a><code>igb_clean_tx_irq</code></h5><p>请查看 <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/drivers/net/ethernet/intel/igb/igb_main.c#L6020-L6189">.&#x2F;drivers&#x2F;net&#x2F;ethernet&#x2F;intel&#x2F;igb&#x2F;igb_main.c</a> 中此函数的源代码。</p>
<p>它有点长，所以我们把它分成块并研究它：</p>
<pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">bool</span> <span class="hljs-title">igb_clean_tx_irq</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> igb_q_vector *q_vector)</span></span>
<span class="hljs-function"></span>&#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">igb_adapter</span> *adapter = q_vector-&gt;adapter;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">igb_ring</span> *tx_ring = q_vector-&gt;tx.ring;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">igb_tx_buffer</span> *tx_buffer;
        <span class="hljs-keyword">union</span> <span class="hljs-title class_">e1000_adv_tx_desc</span> *tx_desc;
        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> total_bytes = <span class="hljs-number">0</span>, total_packets = <span class="hljs-number">0</span>;
        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> budget = q_vector-&gt;tx.work_limit;
        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = tx_ring-&gt;next_to_clean;

        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">test_bit</span>(__IGB_DOWN, &amp;adapter-&gt;state))
                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;</code></pre>

<p>该函数首先初始化一些有用的变量。 一个重要的考虑因素是 <code>budget</code>。 正如你在上面看到的<code>budget</code> 被初始化为这个队列的 <code>tx.work_limit</code>。 在 <code>igb</code> 驱动程序中，<code>tx.work_limit</code> 被初始化为硬编码值 <code>IGB_DEFAULT_TX_WORK</code>（128）。</p>
<p>值得注意的是，虽然我们现在看到的传输完成代码与接收处理在相同的 <code>NET_RX</code> 软中断中运行，但 TX 和 RX 函数在 <code>igb</code> 驱动程序中并不共享处理预算 。由于整个 poll 函数在相同的<a target="_blank" rel="noopener" href="https://packagecloud.io/blog/monitoring-tuning-linux-networking-stack-receiving-data/#netrxaction-processing-loop">时间片</a>内运行，因此单次运行 <code>igb_poll</code> 函数不可能使传入的数据包处理或传输完成饿死。只要调用<code>igb_poll</code>，两者都会被处理。</p>
<p>接下来，上面的代码片段以检查网络设备是否关闭结束。如果是，则返回 <code>true</code> 并退出<code>igb_clean_tx_irq</code>。</p>
<pre><code class="hljs c++">tx_buffer = &amp;tx_ring-&gt;tx_buffer_info[i];
tx_desc = <span class="hljs-built_in">IGB_TX_DESC</span>(tx_ring, i);
i -= tx_ring-&gt;count;</code></pre>

<ol>
<li><code>tx_buffer</code>  变量被初始化为位于 <code>tx_ring-&gt;next_to_clean</code>（其本身被初始化为<code>0</code>）的传输缓冲区信息结构。</li>
<li>获得相关联的描述符的引用，并将其存储在 <code>tx_desc</code>。</li>
<li>计数器 <code>i</code> 减少发送队列的大小。 这个值可以调整（正如我们将在调优部分看到的那样），但是被初始化为 <code>IGB_DEFAULT_TXD</code>（256）。</li>
</ol>
<p>接下来，循环开始。 它包括一些有用的注释，以解释每个步骤中发生的事情：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">do</span> &#123;
        <span class="hljs-keyword">union</span> <span class="hljs-title class_">e1000_adv_tx_desc</span> *eop_desc = tx_buffer-&gt;next_to_watch;

        <span class="hljs-comment">/* if next_to_watch is not set then there is no work pending */</span>
        <span class="hljs-keyword">if</span> (!eop_desc)
                <span class="hljs-keyword">break</span>;

        <span class="hljs-comment">/* prevent any other reads prior to eop_desc */</span>
        <span class="hljs-built_in">read_barrier_depends</span>();

        <span class="hljs-comment">/* if DD is not set pending work has not been completed */</span>
        <span class="hljs-keyword">if</span> (!(eop_desc-&gt;wb.status &amp; <span class="hljs-built_in">cpu_to_le32</span>(E1000_TXD_STAT_DD)))
                <span class="hljs-keyword">break</span>;

        <span class="hljs-comment">/* clear next_to_watch to prevent false hangs */</span>
        tx_buffer-&gt;next_to_watch = <span class="hljs-literal">NULL</span>;

        <span class="hljs-comment">/* update the statistics for this packet */</span>
        total_bytes += tx_buffer-&gt;bytecount;
        total_packets += tx_buffer-&gt;gso_segs;

        <span class="hljs-comment">/* free the skb */</span>
        <span class="hljs-built_in">dev_kfree_skb_any</span>(tx_buffer-&gt;skb);

        <span class="hljs-comment">/* unmap skb header data */</span>
        <span class="hljs-built_in">dma_unmap_single</span>(tx_ring-&gt;dev,
                         <span class="hljs-built_in">dma_unmap_addr</span>(tx_buffer, dma),
                         <span class="hljs-built_in">dma_unmap_len</span>(tx_buffer, len),
                         DMA_TO_DEVICE);

        <span class="hljs-comment">/* clear tx_buffer data */</span>
        tx_buffer-&gt;skb = <span class="hljs-literal">NULL</span>;
        <span class="hljs-built_in">dma_unmap_len_set</span>(tx_buffer, len, <span class="hljs-number">0</span>);</code></pre>

<ol>
<li>首先，<code>eop_desc</code> 被设置为缓冲区的 <code>next_to_watch</code> 字段。这是在我们之前看到的传输代码中设置的。</li>
<li>如果 <code>eop_desc</code>（eop &#x3D; 数据包结束）为 <code>NULL</code>，则没有工作待处理。</li>
<li>调用 <code>read_barrier_depends</code> 函数，该函数将为此 CPU 架构执行适当的 CPU 指令，以防止读取被重新排序到此屏障之前。</li>
<li>接下来，在数据包结束描述符 <code>eop_desc</code> 中检查一个状态位。如果未设置 <code>E1000_TXD_STAT_DD</code> 位，则传输尚未完成，因此从循环中退出。</li>
<li>清除 <code>tx_buffer-&gt;next_to_watch</code>。驱动程序中的看门狗定时器将监视此字段以确定传输是否挂起。清除此字段将防止看门狗触发。</li>
<li>更新发送的总字节数和数据包数的统计计数器。一旦处理完所有描述符，复制这些到驱动程序读取的统计计数器中。</li>
<li>释放 skb。</li>
<li>使用 <code>dma_unmap_single</code> 取消映射 skb 数据区域。</li>
<li>设置 <code>tx_buffer-&gt;skb</code> 为 <code>NULL</code> 并取消映射 <code>tx_buffer</code>。</li>
</ol>
<p>接下来，在上面的循环内部开始另一个循环：</p>
<pre><code class="hljs c++"><span class="hljs-comment">/* clear last DMA location and unmap remaining buffers */</span>
<span class="hljs-keyword">while</span> (tx_desc != eop_desc) &#123;
        tx_buffer++;
        tx_desc++;
        i++;
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(!i)) &#123;
                i -= tx_ring-&gt;count;
                tx_buffer = tx_ring-&gt;tx_buffer_info;
                tx_desc = <span class="hljs-built_in">IGB_TX_DESC</span>(tx_ring, <span class="hljs-number">0</span>);
        &#125;

        <span class="hljs-comment">/* unmap any remaining paged data */</span>
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">dma_unmap_len</span>(tx_buffer, len)) &#123;
                <span class="hljs-built_in">dma_unmap_page</span>(tx_ring-&gt;dev,
                               <span class="hljs-built_in">dma_unmap_addr</span>(tx_buffer, dma),
                               <span class="hljs-built_in">dma_unmap_len</span>(tx_buffer, len),
                               DMA_TO_DEVICE);
                <span class="hljs-built_in">dma_unmap_len_set</span>(tx_buffer, len, <span class="hljs-number">0</span>);
        &#125;
&#125;</code></pre>

<p>该内部循环将在每个传输描述符上循环，直到 <code>tx_desc</code> 到达 <code>eop_desc</code>。 这段代码取消映射任何附加描述符引用的数据。</p>
<p>外部循环继续：</p>
<pre><code class="hljs c++">        <span class="hljs-comment">/* move us one more past the eop_desc for start of next pkt */</span>
        tx_buffer++;
        tx_desc++;
        i++;
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(!i)) &#123;
                i -= tx_ring-&gt;count;
                tx_buffer = tx_ring-&gt;tx_buffer_info;
                tx_desc = <span class="hljs-built_in">IGB_TX_DESC</span>(tx_ring, <span class="hljs-number">0</span>);
        &#125;

        <span class="hljs-comment">/* issue prefetch for next Tx descriptor */</span>
        <span class="hljs-built_in">prefetch</span>(tx_desc);

        <span class="hljs-comment">/* update budget accounting */</span>
        budget--;
&#125; <span class="hljs-keyword">while</span> (<span class="hljs-built_in">likely</span>(budget));</code></pre>

<p>外部循环增加迭代器并减少 <code>budget</code> 值。 检查循环不变量以确定循环是否应继续。</p>
<pre><code class="hljs c++"><span class="hljs-built_in">netdev_tx_completed_queue</span>(<span class="hljs-built_in">txring_txq</span>(tx_ring),
                          total_packets, total_bytes);
i += tx_ring-&gt;count;
tx_ring-&gt;next_to_clean = i;
<span class="hljs-built_in">u64_stats_update_begin</span>(&amp;tx_ring-&gt;tx_syncp);
tx_ring-&gt;tx_stats.bytes += total_bytes;
tx_ring-&gt;tx_stats.packets += total_packets;
<span class="hljs-built_in">u64_stats_update_end</span>(&amp;tx_ring-&gt;tx_syncp);
q_vector-&gt;tx.total_bytes += total_bytes;
q_vector-&gt;tx.total_packets += total_packets;</code></pre>

<p>此代码：</p>
<ol>
<li>调用 <code>netdev_tx_completed_queue</code>，它是上面解释的 DQL API 的一部分。 如果处理了足够的传输完成，这将潜在地重新启用传输队列。</li>
<li>统计数据被添加到适当位置，以便用户可以访问它们，我们将在后面看到。</li>
</ol>
<p>代码继续执行，首先检查是否设置了 IGB<code>IGB_RING_FLAG_TX_DETECT_HANG</code> 标志。 看门狗定时器在每次运行定时器回调时设置此标志，以强制执行传输队列的定期检查。 如果该标志现在恰好打开，代码将继续并检查传输队列是否挂起：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">test_bit</span>(IGB_RING_FLAG_TX_DETECT_HANG, &amp;tx_ring-&gt;flags)) &#123;
        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">e1000_hw</span> *hw = &amp;adapter-&gt;hw;

        <span class="hljs-comment">/* Detect a transmit hang in hardware, this serializes the</span>
<span class="hljs-comment">         * check with the clearing of time_stamp and movement of i</span>
<span class="hljs-comment">         */</span>
        <span class="hljs-built_in">clear_bit</span>(IGB_RING_FLAG_TX_DETECT_HANG, &amp;tx_ring-&gt;flags);
        <span class="hljs-keyword">if</span> (tx_buffer-&gt;next_to_watch &amp;&amp;
            <span class="hljs-built_in">time_after</span>(jiffies, tx_buffer-&gt;time_stamp +
                       (adapter-&gt;tx_timeout_factor * HZ)) &amp;&amp;
            !(<span class="hljs-built_in">rd32</span>(E1000_STATUS) &amp; E1000_STATUS_TXOFF)) &#123;

                <span class="hljs-comment">/* detected Tx unit hang */</span>
                <span class="hljs-built_in">dev_err</span>(tx_ring-&gt;dev,
                        <span class="hljs-string">&quot;Detected Tx Unit Hang\n&quot;</span>
                        <span class="hljs-string">&quot;  Tx Queue             &lt;%d&gt;\n&quot;</span>
                        <span class="hljs-string">&quot;  TDH                  &lt;%x&gt;\n&quot;</span>
                        <span class="hljs-string">&quot;  TDT                  &lt;%x&gt;\n&quot;</span>
                        <span class="hljs-string">&quot;  next_to_use          &lt;%x&gt;\n&quot;</span>
                        <span class="hljs-string">&quot;  next_to_clean        &lt;%x&gt;\n&quot;</span>
                        <span class="hljs-string">&quot;buffer_info[next_to_clean]\n&quot;</span>
                        <span class="hljs-string">&quot;  time_stamp           &lt;%lx&gt;\n&quot;</span>
                        <span class="hljs-string">&quot;  next_to_watch        &lt;%p&gt;\n&quot;</span>
                        <span class="hljs-string">&quot;  jiffies              &lt;%lx&gt;\n&quot;</span>
                        <span class="hljs-string">&quot;  desc.status          &lt;%x&gt;\n&quot;</span>,
                        tx_ring-&gt;queue_index,
                        <span class="hljs-built_in">rd32</span>(<span class="hljs-built_in">E1000_TDH</span>(tx_ring-&gt;reg_idx)),
                        <span class="hljs-built_in">readl</span>(tx_ring-&gt;tail),
                        tx_ring-&gt;next_to_use,
                        tx_ring-&gt;next_to_clean,
                        tx_buffer-&gt;time_stamp,
                        tx_buffer-&gt;next_to_watch,
                        jiffies,
                        tx_buffer-&gt;next_to_watch-&gt;wb.status);
                <span class="hljs-built_in">netif_stop_subqueue</span>(tx_ring-&gt;netdev,
                                    tx_ring-&gt;queue_index);

                <span class="hljs-comment">/* we are about to reset, no point in enabling stuff */</span>
                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;
        &#125;</code></pre>

<p>上面的 <code>if</code> 语句检查：</p>
<ul>
<li>设置了 <code>tx_buffer-&gt;next_to_watch</code>，并且</li>
<li>当前 <code>jiffies</code> 大于在传输路径上记录到 <code>tx_buffer</code> 的 <code>time_stamp</code>，其中添加了超时因子，以及</li>
<li>设备的传输状态寄存器未设置为 <code>E1000_STATUS_TXOFF</code>。</li>
</ul>
<p>如果这三个测试都为真，则打印一个错误，表明检测到挂起。使用 <code>netif_stop_subqueue</code> 关闭队列，并返回 <code>true</code>。</p>
<p>让我们继续阅读代码，看看如果没有传输挂起检查，或者如果有，但没有检测到挂起，会发生什么：</p>
<pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TX_WAKE_THRESHOLD (DESC_NEEDED * 2)</span>
        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">unlikely</span>(total_packets &amp;&amp;
            <span class="hljs-built_in">netif_carrier_ok</span>(tx_ring-&gt;netdev) &amp;&amp;
            <span class="hljs-built_in">igb_desc_unused</span>(tx_ring) &gt;= TX_WAKE_THRESHOLD)) &#123;
                <span class="hljs-comment">/* Make sure that anybody stopping the queue after this</span>
<span class="hljs-comment">                 * sees the new next_to_clean.</span>
<span class="hljs-comment">                 */</span>
                <span class="hljs-built_in">smp_mb</span>();
                <span class="hljs-keyword">if</span> (__netif_subqueue_stopped(tx_ring-&gt;netdev,
                                             tx_ring-&gt;queue_index) &amp;&amp;
                    !(<span class="hljs-built_in">test_bit</span>(__IGB_DOWN, &amp;adapter-&gt;state))) &#123;
                        <span class="hljs-built_in">netif_wake_subqueue</span>(tx_ring-&gt;netdev,
                                            tx_ring-&gt;queue_index);

                        <span class="hljs-built_in">u64_stats_update_begin</span>(&amp;tx_ring-&gt;tx_syncp);
                        tx_ring-&gt;tx_stats.restart_queue++;
                        <span class="hljs-built_in">u64_stats_update_end</span>(&amp;tx_ring-&gt;tx_syncp);
                &#125;
        &#125;

        <span class="hljs-keyword">return</span> !!budget;</code></pre>

<p>在上面的代码中，驱动程序重新启动传输队列（如果先前已禁用）。它首先检查是否：</p>
<ul>
<li>某些数据包已经处理完成（<code>total_packets</code> 非零），并且</li>
<li><code>netif_carrier_ok</code> 以确保设备未被关闭，以及</li>
<li>传输队列中未使用的描述符数量大于或等于 <code>TX_WAKE_THRESHOLD</code>。在我的 x86_64 系统上，此阈值似乎为 <code>42</code>。</li>
</ul>
<p>如果所有条件都满足，则使用写屏障（<code>smp_mb</code>）。接下来检查另一组条件：</p>
<ul>
<li>如果队列已停止，并且</li>
<li>设备未关闭</li>
</ul>
<p>然后调用 <code>netif_wake_subqueue</code> 唤醒传输队列并向更高层次发出信号，表示它们可以再次排队数据。增加 <code>restart_queue</code> 统计计数器。接下来我们将看到如何读取此值。</p>
<p>最后，返回一个布尔值。如果有任何剩余的未使用预算，则返回 <code>true</code>，否则返回 <code>false</code>。在 <code>igb_poll</code> 中检查此值以确定返回给 <code>net_rx_action</code> 的内容。</p>
<h5 id="igb-poll-返回值"><a href="#igb-poll-返回值" class="headerlink" title="igb_poll 返回值"></a><code>igb_poll</code> 返回值</h5><p>igb<code>igb_poll</code> 函数有以下代码来确定返回给 <code>net_rx_action</code>：</p>
<pre><code class="hljs c++"><span class="hljs-keyword">if</span> (q_vector-&gt;tx.ring)
        clean_complete = <span class="hljs-built_in">igb_clean_tx_irq</span>(q_vector);

<span class="hljs-keyword">if</span> (q_vector-&gt;rx.ring)
        clean_complete &amp;= <span class="hljs-built_in">igb_clean_rx_irq</span>(q_vector, budget);

<span class="hljs-comment">/* If all work not completed, return budget and keep polling */</span>
<span class="hljs-keyword">if</span> (!clean_complete)
        <span class="hljs-keyword">return</span> budget;</code></pre>

<p>换句话说，如果：</p>
<ul>
<li><code>igb_clean_tx_irq</code> 清除了所有传输完成，而没有耗尽其传输完成预算，以及</li>
<li><code>igb_clean_rx_irq</code> 清除了所有传入数据包，而没有耗尽其数据包处理预算</li>
</ul>
<p>然后，将返回整个预算数量（对于大多数驱动程序，它被硬编码为 <code>64</code>，包括 <code>igb</code>）。 如果传输或传入处理中的任何一个不能完成（因为还有更多的工作要做），则调用 <code>napi_complete</code> 并返回 <code>0</code>：</p>
<pre><code class="hljs c++">        <span class="hljs-comment">/* If not enough Rx work done, exit the polling mode */</span>
        <span class="hljs-built_in">napi_complete</span>(napi);
        <span class="hljs-built_in">igb_ring_irq_enable</span>(q_vector);

        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
&#125;</code></pre>

<h4 id="监控网络设备"><a href="#监控网络设备" class="headerlink" title="监控网络设备"></a>监控网络设备</h4><p>有几种不同的方法可以监控网络设备，提供不同级别的粒度和复杂性。 让我们从最细粒度开始，然后转到最细粒度。</p>
<h5 id="使用-ethtool-S"><a href="#使用-ethtool-S" class="headerlink" title="使用 ethtool -S"></a>使用 <code>ethtool -S</code></h5><p>你可以运行以下命令在 Ubuntu 系统上安装 <code>ethtool</code>：<code>sudo apt-get install ethtool</code>.</p>
<p>安装后，您可以传递  <code>-S</code> 标志以及需要统计信息的网络设备的名称来访问统计信息。</p>
<p>使用  <code>ethtool -S</code> 监控详细的 NIC 设备统计信息（例如， 传输错误）。</p>
<pre><code class="hljs bash">$ sudo ethtool -S eth0
NIC statistics:
     rx_packets: 597028087
     tx_packets: 5924278060
     rx_bytes: 112643393747
     tx_bytes: 990080156714
     rx_broadcast: 96
     tx_broadcast: 116
     rx_multicast: 20294528
     ....</code></pre>

<p>监测这些数据可能很困难。 它很容易获得，但字段值没有标准化。 不同的驱动程序，甚至不同版本的<em>同一</em> 驱动可能会产生具有相同含义的不同字段名称。</p>
<p>你应该在标签中寻找带有“drop”、“buffer”、“miss”、“errors”等的值。接下来，您将不得不阅读驱动程序源代码。您将能够确定哪些值完全在软件中计算（例如，在没有内存时增加）以及哪些值直接通过寄存器从硬件读取获得。对于寄存器值，您应该查阅硬件的数据表以确定计数器的真实含义； <code>ethtool</code> 给出的许多标签可能会产生误导。</p>
<h5 id="使用-sysfs"><a href="#使用-sysfs" class="headerlink" title="使用 sysfs"></a>使用 sysfs</h5><p>sysfs 也提供了许多统计值，但它们比直接提供的 NIC 级别统计值略高一些。</p>
<p>您可以使用 <code>cat</code> 在文件上查找丢弃的传入网络数据帧的数量，例如 eth0。</p>
<p>使用 sysfs 监控更高级别的 NIC 统计信息。</p>
<pre><code class="hljs bash">$ <span class="hljs-built_in">cat</span> /sys/class/net/eth0/statistics/tx_aborted_errors
2</code></pre>

<p>计数器值将被拆分为 <code>tx_aborted_errors</code>、<code>tx_carrier_errors</code>、<code>tx_compressed</code>、<code>tx_dropped</code> 等文件。</p>
<p>不幸的是，由驱动程序来决定每个字段的含义，以及何时增加它们以及值来自何处。 您可能会注意到，一些驱动程序将某种类型的错误情况视为丢弃，但其他驱动程序可能会将其视为未命中。</p>
<p>如果这些值对您很重要，您需要阅读驱动程序源代码和设备数据表，以准确了解驱动程序认为的每个值的含义。</p>
<h5 id="使用-proc-net-dev"><a href="#使用-proc-net-dev" class="headerlink" title="使用 /proc/net/dev"></a>使用 <code>/proc/net/dev</code></h5><p>更高级的文件是 <code>/proc/net/dev</code>，它为系统上的每个网络适配器提供高级摘要式信息。</p>
<p>读取 <code>/proc/net/dev</code> 来监视高级 NIC 统计信息。</p>
<pre><code class="hljs bash">$ <span class="hljs-built_in">cat</span> /proc/net/dev
Inter-|   Receive                                                |  Transmit
 face |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed
  eth0: 110346752214 597737500    0    2    0     0          0  20963860 990024805984 6066582604    0    0    0     0       0          0
    lo: 428349463836 1579868535    0    0    0     0          0         0 428349463836 1579868535    0    0    0     0       0          0</code></pre>

<p>这个文件显示了您在上面提到的 sysfs 文件中找到的值的子集，但它可能作为一个有用的一般参考。</p>
<p>上面提到的警告也适用于这里：如果这些值对您很重要，您仍然需要阅读驱动程序源代码，以准确了解何时、何地以及为什么它们会增加，以确保您对 error、drop 或 fifo 的理解与驱动程序相同。</p>
<h4 id="监控动态队列限制"><a href="#监控动态队列限制" class="headerlink" title="监控动态队列限制"></a>监控动态队列限制</h4><p>您可以读取位于以下位置的文件来监控网络设备的动态队列限制：</p>
<p><code>/sys/class/net/NIC/queues/tx-QUEUE_NUMBER/byte_queue_limits/</code>。</p>
<p>替换 <code>NIC</code> 为您的设备名称（<code>eth0</code>、<code>eth1</code> 等），替换 <code>tx-QUEUE_NUMBER</code> 为传输队列号（<code>tx-0</code>、<code>tx-1</code>、<code>tx-2</code> 等）。</p>
<p>其中一些文件是：</p>
<ul>
<li><code>hold_time</code>：初始化为 <code>HZ</code>（单个赫兹）。 如果队列在 <code>hold_time</code> 内已满，则减小最大大小。</li>
<li><code>inflight</code>：它是尚未处理完成的正在传输的数据包的当前数量。该值等于（排队的数据包数量-完成的数据包数量）。 </li>
<li><code>limit_max</code>：硬编码值，设置为 <code>DQL_MAX_LIMIT</code>（在我的 x86_64 系统上为 <code>1879048192</code>）。</li>
<li><code>limit_min</code>：硬编码值，设置为 <code>0</code>。</li>
<li><code>limit</code>：一个介于 <code>limit_min</code> 和 <code>limit_max</code> 之间的值，表示当前可以排队的对象的最大数量。</li>
</ul>
<p>在修改任何这些值之前，强烈建议<a target="_blank" rel="noopener" href="https://www.linuxplumbersconf.org/2012/wp-content/uploads/2012/08/bql_slide.pdf">阅读这些演示幻灯片，</a>以深入了解算法。</p>
<p>读取 <code>/sys/class/net/eth0/queues/tx-0/byte_queue_limits/inflight</code> 监控在传输过程中的数据包情况。</p>
<pre><code class="hljs bash">$ <span class="hljs-built_in">cat</span> /sys/class/net/eth0/queues/tx-0/byte_queue_limits/inflight
350</code></pre>

<h4 id="调优网络设备"><a href="#调优网络设备" class="headerlink" title="调优网络设备"></a>调优网络设备</h4><h5 id="检查正在使用的传输队列数"><a href="#检查正在使用的传输队列数" class="headerlink" title="检查正在使用的传输队列数"></a>检查正在使用的传输队列数</h5><p>如果您的 NIC 和系统上加载的设备驱动程序支持多个传输队列，则通常可以使用 ethtool 调整 TX 队列（也称为 TX 通道）的数量 <code>ethtool</code>。</p>
<p>使用 ethtool 检查 NIC 传输队列的数量 <code>ethtool</code></p>
<pre><code class="hljs bash">$ sudo ethtool -l eth0
Channel parameters <span class="hljs-keyword">for</span> eth0:
Pre-<span class="hljs-built_in">set</span> maximums:
RX:   0
TX:   0
Other:    0
Combined: 8
Current hardware settings:
RX:   0
TX:   0
Other:    0
Combined: 4</code></pre>

<p>此输出显示预设的最大值（由驱动程序和硬件强制执行）和当前设置。</p>
<p><strong>注意：</strong> 并非所有设备驱动程序都支持此操作。</p>
<p>如果您的 NIC 不支持此操作，则会出现错误。</p>
<pre><code class="hljs bash">$ sudo ethtool -l eth0
Channel parameters <span class="hljs-keyword">for</span> eth0:
Cannot get device channel parameters
: Operation not supported</code></pre>

<p>这意味着您的驱动程序尚未实现 ethtool <code>get_channels</code> 操作。 这可能是因为 NIC 不支持调整队列数量，不支持多个传输队列，或者您的驱动程序尚未更新以处理此功能。</p>
<h5 id="调整使用的传输队列数"><a href="#调整使用的传输队列数" class="headerlink" title="调整使用的传输队列数"></a>调整使用的传输队列数</h5><p>找到当前和最大队列计数后，可以使用 <code>sudo ethtool -L</code> 调整这些值。</p>
<p><strong>注意：</strong> 某些设备及其驱动程序仅支持为发送和接收配对的组合队列，如上一节中的示例所示。</p>
<p>使用 <code>ethtool -L</code> 设置组合 NIC 传输和接收队列为 8</p>
<pre><code class="hljs bash">$ sudo ethtool -L eth0 combined 8</code></pre>

<p>如果您的设备和驱动程序支持 RX 和 TX 的单独设置，并且您只想更改 TX 队列计数为 8，则可以运行：</p>
<p>使用 <code>ethtool -L</code> 设置 NIC 传输队列的数量为 8。</p>
<pre><code class="hljs bash">$ sudo ethtool -L eth0 tx 8</code></pre>

<p><strong>注意：</strong> 对于大多数驱动程序来说，进行这些更改将关闭接口，然后再重新打开; 与该接口的连接将被中断。 不过，这对于一次性的改变来说可能并不重要。</p>
<h5 id="调整传输队列的大小"><a href="#调整传输队列的大小" class="headerlink" title="调整传输队列的大小"></a>调整传输队列的大小</h5><p>某些 NIC 及其驱动程序还支持调整 TX 队列的大小。 具体的工作原理是硬件相关的，但幸运的是，<code>ethtool</code> 为用户提供了一种通用的方法来调整大小。 由于使用了 DQL 来防止更高层次的网络代码在某些时候排队更多数据，因此增加发送队列的大小可能不会产生巨大的差异。尽管如此，您可能仍然希望增加发送队列到最大大小，并让 DQL 为您处理其他所有事情：</p>
<p>使用 <code>ethtool -g</code> 检查当前网卡队列大小。</p>
<pre><code class="hljs bash">$ sudo ethtool -g eth0
Ring parameters <span class="hljs-keyword">for</span> eth0:
Pre-<span class="hljs-built_in">set</span> maximums:
RX:   4096
RX Mini:  0
RX Jumbo: 0
TX:   4096
Current hardware settings:
RX:   512
RX Mini:  0
RX Jumbo: 0
TX:   512</code></pre>

<p>上面的输出指示硬件支持多达 4096 个接收和发送描述符，但是它当前仅使用 512 个。</p>
<p>使用 <code>ethtool -G</code> 增加每个 TX 队列的大小到 4096</p>
<pre><code class="hljs bash">$ sudo ethtool -G eth0 tx 4096</code></pre>

<p><strong>注意：</strong> 对于大多数驱动程序来说，进行这些更改将关闭接口，然后再重新打开；与该接口的连接将被中断。 不过，这对于一次性的改变来说可能并不重要。</p>
<h3 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h3><p>结束了！ 现在你已经知道了 Linux 上数据包传输的工作原理：从用户程序到设备驱动程序再返回。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>有一些额外的事情值得一提，值得一提的是，似乎不太正确的其他任何地方。</p>
<h3 id="减少-ARP-流量（MSG-CONFIRM）"><a href="#减少-ARP-流量（MSG-CONFIRM）" class="headerlink" title="减少 ARP 流量（MSG_CONFIRM）"></a>减少 ARP 流量（<code>MSG_CONFIRM</code>）</h3><p><code>send</code>、<code>sendto</code> 和 <code>sendmsg</code> 系统调用都采用 <code>flags</code> 参数。 如果您传递 <code>MSG_CONFIRM</code> 标志给应用程序中的这些系统调用，它将导致内核中发送路径上的 <code>dst_neigh_output</code> 函数更新邻居结构的时间戳。 这样做的结果是相邻结构将不会被垃圾收集。 这可以防止产生额外的 ARP 流量，因为邻居缓存条目将保持更热、更长时间。</p>
<h3 id="UDP-Corking"><a href="#UDP-Corking" class="headerlink" title="UDP Corking"></a>UDP Corking</h3><p>我们在整个 UDP 协议栈中广泛地研究了 UDP corking。 如果要在应用程序中使用它，可以调用 <code>setsockopt</code> 启用 UDP corking，设置 level 为 <code>IPPROTO_UDP</code>，optname 设置为 <code>UDP_CORK</code>，<code>optval</code> 设置为 <code>1</code>。</p>
<h3 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h3><p>正如上面的博客文章中提到的，网络栈可以收集传出数据的时间戳。 请参阅上面的网络栈演练，了解软件中的传输时间戳发生的位置。 一些 NIC 甚至还支持硬件中的时间戳。</p>
<p>如果您想尝试确定内核网络栈在发送数据包时增加了多少延迟，这是一个有用的特性。</p>
<p>关于<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/timestamping.txt">时间戳的内核文档</a>非常好，甚至还有一个包含的示例程序和 Makefile，<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/tree/v3.13/Documentation/networking/timestamping">你可以查看</a>！</p>
<p>使用 <code>ethtool -T</code> 确定您的驱动程序和设备支持的时间戳模式。</p>
<pre><code class="hljs bash">$ sudo ethtool -T eth0
Time stamping parameters <span class="hljs-keyword">for</span> eth0:
Capabilities:
  software-transmit     (SOF_TIMESTAMPING_TX_SOFTWARE)
  software-receive      (SOF_TIMESTAMPING_RX_SOFTWARE)
  software-system-clock (SOF_TIMESTAMPING_SOFTWARE)
PTP Hardware Clock: none
Hardware Transmit Timestamp Modes: none
Hardware Receive Filter Modes: none</code></pre>

<p>不幸的是，这个网卡不支持硬件传输时间戳，但是软件时间戳仍然可以在这个系统上使用，以帮助我确定内核给我的数据包传输路径增加了多少延迟。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>Linux 网络栈很复杂。</p>
<p>正如我们上面看到的，即使像 <code>NET_RX</code> 这样简单的东西也不能保证像我们期望的那样工作。 即使<code>RX</code> 在名称中，传输完成仍在此 softIRQ 中处理。</p>
<p>这突出了我认为是问题的核心：除非您仔细阅读并理解网络栈的工作原理，否则无法优化和监控网络栈。您无法监控您不深入了解的代码。</p>
<p><em>原文：</em> <a target="_blank" rel="noopener" href="https://blog.packagecloud.io/monitoring-tuning-linux-networking-stack-sending-data/">Monitoring and Tuning the Linux Networking Stack: Sending Data</a></p>
<p><strong>本文作者</strong> ： cyningsun<br /><strong>本文地址</strong> ： <a href="https://www.cyningsun.com/04-25-2023/monitoring-and-tuning-the-linux-networking-stack-sent-cn.html">https://www.cyningsun.com/04-25-2023/monitoring-and-tuning-the-linux-networking-stack-sent-cn.html</a> <br /><strong>版权声明</strong> ：本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc-nd/3.0/cn/">CC BY-NC-ND 3.0 CN</a> 许可协议。转载请注明出处！</p>

    </div>
    
<div class="post-subject">
    
    <a href="/subjects#Network" rel="category"># Network</a>
    
</div>


    



  <ol class="related">
      
            <li><span><a href="/10-08-2023/dive-into-dns-resolution.html">深入理解 DNS 解析</a></span></li>
          
            <li><span><a href="/05-10-2023/a-scalable-commodity-data-center-network-architecture-cn.html">译｜A scalable, commodity data center network architecture</a></span></li>
          
            <li><span><a href="/04-26-2023/illustrated-guide-to-monitoring-and-tuning-the-Linux-networking-stack-recv-cn.html">译｜llustrated Guide to Monitoring and Tuning the Linux Networking Stack: Receiving Data</a></span></li>
          
            <li><span><a href="/04-24-2023/monitoring-and-tuning-the-linux-networking-stack-recv-cn.html">译｜Monitoring and Tuning the Linux Networking Stack: Receiving Data</a></span></li>
          
            <li><span><a href="/03-30-2023/network-transmission.html">TCP/IP 网络传输</a></span></li>
          
  </ol>


    <ul class="pager">
     
     <li class="next"><a href="/04-26-2023/illustrated-guide-to-monitoring-and-tuning-the-Linux-networking-stack-recv-cn.html">Newer &rarr;</a></li>
    
    
    <li class="previous"><a href="/04-24-2023/monitoring-and-tuning-the-linux-networking-stack-recv-cn.html">&larr; Older</a></li>
    
</ul>
</div>

<div id="comment"  class="typo">
			<!-- Comment BEGIN -->
      <script src="https://utteranc.es/client.js"
            repo="cyningsun/blog-sidecar"
            issue-term="title"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>


<!-- Comment END -->
</div>
      </div>
      <div class="container">
  <footer>
    <p class="text-muted credit">Copyright ©2025 cyningsun
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <a href="  https://www.cyningsun.com">Powered by Hexo</a></p>
  </footer>
</div>

  <script src='https://unpkg.com/mermaid@8.6.4/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'neutral'});
    }
  </script>

    </div>
    <!-- Bootstrap core JavaScript-->

<script src="/js/jquery-1.10.2.min.js"></script>


<script src="/js/bootstrap.min.js"></script>


<script src="/js/hc.js"></script>

<script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

<script src="/js/syntax.js"></script>

  </body>
</html>
